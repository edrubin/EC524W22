# Class project

## Project description

1. **Group** Create a two-person group. (You can work alone if you want, but the expectations will be the same as for a two-person group.)
1. **Topic** Select a prediction problem and "register" it with me (Ed).
   - You should have a motivation for why this prediction problem is potentially interesting/important.
   - You should also know whether/where you're able to get the data.
   - **Important** In addition to an outcome variable, you are going to need a decent set of predictors.
   - **Also important** The datasets that we've used in class are off limits—as are anything in `ISLR` (the R package).
   - **Still important** Groups cannot overlap in topics. First mover wins.
1. **Data** Gather data.
1. **Test** Randomly select approximately 20% of your data for a test set. (Don't train on it until everything is done.)
1. **Train** Apply "best" techniques to clean, train, and predict. Use **four different algorithms**—one of which should be a linear-regression-based model (unless it is not possible in your context). Examples of different algorithms: Logistic regression, lasso, random forests, SVM.
1. **CV error** Estimate your error (with an appropriately chosen metric) using cross validation.
1. **Test** Test your performance with the held out data.
1. **Reports** Create the following reports (see *materials due*, below).

## Materials due

Your topic and group are due by the end of the day on **February 16th**.

By midnight on **March 9th**, submit **four documents** on Canvas (share links or upload files):

1. Kaggle notebook (or [RMarkdown](https://rmarkdown.rstudio.com/lesson-10.html) notebook) with commented analysis code and figures
1. 1-page "executive summary" (see below for format)
1. 4-slide summary following paragraphs 2–5 of the executive summary (below)
1. Evaluation of your group member's contribution (submitted individually)

**NOTE:** No late submissions accepted.

## Notebook

Your Kaggle notebook should have sections (_e.g._, "data", "cleaning", "tuning", "training", "prediction") and should be heavily commented. **Create figures**—both to visualize your data and to deepen your understanding of the results/predictions/tuning.

This notebook should look clean enough to send to a potential employer.

## Executive summary

The executive summary should be organized and written well. Specifically, it should follow this outline.

**Paragraph 2:** The big picture

- your project's question
- why the question is important/interesting
- what makes this a prediction problem

**Paragraph 3:** Data

- sources
- cleaning
- challenges
- shortcomings

**Paragraph 4:** Methods

- learning methods applied
- tuned parameters
- method for tuning

**Paragraph 5:** Results and conclusion

- how you measure performance/success
- how your models perform
- what you think limited your performance
- what you learned in this process

**Paragraph 1:** Brief overview of paragraphs 2–5

## Presentation

You will present a 4-slide summary paragraphs 2–5 of the executive summary (above).

Do not include all of the information from the four paragraphs. Your presentation should be a graphical companion to the other two reports. Again, it should be high enough quality to send to a prospective employer.

## Evaluation

Submit a short evaluation of whether you and your group-member equally distributed work—or if the work was unequal. If it was unequal, describe to what extent it was unequal and whether you believe you should receive the same grade.

## Groups and topics

| ID | Member 1 | Member 2 | Member 3 | Topic/Title |
|----|----------|-----------|-----------|-------------|
| 1  | Zoe Arnaut-Hull | Octavio De Lima | Cyrus Tadjiki |  |
| 2  |  |  |  |  |
| 3  |  |  |  |  |
| 4  |  |  |  |  |
| 5  |  |  |  |  |
| 6  |  |  |  |  |
| 7  |  |  |  |  |
| 8  |  |  |  |  |
| 9  |  |  |  |  |
| 10 |  |  |  |  |
| 11 |  |  |  |  |
| 12 |  |  |  |  |
| 13 |  |  |  |  |
| 14 |  |  |  |  |
| 15 |  |  |  |  |
