<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Lecture .mono[008]</title>
    <meta charset="utf-8" />
    <meta name="author" content="Edward Rubin" />
    <script src="008-slides_files/header-attrs-2.11/header-attrs.js"></script>
    <link href="008-slides_files/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="008-slides_files/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="008-slides_files/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link href="008-slides_files/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="008-slides_files/tile-view-0.2.6/tile-view.js"></script>
    <script src="008-slides_files/xaringanExtra_fit-screen-0.2.6/fit-screen.js"></script>
    <link rel="stylesheet" href="my-css.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Lecture .mono[008]
## Ensembles ðŸŒ².smallest[ðŸŒ²]ðŸŒ².smallest[ðŸŽ„]ðŸŒ²
### Edward Rubin
### Winter 2022

---

exclude: true



---
name: admin
# Admin
## Today

.note[Topic] Ensembles (applied to decision trees)

## Upcoming

.b[Readings]
- .note[Today] .it[ISL] Ch. 8.2
- .note[Next] .it[ISL] Ch. 9

.b[Project] Project topic and group due next week (Feb. 25th).

---
class: inverse, middle
# Decision trees
## Review

---
name: tree-review-fundamentals
# Decision trees
## Fundamentals

.attn[Decision trees]
- split the .it[predictor space] (our `\(\mathbf{X}\)`) into regions
- then predict the most-common value within a region

--


.col-left[
.hi-purple[Regression trees]
- .hi-slate[Predict:] Region's mean
- .hi-slate[Split:] Minimize RSS
- .hi-slate[Prune:] Penalized RSS
]

--

.col-right[
.hi-pink[Classification trees]
- .hi-slate[Predict:] Region's mode
- .hi-slate[Split:] Min. Gini or entropy.super
- .hi-slate[Prune:] Penalized error rate.super[ðŸŒ´]
]

.footnote[
ðŸŒ´ ... or Gini index or entropy
]

--

.clear-up[
An additional nuance for .attn[classification trees:] we typically care about the .b[proportions of classes in the leaves]â€”not just the final prediction.
]

---
class: clear



.ex[Example] Each split in our tree creates .hi-purple[regions].

&lt;img src="008-slides_files/figure-html/plot-tree-example-1.svg" style="display: block; margin: auto;" /&gt;

---
class: clear

.ex[Example] Each region has its own .b[predicted value].

&lt;img src="008-slides_files/figure-html/plot-tree-example2-1.svg" style="display: block; margin: auto;" /&gt;

---
class: clear
exclude: true



---
name: tree-review-tradeoff
# Decision trees
## Strengths and weaknesses

As with any method, decision trees have tradeoffs.

--

.col-left.purple.small[
.b[Strengths]
&lt;br&gt;.b[+] Easily explained/interpretted
&lt;br&gt;.b[+] Include several graphical options
&lt;br&gt;.b[+] Mirror human decision making?
&lt;br&gt;.b[+] Handle num. or cat. on LHS/RHS.super[ðŸŒ³]
]

.footnote[
ðŸŒ³ Without needing to create lots of dummy variables!
&lt;br&gt;
.tran[ðŸŒ´ Blank]
]

--

.col-right.pink.small[
.b[Weaknesses]
&lt;br&gt;.b[-] Outperformed by other methods
&lt;br&gt;.b[-] Struggle with linearity
&lt;br&gt;.b[-] Can be very "non-robust"
]

.clear-up[
.attn[Non-robust:] Small data changes can cause huge changes in our tree.
]

--

.footnote[
.tran[ðŸŒ´ Blank]
&lt;br&gt;
ðŸŒ² Forests!
]

.note[Next:] Create ensembles of trees.super[ðŸŒ²] to strengthen these weaknesses.
--
.super[ðŸŒ´]

.footnote[
.tran[ðŸŒ´ Blank]
&lt;br&gt;
.tran[ðŸŒ² Forests!] ðŸŒ´ Which will also weaken some of the strengths.
]

---
layout: true
# Ensemble methods

---
class: inverse, middle

---
name: intro
## Intro

Rather than focusing on training a .b[single], highly accurate model,
&lt;br&gt;.attn[ensemble methods] combine .b[many] low-accuracy models into a .it[meta-model].

--

.note[Today:] Three common methods for .b[combining individual trees]

1. .attn[Bagging]
1. .attn[Random forests]
1. .attn[Boosting]

--

.b[Why?] While individual trees may be highly variable and inaccurate,
&lt;br&gt;a combination of trees is often quite stable and accurate.
--
.super[ðŸŒ²]

.footnote[
ðŸŒ² We will lose interpretability.
]

---
name: bag-intro
## Bagging

.attn[Bagging] creates additional samples via [.hi[bootstrapping]](https://raw.githack.com/edrubin/EC524W20/master/lecture/003/003-slides.html#62).

--

.qa[Q] How does bootstrapping help?

--

.qa[A] .note[Recall:] Individual decision trees suffer from variability (.it[non-robust]).

--

This .it[non-robustness] means trees can change .it[a lot] based upon which observations are included/excluded.

--

We're essentially using many "draws" instead of a single one..super[ðŸŒ´]

.footnote[
ðŸŒ´ Recall that an estimator's variance typically decreases as the sample size increases.
]

---
name: bag-algorithm
## Bagging

.attn[Bootstrap aggregation] (bagging) reduces this type of variability.

1. Create `\(B\)` bootstrapped samples

1. Train an estimator (tree) `\(\color{#6A5ACD}{\mathop{\hat{f^b}}(x)}\)` on each of the `\(B\)` samples

1. Aggregate across your `\(B\)` bootstrapped models:
$$
`\begin{align}
  \color{#e64173}{\mathop{\hat{f}_{\text{bag}}}(x)} = \dfrac{1}{B}\sum_{b=1}^{B}\color{#6A5ACD}{\mathop{\hat{f^b}}(x)}
\end{align}`
$$

This aggregated model `\(\color{#e64173}{\mathop{\hat{f}_{\text{bag}}}(x)}\)` is your final model.

---
## Bagging trees

When we apply bagging to decision trees,

- we typically .hi-pink[grow the trees deep and do not prune]

- for .hi-purple[regression], we .hi-purple[average] across the `\(B\)` trees' regions

- for .hi-purple[classification], we have more optionsâ€”but often take .hi-purple[plurality]

--

.hi-pink[Individual] (unpruned) trees will be very .hi-pink[flexible] and .hi-pink[noisy],
&lt;br&gt;but their .hi-purple[aggregate] will be quite .hi-purple[stable].

--

The number of trees `\(B\)` is generally not critical with bagging.
&lt;br&gt; `\(B=100\)` often works fine.

---
name: bag-oob
## Out-of-bag error estimation

Bagging also offers a convenient method for evaluating performance.

--

For any bootstrapped sample, we omit âˆ¼n/3 observations.

.attn[Out-of-bag (OOB) error estimation] estimates the test error rate using observations .b[randomly omitted] from each bootstrapped sample.

--

For each observation `\(i\)`:

1. Find all samples `\(S_i\)` in which `\(i\)` was omitted from training.

1. Aggregate the `\(|S_i|\)` predictions `\(\color{#6A5ACD}{\mathop{\hat{f^b}}(x_i)}\)`, _e.g._, using their mean or mode

1. Calculate the error, _e.g._, `\(y_i - \mathop{\hat{f}_{i,\text{OOB},i}}(x_i)\)`

---
## Out-of-bag error estimation

When `\(B\)` is big enough, the OOB error rate will be very close to LOOCV.

--

.qa[Q] Why use OOB error rate?

--

.qa[A] When `\(B\)` and `\(n\)` are large, cross validationâ€”with any number of foldsâ€”can become pretty computationally intensive.

---
class: clear, middle
layout: false

.note[Quick aside:] Here is a tool to search `parsnip` models:

&gt;[https://www.tidymodels.org/find/parsnip/](https://www.tidymodels.org/find/parsnip/)

---
layout: true
# Ensemble methods

---
name: bag-r
## Bagging in R

We can use `tidymodels` plus the `baguette` package to bag trees.

--

.col-left[
.b[Function:] `bag_treebag()`
- "Specifies" model for `parsnip`.
]

.col-right[

```r
# Train a bagged tree model
bag_tree(
  mode = "classification",
  cost_complexity = 0,
  tree_depth = NULL,
  min_n = 2,
  class_cost = NULL
)
```
]

---
count: false
## Bagging in R

We can use `tidymodels` plus the `baguette` package to bag trees.

.col-left[
.b[Function:] `bag_treebag()`
- "Specifies" model for `parsnip`.
- `mode`: class., reg., or unknown
]

.col-right[

```r
# Train a bagged tree model
bag_tree(
* mode = "classification",
  cost_complexity = 0,
  tree_depth = NULL,
  min_n = 2,
  class_cost = NULL
)
```
]

---
count: false
## Bagging in R

We can use `tidymodels` plus the `baguette` package to bag trees.

.col-left[
.b[Function:] `bag_treebag()`
- "Specifies" model for `parsnip`.
- `mode`: class., reg., or unknown
- `cost_complexity`: the penalty for model complexity (`Cp`)
]

.col-right[

```r
# Train a bagged tree model
bag_tree(
  mode = "classification",
* cost_complexity = 0,
  tree_depth = NULL,
  min_n = 2,
  class_cost = NULL
)
```
]

---
count: false
## Bagging in R

We can use `tidymodels` plus the `baguette` package to bag trees.

.col-left[
.b[Function:] `bag_treebag()`
- "Specifies" model for `parsnip`.
- `mode`: class., reg., or unknown
- `cost_complexity`: the penalty for model complexity (`Cp`)
- `tree_depth`: max. tree depth
]

.col-right[

```r
# Train a bagged tree model
bag_tree(
  mode = "classification",
  cost_complexity = 0,
* tree_depth = NULL,
  min_n = 2,
  class_cost = NULL
)
```
]

---
count: false
## Bagging in R

We can use `tidymodels` plus the `baguette` package to bag trees.

.col-left[
.b[Function:] `bag_treebag()`
- "Specifies" model for `parsnip`.
- `mode`: class., reg., or unknown
- `cost_complexity`: the penalty for model complexity (`Cp`)
- `tree_depth`: max. tree depth
- `min_n`: min. # obs. to split
]

.col-right[

```r
# Train a bagged tree model
bag_tree(
  mode = "classification",
  cost_complexity = 0,
  tree_depth = NULL,
* min_n = 2,
  class_cost = NULL
)
```
]

---
count: false
## Bagging in R

We can use `tidymodels` plus the `baguette` package to bag trees.

.col-left[
.b[Function:] `bag_treebag()`
- "Specifies" model for `parsnip`.
- `mode`: class., reg., or unknown
- `cost_complexity`: the penalty for model complexity (`Cp`)
- `tree_depth`: max. tree depth
- `min_n`: min. # obs. to split
- `class_cost`: magnify .note[cost] of incorrect guess (for first class)
]

.col-right[

```r
# Train a bagged tree model
bag_tree(
  mode = "classification",
  cost_complexity = 0,
  tree_depth = NULL,
  min_n = 2,
* class_cost = NULL
)
```
]

---
count: false
## Bagging in R

We can use `tidymodels` plus the `baguette` package to bag trees.

.col-left[
.b[Function:] `bag_treebag()`
- "Specifies" model for `parsnip`.
- `mode`: class., reg., or unknown
- `cost_complexity`: the penalty for model complexity (`Cp`)
- `tree_depth`: max. tree depth
- `min_n`: min. # obs. to split
- `class_cost`: magnify .note[cost]
- `rpart` is the defaul engine
]

.col-right[

```r
# Train a bagged tree model
bag_tree(
  mode = "classification",
  cost_complexity = 0,
  tree_depth = NULL,
  min_n = 2,
  class_cost = NULL
) %&gt;% set_engine(
* engine = "rpart",
  times = 100
)
```
]

---
count: false
## Bagging in R

We can use `tidymodels` plus the `baguette` package to bag trees.

.col-left[
.b[Function:] `bag_treebag()`
- "Specifies" model for `parsnip`.
- `mode`: class., reg., or unknown
- `cost_complexity`: the penalty for model complexity (`Cp`)
- `tree_depth`: max. tree depth
- `min_n`: min. # obs. to split
- `class_cost`: magnify .note[cost]
- `rpart` is the defaul engine
- `times`: the number of trees
]

.col-right[

```r
# Train a bagged tree model
bag_tree(
  mode = "classification",
  cost_complexity = 0,
  tree_depth = NULL,
  min_n = 2,
  class_cost = NULL
) %&gt;% set_engine(
  engine = "rpart",
* times = 100
)
```
]

---
exclude: true

## Example: Bagging in R



.col-left[
&lt;br&gt;With OOB-based error

```r
# Set the seed
set.seed(12345)
# Train the bagged trees
heart_bag = train(
  heart_disease ~ .,
  data = heart_df,
  method = "treebag",
  nbagg = 100,
  keepX = T,
  trControl = trainControl(
*   method = "oob"
  )
)
```
]
.col-right[
&lt;br&gt;With CV-based error

```r
# Set the seed
set.seed(12345)
# Train the bagged trees
heart_bag_cv = train(
  heart_disease ~ .,
  data = heart_df,
  method = "treebag",
  nbagg = 100,
  keepX = T,
  trControl = trainControl(
*   method = "cv",
*   number = 5
  )
)
```
]

---
exclude: true


```r
# Set the seed
set.seed(12345)
# Train the bagged trees
bag_oob = mclapply(
  X = 2:300,
  mc.cores = 12,
  FUN = function(n) {
    train(
      heart_disease ~ .,
      data = heart_df,
      method = "treebag",
      nbagg = n,
      keepX = T,
      trControl = trainControl(
        method = "oob"
      )
    )$results$Accuracy %&gt;%
    data.frame(accuracy = ., n_trees = n)
  }
) %&gt;% bind_rows()
# Train the bagged trees
bag_cv = mclapply(
  X = 2:300,
  mc.cores = 12,
  FUN = function(n) {
    train(
      heart_disease ~ .,
      data = heart_df,
      method = "treebag",
      nbagg = n,
      keepX = T,
      trControl = trainControl(
        method = "cv",
        number = 5
      )
    )$results$Accuracy %&gt;%
    data.frame(accuracy = ., n_trees = n)
  }
) %&gt;% bind_rows()
```

---
layout: false
class: clear

.b[Bagging and the number of trees]

&lt;img src="008-slides_files/figure-html/plot-bag-1.svg" style="display: block; margin: auto;" /&gt;

---
class: clear, middle

Unfortunately, this combination of `rpart`/`baguette`/`parsnip`/`yardstick` doesn't ([currently](https://github.com/tidymodels/baguette/issues/33)) offer OOB-based metrics. ðŸ˜ž

---
class: clear, middle

We .it[can] ["trick"](https://www.sds.pub/bagged-trees.html) random forests (`ranger`) into doing OOB for bagged trees.

But first, we need to learn about random forests...

---
class: clear, middle

... and before .it[that], let's briefly talk about variable importance.

---
name: bag-var
# Ensemble methods
## Variable importance

While ensemble methods tend to .hi[improve predictive performance],
&lt;br&gt;they also tend .hi[reduce interpretability].

--

We can illustrate .attn[variables' importance] by considering their splits' reductions in the model's performance metric (RSS, Gini, entropy, _etc._)..super[ðŸŒ³]

.footnote[
ðŸŒ³ This idea isn't exclusive to bagging/ensembles; it also works for a single tree.
]

--

.note[Note] By default, many variable-importance functions will scale importance.

---
layout: false
class: clear

In the case of `"rpart"` bagged trees...




```r
# Recipe to clean data (impute NAs)
heart_recipe = recipe(heart_disease ~ ., data = heart_df) %&gt;% 
  step_medianimpute(all_predictors() &amp; all_numeric()) %&gt;% 
  step_modeimpute(all_predictors() &amp; all_nominal())
# Define the bagged tree model
heart_bag = bag_tree(
  mode = "classification",
  cost_complexity = 0,
  tree_depth = NULL,
  min_n = 2,
  class_cost = NULL
) %&gt;% set_engine(
  engine = "rpart",
  times = 100
)
# Define workflow
heart_bag_wf = workflow() %&gt;% 
  add_model(heart_bag) %&gt;% 
  add_recipe(heart_recipe)
# Fit/assess with CV
heart_bag_fit = heart_bag_wf %&gt;% fit(heart_df)
```

---
class: clear

... the fitted object automatically includes variable importance.


```
#&gt; Bagged CART (classification with 100 members)
#&gt; 
#&gt; Variable importance scores include:
#&gt; 
#&gt; # A tibble: 13 Ã— 4
#&gt;    term       value std.error  used
#&gt;    &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt; &lt;int&gt;
#&gt;  1 max_hr     41.1      0.839   100
#&gt;  2 chest_pain 36.9      1.18    100
#&gt;  3 oldpeak    36.8      0.806   100
#&gt;  4 thal       35.7      1.35    100
#&gt;  5 age        32.2      0.702   100
#&gt;  6 ca         26.8      1.18    100
#&gt;  7 chol       23.2      0.685   100
#&gt;  8 rest_bp    22.1      0.589   100
#&gt;  9 ex_ang     20.6      0.818    99
#&gt; 10 slope      16.3      0.772   100
#&gt; 11 sex        11.8      0.678   100
#&gt; 12 rest_ecg    4.92     0.311    95
#&gt; 13 fbs         3.02     0.210    93
```

---
class: clear



.hi-pink[Variable importance] from our bagged tree model.

&lt;img src="008-slides_files/figure-html/plot-var-importance-1.svg" style="display: block; margin: auto;" /&gt;

---
name: bag-weak
# Ensemble methods
## Bagging

Bagging has one additional shortcoming...

If one variable dominates other variables, the .hi[trees will be very correlated].

--

If the trees are very correlated, then bagging loses its advantage.

--

.note[Solution] We should make the trees less correlated.

---
layout: true
# Ensemble methods

---
name: rf-intro
## Random forests

.attn[Random forests] improve upon bagged trees by .it[decorrelating] the trees.

--

In order to decorrelate its trees, a .attn[random forest] only .pink[considers a random subset of] `\(\color{#e64173}{m\enspace (\approx\sqrt{p})}\)` .pink[predictors] when making each split (for each tree).

--

Restricting the variables our tree sees at a given split

--

- nudges trees away from always using the same variables,

--

- increasing the variation across trees in our forest,

--

- which potentially reduces the variance of our estimates.

--

If our predictors are very correlated, we may want to shrink `\(m\)`.

---
## Random forests

Random forests thus introduce .b[two dimensions of random variation]

1. the .b[bootstrapped sample]

2. the `\(m\)` .b[randomly selected predictors] (for the split)

Everything else about random forests works just as it did with bagging..super[ðŸŽ„]

.footnote[
ðŸŽ„ And just as it did with plain, old decision trees.
]


---
name: rf-r
## Random forests in R

You have several [options](http://topepo.github.io/caret/train-models-by-tag.html#Random_Forest) for training random forests with `tidymodels`..super[ðŸŽ„]
&lt;br&gt;_E.g._, `ranger`, `randomForest`, `spark`.

`rand_forest()` accesses each of these packages via their .it[engines].

.footnote[
ðŸŽ„ And even more if you look outside of `tidymodels`.
]

--

- The default engine is `"ranger"` ([`ranger`](https://cran.r-project.org/web/packages/ranger/index.html) package).

--

- The argument `mtry` gives `\(m\)`, the # of predictors at each split.

--

You've already seen the other hyperparameters for `ranger`:

- `trees` the number of trees in your (random) forest
- `min_n` min. # of observations

---
layout: true
# Ensemble methods

Training a random forest in R using `tidymodels`...

---

.col-left[
... and `ranger`
]

.col-right[

```r
# Define the random forest
heart_rf = rand_forest(
  mode = "classification",
  mtry = 3,
  trees = 100,
  min_n = 2
) %&gt;% set_engine(
  engine = "ranger",
  splitrule = "gini"
)
```
]



---
count: false

.col-left[
... and `ranger`
- Goal: Classification
]

.col-right[

```r
# Define the random forest
heart_rf = rand_forest(
* mode = "classification",
  mtry = 3,
  trees = 100,
  min_n = 2
) %&gt;% set_engine(
  engine = "ranger",
  splitrule = "gini"
)
```
]

---
count: false

.col-left[
... and `ranger`
- Goal: Classification
- Three variables per split
]

.col-right[

```r
# Define the random forest
heart_rf = rand_forest(
  mode = "classification", 
* mtry = 3,
  trees = 100,
  min_n = 2
) %&gt;% set_engine(
  engine = "ranger",
  splitrule = "gini"
)
```
]

---
count: false

.col-left[
... and `ranger`
- Goal: Classification
- Three variables per split
- 100 trees in the forest
]

.col-right[

```r
# Define the random forest
heart_rf = rand_forest(
  mode = "classification", 
  mtry = 3,
* trees = 100,
  min_n = 2
) %&gt;% set_engine(
  engine = "ranger",
  splitrule = "gini"
)
```
]

---
count: false

.col-left[
... and `ranger`
- Goal: Classification
- Three variables per split
- 100 trees in the forest
- At least 2 obs. to split
]

.col-right[

```r
# Define the random forest
heart_rf = rand_forest(
  mode = "classification", 
  mtry = 3,
  trees = 100,
* min_n = 2
) %&gt;% set_engine(
  engine = "ranger",
  splitrule = "gini"
)
```
]

---
count: false

.col-left[
... and `ranger`
- Goal: Classification
- Three variables per split
- 100 trees in the forest
- At least 2 obs. to split
- Choose the `ranger` engine
]

.col-right[

```r
# Define the random forest
heart_rf = rand_forest(
  mode = "classification", 
  mtry = 3,
  trees = 100,
  min_n = 2
) %&gt;% set_engine(
* engine = "ranger",
  splitrule = "gini"
)
```
]

---
count: false

.col-left[
... and `ranger`
- Goal: Classification
- Three variables per split
- 100 trees in the forest
- At least 2 obs. to split
- Choose the `ranger` engine
- Set a [splitting rule](https://dials.tidymodels.org/reference/ranger_parameters.html)
]

.col-right[

```r
# Define the random forest
heart_rf = rand_forest(
  mode = "classification", 
  mtry = 3,
  trees = 100,
  min_n = 2
) %&gt;% set_engine(
  engine = "ranger",
* splitrule = "gini"
)
```
]

---
layout: false
class: clear

.note[Step 1:] Define our parameter grid


```r
# Define the parameter grid
rf_grid = expand_grid(
  mtry = 1:13,
  min_n = 1:15
)
```

---
class: clear

.note[Step 2:] Write a function that fits a RF using .b.orange[given hyperparameters].


```r
# Function: One set of hyperparam
rf_i = function(i) {
  # Define the random forest
  heart_rf_i = rand_forest(
    mode = "classification", 
*   mtry = rf_grid$mtry[i],
    trees = 100,
*   min_n = rf_grid$min_n[i]
  ) %&gt;% set_engine(engine = "ranger", splitrule = "gini")
  # Define workflow
  heart_rf_wf_i = 
    workflow() %&gt;% add_model(heart_rf_i) %&gt;% add_recipe(heart_recipe)
  # Fit
  heart_rf_fit_i = heart_rf_wf_i %&gt;% fit(heart_df)
  # Return DF w/ OOB error and the hyperparameters
  tibble(
    mtry = rf_grid$mtry[i],
    min_n = rf_grid$min_n[i],
    # Note: OOB error is buried
    error_oob = heart_rf_fit_i$fit$fit$fit$prediction.error
  )
}
```

---
layout: false
class: clear

.note[Step 3:] Fit all of the forests (in `parallel`)!


```r
# Fit the RFs on the grid
rf_tuning = mclapply(
  X = 1:nrow(rf_grid),
  FUN = rf_i,
  mc.cores = 12
) %&gt;% rbindlist()
```

---
layout: false
class: clear

.b[Accuracy] (OOB) across the grid of our parameters.

&lt;img src="008-slides_files/figure-html/plot-rf-parameters-1.svg" style="display: block; margin: auto;" /&gt;

---
class: clear
exclude: true

.col-left[

```r
# Read data
heart_df = read_csv("Heart.csv") %&gt;%
  dplyr::select(-1) %&gt;%
  rename(HeartDisease = AHD) %&gt;%
  clean_names()
# Impute missing values
heart_recipe = recipe(heart_disease ~ ., data = heart_df) %&gt;% 
  step_impute_median(all_predictors() &amp; all_numeric()) %&gt;% 
  step_impute_mode(all_predictors() &amp; all_nominal())
heart_df = heart_recipe %&gt;% prep() %&gt;% juice()
# Set the seed
set.seed(12345)
# Train the bagged trees
rf_oob = mclapply(
  X = 2:300,
  mc.cores = 12,
  FUN = function(n) {
    train(
      heart_disease ~ .,
      data = heart_df,
      method = "ranger",
      num.trees = n,
      trControl = trainControl(
        method = "oob"
      ),
      tuneGrid = data.frame(
        "mtry" = 2,
        "splitrule" = "gini",
        "min.node.size" = 4
      )
    )$finalModel$prediction.error %&gt;% subtract(1, .) %&gt;%
    data.frame(accuracy = ., n_trees = n)
  }
) %&gt;% bind_rows()
```
]

.col-right[

```r
# Set seed
set.seed(6789)
# Train the bagged trees
rf_cv = mclapply(
  X = 2:300,
  mc.cores = 12,
  FUN = function(n) {
    train(
      heart_disease ~ .,
      data = heart_df,
      method = "ranger",
      num.trees = n,
      trControl = trainControl(
        method = "cv",
        number = 5
      ),
      tuneGrid = data.frame(
        "mtry" = 2,
        "splitrule" = "gini",
        "min.node.size" = 4
      )
    )$finalModel$prediction.error %&gt;% subtract(1, .) %&gt;%
    data.frame(accuracy = ., n_trees = n)
  }
) %&gt;% bind_rows()
```
]

---
class: clear

.b[Tree ensembles and the number of trees]

&lt;img src="008-slides_files/figure-html/plot-bag-rf-1.svg" style="display: block; margin: auto;" /&gt;

---
layout: true
# Ensemble methods

---
name: boost-intro
## Boosting

So far, the elements of our ensembles have been acting independently:
&lt;br&gt; any single tree knows nothing about the rest of the forest.

--

.attn[Boosting] allows trees to pass on information to eachother.

--

Specifically, .attn[boosting] trains its trees.super[ðŸŒ²] .it[sequentially]â€”each new tree trains on the residuals (mistakes) from its predecessors.

.footnote[
ðŸŒ² As with bagging, boosting can be applied to many methods (in addition to trees).
]

--

- We add each new tree to our model `\(\hat{f}\)` (and update our residuals).

- Trees are typically smallâ€”slowly improving `\(\hat{f}\)` .it[where it struggles].

---
name: boost-param
## Boosting

Boosting has three .hi[tuning parameters].

1. The .hi[number of trees] `\(\color{#e64173}{B}\)` can be important to prevent overfitting.

--

1. The .hi[shrinkage parameter] `\(\color{#e64173}{\lambda}\)`, which controls boosting's .it[learning rate] (often 0.01 or 0.001).

--

1. The .hi[number of splits] `\(\color{#e64173}{d}\)` in each tree (trees' complexity).
--

  - Individual trees are typically shortâ€”often `\(d=1\)` ("stumps").

  - .note[Remember] Trees learn from predecessors' mistakes,&lt;br&gt;so no single tree needs to offer a perfect model.
---
name: boost-alg
## How to boost

.hi-purple[Step 1:] Set `\(\color{#6A5ACD}{\mathop{\hat{f}}}(x) = 0\)`, which yields residuals `\(r_i = y_i\)` for all `\(i\)`.

--

.hi-pink[Step 2:] For `\(\color{#e64173}{b} = 1,\,2\,\ldots,\, B\)` do:

.move-right[
.b[A.] Fit a tree `\(\color{#e64173}{\hat{f^b}}\)` with `\(d\)` splits.
]

--

.move-right[
.b[B.] Update the model `\(\color{#6A5ACD}{\hat{f}}\)` with "shrunken version" of new treee `\(\color{#e64173}{\hat{f^b}}\)`
]

$$
`\begin{align}
  \color{#6A5ACD}{\mathop{\hat{f}}}(x) \leftarrow \color{#6A5ACD}{\mathop{\hat{f}}}(x) + \lambda \mathop{\color{#e64173}{\hat{f^b}}}(x)
\end{align}`
$$

--

.move-right[
.b[C.] Update the residuals: `\(r_i \leftarrow r_i - \lambda \mathop{\color{#e64173}{\hat{f^b}}}(x)\)`.
]

--

.hi-orange[Step 3:] Output the boosted model:
`\(\mathop{\color{#6A5ACD}{\hat{f}}}(x) = \sum_{b} \lambda \mathop{\color{#e64173}{\hat{f^b}}}(x)\)`.
---
name: boost-r
## Boosting in R

We will use `parsnips`'s `boost_tree()` to train boosted trees..super[ðŸŒ´]

.footnote[
ðŸŒ´ This method uses the `xgboost` package.
]

`boost_tree()` takes several parameters you've seenâ€”plus one more:

1. `mtry` number of predictors to try at each split

1. `trees`, the number of trees `\((B)\)`

1. `min_n`, minimum observations to split

1. `tree_depth`, max. tree depth (max. splits from top)

1. `learn_rate`, the learning rate `\((\lambda)\)`

---
exclude: true


```r
# Set the seed
set.seed(12345)
# Train the random forest
heart_boost = train(
  heart_disease ~ .,
  data = heart_df,
  method = "gbm",
  trControl = trainControl(
    method = "cv",
    number = 5
  ),
  tuneGrid = expand.grid(
    "n.trees" = seq(1, 300, by = 1),
    "interaction.depth" = 1:3,
    "shrinkage" = c(0.1, 0.01, 0.001),
    "n.minobsinnode" = 5
  )
)
```

```
#&gt; 1 package is needed and is not installed. (gbm). Would you like to try to install it now?
#&gt; 1: yes
#&gt; 2: no
#&gt; 
#&gt; 
#&gt; The downloaded binary packages are in
#&gt; 	/var/folders/5g/5py69pv54w796mwsnl5vcfq80000gp/T//RtmpqZnJAY/downloaded_packages
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3789             nan     0.0010    0.0003
#&gt;      2        1.3784             nan     0.0010    0.0003
#&gt;      3        1.3778             nan     0.0010    0.0002
#&gt;      4        1.3773             nan     0.0010    0.0003
#&gt;      5        1.3767             nan     0.0010    0.0002
#&gt;      6        1.3761             nan     0.0010    0.0002
#&gt;      7        1.3757             nan     0.0010    0.0002
#&gt;      8        1.3751             nan     0.0010    0.0002
#&gt;      9        1.3745             nan     0.0010    0.0002
#&gt;     10        1.3740             nan     0.0010    0.0002
#&gt;     20        1.3688             nan     0.0010    0.0002
#&gt;     40        1.3582             nan     0.0010    0.0002
#&gt;     60        1.3486             nan     0.0010    0.0002
#&gt;     80        1.3391             nan     0.0010    0.0002
#&gt;    100        1.3295             nan     0.0010    0.0002
#&gt;    120        1.3198             nan     0.0010    0.0002
#&gt;    140        1.3106             nan     0.0010    0.0002
#&gt;    160        1.3016             nan     0.0010    0.0002
#&gt;    180        1.2932             nan     0.0010    0.0002
#&gt;    200        1.2847             nan     0.0010    0.0001
#&gt;    220        1.2761             nan     0.0010    0.0002
#&gt;    240        1.2679             nan     0.0010    0.0002
#&gt;    260        1.2597             nan     0.0010    0.0002
#&gt;    280        1.2516             nan     0.0010    0.0002
#&gt;    300        1.2441             nan     0.0010    0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3788             nan     0.0010    0.0003
#&gt;      2        1.3781             nan     0.0010    0.0003
#&gt;      3        1.3773             nan     0.0010    0.0003
#&gt;      4        1.3765             nan     0.0010    0.0003
#&gt;      5        1.3758             nan     0.0010    0.0004
#&gt;      6        1.3750             nan     0.0010    0.0003
#&gt;      7        1.3743             nan     0.0010    0.0003
#&gt;      8        1.3736             nan     0.0010    0.0003
#&gt;      9        1.3728             nan     0.0010    0.0003
#&gt;     10        1.3722             nan     0.0010    0.0003
#&gt;     20        1.3649             nan     0.0010    0.0003
#&gt;     40        1.3510             nan     0.0010    0.0003
#&gt;     60        1.3373             nan     0.0010    0.0003
#&gt;     80        1.3239             nan     0.0010    0.0003
#&gt;    100        1.3114             nan     0.0010    0.0003
#&gt;    120        1.2987             nan     0.0010    0.0002
#&gt;    140        1.2867             nan     0.0010    0.0003
#&gt;    160        1.2750             nan     0.0010    0.0003
#&gt;    180        1.2634             nan     0.0010    0.0002
#&gt;    200        1.2521             nan     0.0010    0.0003
#&gt;    220        1.2409             nan     0.0010    0.0002
#&gt;    240        1.2304             nan     0.0010    0.0002
#&gt;    260        1.2199             nan     0.0010    0.0002
#&gt;    280        1.2096             nan     0.0010    0.0002
#&gt;    300        1.1995             nan     0.0010    0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3785             nan     0.0010    0.0004
#&gt;      2        1.3777             nan     0.0010    0.0004
#&gt;      3        1.3767             nan     0.0010    0.0004
#&gt;      4        1.3759             nan     0.0010    0.0004
#&gt;      5        1.3750             nan     0.0010    0.0004
#&gt;      6        1.3743             nan     0.0010    0.0003
#&gt;      7        1.3734             nan     0.0010    0.0004
#&gt;      8        1.3725             nan     0.0010    0.0003
#&gt;      9        1.3717             nan     0.0010    0.0004
#&gt;     10        1.3707             nan     0.0010    0.0004
#&gt;     20        1.3626             nan     0.0010    0.0003
#&gt;     40        1.3455             nan     0.0010    0.0002
#&gt;     60        1.3298             nan     0.0010    0.0002
#&gt;     80        1.3144             nan     0.0010    0.0002
#&gt;    100        1.2997             nan     0.0010    0.0003
#&gt;    120        1.2850             nan     0.0010    0.0003
#&gt;    140        1.2711             nan     0.0010    0.0003
#&gt;    160        1.2577             nan     0.0010    0.0002
#&gt;    180        1.2439             nan     0.0010    0.0002
#&gt;    200        1.2309             nan     0.0010    0.0002
#&gt;    220        1.2179             nan     0.0010    0.0003
#&gt;    240        1.2055             nan     0.0010    0.0002
#&gt;    260        1.1935             nan     0.0010    0.0002
#&gt;    280        1.1817             nan     0.0010    0.0002
#&gt;    300        1.1702             nan     0.0010    0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3743             nan     0.0100    0.0025
#&gt;      2        1.3689             nan     0.0100    0.0025
#&gt;      3        1.3638             nan     0.0100    0.0025
#&gt;      4        1.3587             nan     0.0100    0.0023
#&gt;      5        1.3534             nan     0.0100    0.0023
#&gt;      6        1.3490             nan     0.0100    0.0022
#&gt;      7        1.3448             nan     0.0100    0.0018
#&gt;      8        1.3405             nan     0.0100    0.0017
#&gt;      9        1.3364             nan     0.0100    0.0017
#&gt;     10        1.3319             nan     0.0100    0.0024
#&gt;     20        1.2861             nan     0.0100    0.0021
#&gt;     40        1.2063             nan     0.0100    0.0016
#&gt;     60        1.1410             nan     0.0100    0.0013
#&gt;     80        1.0853             nan     0.0100    0.0011
#&gt;    100        1.0379             nan     0.0100    0.0006
#&gt;    120        0.9957             nan     0.0100    0.0008
#&gt;    140        0.9619             nan     0.0100    0.0007
#&gt;    160        0.9308             nan     0.0100    0.0004
#&gt;    180        0.9021             nan     0.0100    0.0005
#&gt;    200        0.8773             nan     0.0100    0.0004
#&gt;    220        0.8546             nan     0.0100    0.0001
#&gt;    240        0.8349             nan     0.0100   -0.0002
#&gt;    260        0.8163             nan     0.0100    0.0001
#&gt;    280        0.7977             nan     0.0100    0.0003
#&gt;    300        0.7823             nan     0.0100    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3721             nan     0.0100    0.0032
#&gt;      2        1.3651             nan     0.0100    0.0028
#&gt;      3        1.3584             nan     0.0100    0.0030
#&gt;      4        1.3518             nan     0.0100    0.0032
#&gt;      5        1.3451             nan     0.0100    0.0029
#&gt;      6        1.3378             nan     0.0100    0.0027
#&gt;      7        1.3310             nan     0.0100    0.0027
#&gt;      8        1.3236             nan     0.0100    0.0030
#&gt;      9        1.3166             nan     0.0100    0.0028
#&gt;     10        1.3108             nan     0.0100    0.0026
#&gt;     20        1.2511             nan     0.0100    0.0020
#&gt;     40        1.1560             nan     0.0100    0.0012
#&gt;     60        1.0728             nan     0.0100    0.0017
#&gt;     80        1.0024             nan     0.0100    0.0011
#&gt;    100        0.9466             nan     0.0100    0.0007
#&gt;    120        0.8970             nan     0.0100    0.0007
#&gt;    140        0.8553             nan     0.0100    0.0004
#&gt;    160        0.8201             nan     0.0100    0.0003
#&gt;    180        0.7901             nan     0.0100    0.0003
#&gt;    200        0.7633             nan     0.0100    0.0005
#&gt;    220        0.7384             nan     0.0100    0.0002
#&gt;    240        0.7178             nan     0.0100    0.0000
#&gt;    260        0.6975             nan     0.0100    0.0001
#&gt;    280        0.6794             nan     0.0100    0.0001
#&gt;    300        0.6622             nan     0.0100   -0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3711             nan     0.0100    0.0038
#&gt;      2        1.3631             nan     0.0100    0.0035
#&gt;      3        1.3550             nan     0.0100    0.0035
#&gt;      4        1.3481             nan     0.0100    0.0027
#&gt;      5        1.3410             nan     0.0100    0.0027
#&gt;      6        1.3322             nan     0.0100    0.0035
#&gt;      7        1.3232             nan     0.0100    0.0030
#&gt;      8        1.3151             nan     0.0100    0.0036
#&gt;      9        1.3080             nan     0.0100    0.0027
#&gt;     10        1.3004             nan     0.0100    0.0032
#&gt;     20        1.2307             nan     0.0100    0.0031
#&gt;     40        1.1166             nan     0.0100    0.0021
#&gt;     60        1.0272             nan     0.0100    0.0016
#&gt;     80        0.9544             nan     0.0100    0.0011
#&gt;    100        0.8921             nan     0.0100    0.0008
#&gt;    120        0.8418             nan     0.0100    0.0008
#&gt;    140        0.7982             nan     0.0100    0.0004
#&gt;    160        0.7582             nan     0.0100    0.0003
#&gt;    180        0.7245             nan     0.0100    0.0004
#&gt;    200        0.6943             nan     0.0100    0.0005
#&gt;    220        0.6671             nan     0.0100    0.0002
#&gt;    240        0.6453             nan     0.0100    0.0002
#&gt;    260        0.6244             nan     0.0100    0.0002
#&gt;    280        0.6052             nan     0.0100   -0.0001
#&gt;    300        0.5881             nan     0.0100   -0.0003
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3256             nan     0.1000    0.0224
#&gt;      2        1.2901             nan     0.1000    0.0121
#&gt;      3        1.2369             nan     0.1000    0.0193
#&gt;      4        1.2055             nan     0.1000    0.0129
#&gt;      5        1.1709             nan     0.1000    0.0171
#&gt;      6        1.1386             nan     0.1000    0.0136
#&gt;      7        1.1102             nan     0.1000    0.0136
#&gt;      8        1.0887             nan     0.1000    0.0077
#&gt;      9        1.0628             nan     0.1000    0.0099
#&gt;     10        1.0381             nan     0.1000    0.0089
#&gt;     20        0.8709             nan     0.1000    0.0044
#&gt;     40        0.7222             nan     0.1000    0.0005
#&gt;     60        0.6488             nan     0.1000    0.0010
#&gt;     80        0.5940             nan     0.1000   -0.0023
#&gt;    100        0.5579             nan     0.1000   -0.0019
#&gt;    120        0.5335             nan     0.1000   -0.0021
#&gt;    140        0.5083             nan     0.1000   -0.0021
#&gt;    160        0.4864             nan     0.1000   -0.0021
#&gt;    180        0.4620             nan     0.1000   -0.0020
#&gt;    200        0.4497             nan     0.1000   -0.0007
#&gt;    220        0.4433             nan     0.1000   -0.0016
#&gt;    240        0.4360             nan     0.1000   -0.0013
#&gt;    260        0.4233             nan     0.1000   -0.0011
#&gt;    280        0.4105             nan     0.1000   -0.0018
#&gt;    300        0.3961             nan     0.1000   -0.0032
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3080             nan     0.1000    0.0279
#&gt;      2        1.2508             nan     0.1000    0.0162
#&gt;      3        1.1915             nan     0.1000    0.0255
#&gt;      4        1.1473             nan     0.1000    0.0219
#&gt;      5        1.1061             nan     0.1000    0.0171
#&gt;      6        1.0639             nan     0.1000    0.0173
#&gt;      7        1.0319             nan     0.1000    0.0125
#&gt;      8        0.9988             nan     0.1000    0.0090
#&gt;      9        0.9691             nan     0.1000    0.0134
#&gt;     10        0.9403             nan     0.1000    0.0099
#&gt;     20        0.7631             nan     0.1000    0.0023
#&gt;     40        0.6010             nan     0.1000   -0.0018
#&gt;     60        0.5020             nan     0.1000    0.0002
#&gt;     80        0.4489             nan     0.1000   -0.0024
#&gt;    100        0.4023             nan     0.1000   -0.0015
#&gt;    120        0.3596             nan     0.1000   -0.0031
#&gt;    140        0.3224             nan     0.1000   -0.0019
#&gt;    160        0.2922             nan     0.1000   -0.0023
#&gt;    180        0.2700             nan     0.1000   -0.0019
#&gt;    200        0.2496             nan     0.1000   -0.0000
#&gt;    220        0.2306             nan     0.1000   -0.0009
#&gt;    240        0.2132             nan     0.1000   -0.0013
#&gt;    260        0.1954             nan     0.1000   -0.0015
#&gt;    280        0.1797             nan     0.1000   -0.0016
#&gt;    300        0.1661             nan     0.1000   -0.0012
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.2894             nan     0.1000    0.0348
#&gt;      2        1.2188             nan     0.1000    0.0264
#&gt;      3        1.1611             nan     0.1000    0.0244
#&gt;      4        1.1102             nan     0.1000    0.0229
#&gt;      5        1.0717             nan     0.1000    0.0073
#&gt;      6        1.0299             nan     0.1000    0.0140
#&gt;      7        0.9893             nan     0.1000    0.0127
#&gt;      8        0.9543             nan     0.1000    0.0121
#&gt;      9        0.9208             nan     0.1000    0.0102
#&gt;     10        0.8992             nan     0.1000    0.0039
#&gt;     20        0.6925             nan     0.1000   -0.0009
#&gt;     40        0.5036             nan     0.1000   -0.0003
#&gt;     60        0.4148             nan     0.1000   -0.0015
#&gt;     80        0.3437             nan     0.1000   -0.0017
#&gt;    100        0.2907             nan     0.1000   -0.0035
#&gt;    120        0.2463             nan     0.1000   -0.0017
#&gt;    140        0.2135             nan     0.1000   -0.0012
#&gt;    160        0.1886             nan     0.1000   -0.0022
#&gt;    180        0.1668             nan     0.1000   -0.0005
#&gt;    200        0.1488             nan     0.1000   -0.0010
#&gt;    220        0.1309             nan     0.1000   -0.0016
#&gt;    240        0.1148             nan     0.1000   -0.0009
#&gt;    260        0.1011             nan     0.1000   -0.0009
#&gt;    280        0.0895             nan     0.1000   -0.0006
#&gt;    300        0.0816             nan     0.1000   -0.0006
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3788             nan     0.0010    0.0003
#&gt;      2        1.3782             nan     0.0010    0.0003
#&gt;      3        1.3776             nan     0.0010    0.0003
#&gt;      4        1.3771             nan     0.0010    0.0003
#&gt;      5        1.3764             nan     0.0010    0.0003
#&gt;      6        1.3758             nan     0.0010    0.0003
#&gt;      7        1.3751             nan     0.0010    0.0003
#&gt;      8        1.3745             nan     0.0010    0.0003
#&gt;      9        1.3739             nan     0.0010    0.0003
#&gt;     10        1.3735             nan     0.0010    0.0001
#&gt;     20        1.3672             nan     0.0010    0.0003
#&gt;     40        1.3554             nan     0.0010    0.0003
#&gt;     60        1.3438             nan     0.0010    0.0003
#&gt;     80        1.3327             nan     0.0010    0.0002
#&gt;    100        1.3220             nan     0.0010    0.0003
#&gt;    120        1.3125             nan     0.0010    0.0003
#&gt;    140        1.3028             nan     0.0010    0.0002
#&gt;    160        1.2929             nan     0.0010    0.0002
#&gt;    180        1.2840             nan     0.0010    0.0002
#&gt;    200        1.2747             nan     0.0010    0.0002
#&gt;    220        1.2662             nan     0.0010    0.0002
#&gt;    240        1.2577             nan     0.0010    0.0001
#&gt;    260        1.2491             nan     0.0010    0.0001
#&gt;    280        1.2415             nan     0.0010    0.0001
#&gt;    300        1.2335             nan     0.0010    0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3786             nan     0.0010    0.0003
#&gt;      2        1.3780             nan     0.0010    0.0004
#&gt;      3        1.3772             nan     0.0010    0.0003
#&gt;      4        1.3765             nan     0.0010    0.0003
#&gt;      5        1.3757             nan     0.0010    0.0003
#&gt;      6        1.3749             nan     0.0010    0.0004
#&gt;      7        1.3741             nan     0.0010    0.0003
#&gt;      8        1.3734             nan     0.0010    0.0004
#&gt;      9        1.3726             nan     0.0010    0.0003
#&gt;     10        1.3718             nan     0.0010    0.0003
#&gt;     20        1.3643             nan     0.0010    0.0003
#&gt;     40        1.3504             nan     0.0010    0.0003
#&gt;     60        1.3369             nan     0.0010    0.0003
#&gt;     80        1.3236             nan     0.0010    0.0003
#&gt;    100        1.3106             nan     0.0010    0.0003
#&gt;    120        1.2980             nan     0.0010    0.0003
#&gt;    140        1.2860             nan     0.0010    0.0002
#&gt;    160        1.2741             nan     0.0010    0.0003
#&gt;    180        1.2627             nan     0.0010    0.0003
#&gt;    200        1.2521             nan     0.0010    0.0002
#&gt;    220        1.2410             nan     0.0010    0.0002
#&gt;    240        1.2312             nan     0.0010    0.0002
#&gt;    260        1.2210             nan     0.0010    0.0001
#&gt;    280        1.2112             nan     0.0010    0.0002
#&gt;    300        1.2016             nan     0.0010    0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3786             nan     0.0010    0.0003
#&gt;      2        1.3779             nan     0.0010    0.0003
#&gt;      3        1.3770             nan     0.0010    0.0003
#&gt;      4        1.3762             nan     0.0010    0.0003
#&gt;      5        1.3754             nan     0.0010    0.0004
#&gt;      6        1.3746             nan     0.0010    0.0004
#&gt;      7        1.3738             nan     0.0010    0.0004
#&gt;      8        1.3730             nan     0.0010    0.0004
#&gt;      9        1.3721             nan     0.0010    0.0004
#&gt;     10        1.3712             nan     0.0010    0.0004
#&gt;     20        1.3628             nan     0.0010    0.0003
#&gt;     40        1.3467             nan     0.0010    0.0003
#&gt;     60        1.3309             nan     0.0010    0.0004
#&gt;     80        1.3159             nan     0.0010    0.0003
#&gt;    100        1.3013             nan     0.0010    0.0003
#&gt;    120        1.2871             nan     0.0010    0.0003
#&gt;    140        1.2732             nan     0.0010    0.0003
#&gt;    160        1.2602             nan     0.0010    0.0003
#&gt;    180        1.2473             nan     0.0010    0.0002
#&gt;    200        1.2347             nan     0.0010    0.0002
#&gt;    220        1.2228             nan     0.0010    0.0002
#&gt;    240        1.2108             nan     0.0010    0.0002
#&gt;    260        1.1990             nan     0.0010    0.0002
#&gt;    280        1.1876             nan     0.0010    0.0002
#&gt;    300        1.1764             nan     0.0010    0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3741             nan     0.0100    0.0031
#&gt;      2        1.3679             nan     0.0100    0.0032
#&gt;      3        1.3610             nan     0.0100    0.0031
#&gt;      4        1.3556             nan     0.0100    0.0026
#&gt;      5        1.3504             nan     0.0100    0.0017
#&gt;      6        1.3444             nan     0.0100    0.0029
#&gt;      7        1.3388             nan     0.0100    0.0025
#&gt;      8        1.3329             nan     0.0100    0.0028
#&gt;      9        1.3292             nan     0.0100    0.0021
#&gt;     10        1.3236             nan     0.0100    0.0021
#&gt;     20        1.2713             nan     0.0100    0.0019
#&gt;     40        1.1987             nan     0.0100    0.0010
#&gt;     60        1.1360             nan     0.0100    0.0009
#&gt;     80        1.0841             nan     0.0100    0.0009
#&gt;    100        1.0413             nan     0.0100    0.0007
#&gt;    120        1.0040             nan     0.0100    0.0004
#&gt;    140        0.9733             nan     0.0100    0.0004
#&gt;    160        0.9450             nan     0.0100    0.0006
#&gt;    180        0.9196             nan     0.0100    0.0002
#&gt;    200        0.8987             nan     0.0100    0.0001
#&gt;    220        0.8800             nan     0.0100    0.0002
#&gt;    240        0.8626             nan     0.0100    0.0001
#&gt;    260        0.8479             nan     0.0100    0.0001
#&gt;    280        0.8327             nan     0.0100    0.0002
#&gt;    300        0.8213             nan     0.0100    0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3723             nan     0.0100    0.0037
#&gt;      2        1.3658             nan     0.0100    0.0017
#&gt;      3        1.3588             nan     0.0100    0.0033
#&gt;      4        1.3519             nan     0.0100    0.0033
#&gt;      5        1.3450             nan     0.0100    0.0034
#&gt;      6        1.3377             nan     0.0100    0.0027
#&gt;      7        1.3311             nan     0.0100    0.0032
#&gt;      8        1.3264             nan     0.0100    0.0020
#&gt;      9        1.3195             nan     0.0100    0.0033
#&gt;     10        1.3146             nan     0.0100    0.0021
#&gt;     20        1.2547             nan     0.0100    0.0024
#&gt;     40        1.1567             nan     0.0100    0.0017
#&gt;     60        1.0820             nan     0.0100    0.0013
#&gt;     80        1.0185             nan     0.0100    0.0011
#&gt;    100        0.9689             nan     0.0100    0.0008
#&gt;    120        0.9257             nan     0.0100    0.0004
#&gt;    140        0.8878             nan     0.0100    0.0005
#&gt;    160        0.8561             nan     0.0100    0.0006
#&gt;    180        0.8282             nan     0.0100    0.0002
#&gt;    200        0.8047             nan     0.0100   -0.0001
#&gt;    220        0.7846             nan     0.0100    0.0001
#&gt;    240        0.7650             nan     0.0100   -0.0003
#&gt;    260        0.7497             nan     0.0100    0.0000
#&gt;    280        0.7326             nan     0.0100    0.0002
#&gt;    300        0.7169             nan     0.0100    0.0003
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3712             nan     0.0100    0.0037
#&gt;      2        1.3627             nan     0.0100    0.0037
#&gt;      3        1.3548             nan     0.0100    0.0034
#&gt;      4        1.3477             nan     0.0100    0.0032
#&gt;      5        1.3397             nan     0.0100    0.0027
#&gt;      6        1.3312             nan     0.0100    0.0033
#&gt;      7        1.3234             nan     0.0100    0.0034
#&gt;      8        1.3155             nan     0.0100    0.0034
#&gt;      9        1.3092             nan     0.0100    0.0031
#&gt;     10        1.3015             nan     0.0100    0.0033
#&gt;     20        1.2337             nan     0.0100    0.0026
#&gt;     40        1.1297             nan     0.0100    0.0015
#&gt;     60        1.0470             nan     0.0100    0.0021
#&gt;     80        0.9771             nan     0.0100    0.0009
#&gt;    100        0.9222             nan     0.0100    0.0009
#&gt;    120        0.8747             nan     0.0100    0.0005
#&gt;    140        0.8336             nan     0.0100    0.0007
#&gt;    160        0.7973             nan     0.0100    0.0003
#&gt;    180        0.7662             nan     0.0100    0.0000
#&gt;    200        0.7385             nan     0.0100    0.0001
#&gt;    220        0.7164             nan     0.0100   -0.0002
#&gt;    240        0.6957             nan     0.0100   -0.0000
#&gt;    260        0.6759             nan     0.0100   -0.0003
#&gt;    280        0.6592             nan     0.0100   -0.0002
#&gt;    300        0.6433             nan     0.0100    0.0000
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3160             nan     0.1000    0.0307
#&gt;      2        1.2688             nan     0.1000    0.0245
#&gt;      3        1.2404             nan     0.1000    0.0120
#&gt;      4        1.2127             nan     0.1000    0.0102
#&gt;      5        1.1765             nan     0.1000    0.0180
#&gt;      6        1.1425             nan     0.1000    0.0139
#&gt;      7        1.1207             nan     0.1000    0.0050
#&gt;      8        1.0924             nan     0.1000    0.0133
#&gt;      9        1.0688             nan     0.1000    0.0056
#&gt;     10        1.0477             nan     0.1000    0.0106
#&gt;     20        0.9010             nan     0.1000    0.0052
#&gt;     40        0.7725             nan     0.1000   -0.0020
#&gt;     60        0.7098             nan     0.1000   -0.0004
#&gt;     80        0.6683             nan     0.1000   -0.0038
#&gt;    100        0.6377             nan     0.1000   -0.0015
#&gt;    120        0.6139             nan     0.1000   -0.0020
#&gt;    140        0.5907             nan     0.1000   -0.0003
#&gt;    160        0.5720             nan     0.1000   -0.0013
#&gt;    180        0.5581             nan     0.1000   -0.0007
#&gt;    200        0.5423             nan     0.1000   -0.0020
#&gt;    220        0.5285             nan     0.1000   -0.0008
#&gt;    240        0.5220             nan     0.1000   -0.0028
#&gt;    260        0.5074             nan     0.1000   -0.0004
#&gt;    280        0.4970             nan     0.1000   -0.0022
#&gt;    300        0.4917             nan     0.1000   -0.0025
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3056             nan     0.1000    0.0331
#&gt;      2        1.2552             nan     0.1000    0.0191
#&gt;      3        1.1962             nan     0.1000    0.0234
#&gt;      4        1.1519             nan     0.1000    0.0174
#&gt;      5        1.1183             nan     0.1000    0.0094
#&gt;      6        1.0796             nan     0.1000    0.0140
#&gt;      7        1.0469             nan     0.1000    0.0106
#&gt;      8        1.0200             nan     0.1000    0.0105
#&gt;      9        0.9930             nan     0.1000    0.0082
#&gt;     10        0.9664             nan     0.1000    0.0092
#&gt;     20        0.8026             nan     0.1000    0.0005
#&gt;     40        0.6610             nan     0.1000   -0.0003
#&gt;     60        0.5878             nan     0.1000   -0.0026
#&gt;     80        0.5259             nan     0.1000   -0.0023
#&gt;    100        0.4881             nan     0.1000   -0.0020
#&gt;    120        0.4477             nan     0.1000   -0.0030
#&gt;    140        0.4215             nan     0.1000   -0.0019
#&gt;    160        0.3942             nan     0.1000   -0.0031
#&gt;    180        0.3657             nan     0.1000   -0.0007
#&gt;    200        0.3415             nan     0.1000   -0.0017
#&gt;    220        0.3241             nan     0.1000   -0.0021
#&gt;    240        0.3061             nan     0.1000   -0.0011
#&gt;    260        0.2863             nan     0.1000   -0.0032
#&gt;    280        0.2678             nan     0.1000   -0.0014
#&gt;    300        0.2521             nan     0.1000   -0.0020
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.2916             nan     0.1000    0.0386
#&gt;      2        1.2245             nan     0.1000    0.0296
#&gt;      3        1.1656             nan     0.1000    0.0268
#&gt;      4        1.1110             nan     0.1000    0.0144
#&gt;      5        1.0679             nan     0.1000    0.0142
#&gt;      6        1.0252             nan     0.1000    0.0144
#&gt;      7        0.9897             nan     0.1000    0.0124
#&gt;      8        0.9729             nan     0.1000   -0.0008
#&gt;      9        0.9469             nan     0.1000    0.0076
#&gt;     10        0.9296             nan     0.1000    0.0007
#&gt;     20        0.7427             nan     0.1000    0.0027
#&gt;     40        0.5822             nan     0.1000   -0.0016
#&gt;     60        0.4878             nan     0.1000   -0.0034
#&gt;     80        0.4210             nan     0.1000   -0.0028
#&gt;    100        0.3702             nan     0.1000   -0.0024
#&gt;    120        0.3286             nan     0.1000   -0.0012
#&gt;    140        0.2951             nan     0.1000   -0.0043
#&gt;    160        0.2642             nan     0.1000   -0.0014
#&gt;    180        0.2343             nan     0.1000   -0.0009
#&gt;    200        0.2086             nan     0.1000   -0.0007
#&gt;    220        0.1896             nan     0.1000   -0.0016
#&gt;    240        0.1725             nan     0.1000   -0.0010
#&gt;    260        0.1583             nan     0.1000   -0.0007
#&gt;    280        0.1454             nan     0.1000   -0.0002
#&gt;    300        0.1315             nan     0.1000   -0.0010
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3790             nan     0.0010    0.0002
#&gt;      2        1.3784             nan     0.0010    0.0003
#&gt;      3        1.3779             nan     0.0010    0.0002
#&gt;      4        1.3773             nan     0.0010    0.0002
#&gt;      5        1.3766             nan     0.0010    0.0003
#&gt;      6        1.3760             nan     0.0010    0.0003
#&gt;      7        1.3756             nan     0.0010    0.0001
#&gt;      8        1.3751             nan     0.0010    0.0003
#&gt;      9        1.3746             nan     0.0010    0.0002
#&gt;     10        1.3740             nan     0.0010    0.0003
#&gt;     20        1.3686             nan     0.0010    0.0003
#&gt;     40        1.3581             nan     0.0010    0.0001
#&gt;     60        1.3476             nan     0.0010    0.0002
#&gt;     80        1.3372             nan     0.0010    0.0002
#&gt;    100        1.3276             nan     0.0010    0.0002
#&gt;    120        1.3182             nan     0.0010    0.0002
#&gt;    140        1.3092             nan     0.0010    0.0002
#&gt;    160        1.3003             nan     0.0010    0.0001
#&gt;    180        1.2916             nan     0.0010    0.0002
#&gt;    200        1.2831             nan     0.0010    0.0002
#&gt;    220        1.2750             nan     0.0010    0.0002
#&gt;    240        1.2670             nan     0.0010    0.0002
#&gt;    260        1.2588             nan     0.0010    0.0002
#&gt;    280        1.2510             nan     0.0010    0.0002
#&gt;    300        1.2433             nan     0.0010    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3788             nan     0.0010    0.0003
#&gt;      2        1.3782             nan     0.0010    0.0002
#&gt;      3        1.3775             nan     0.0010    0.0003
#&gt;      4        1.3768             nan     0.0010    0.0003
#&gt;      5        1.3762             nan     0.0010    0.0003
#&gt;      6        1.3755             nan     0.0010    0.0002
#&gt;      7        1.3747             nan     0.0010    0.0003
#&gt;      8        1.3740             nan     0.0010    0.0003
#&gt;      9        1.3734             nan     0.0010    0.0002
#&gt;     10        1.3728             nan     0.0010    0.0003
#&gt;     20        1.3662             nan     0.0010    0.0003
#&gt;     40        1.3527             nan     0.0010    0.0003
#&gt;     60        1.3395             nan     0.0010    0.0003
#&gt;     80        1.3265             nan     0.0010    0.0002
#&gt;    100        1.3137             nan     0.0010    0.0003
#&gt;    120        1.3010             nan     0.0010    0.0003
#&gt;    140        1.2891             nan     0.0010    0.0002
#&gt;    160        1.2775             nan     0.0010    0.0002
#&gt;    180        1.2667             nan     0.0010    0.0001
#&gt;    200        1.2556             nan     0.0010    0.0002
#&gt;    220        1.2449             nan     0.0010    0.0002
#&gt;    240        1.2347             nan     0.0010    0.0002
#&gt;    260        1.2248             nan     0.0010    0.0002
#&gt;    280        1.2148             nan     0.0010    0.0002
#&gt;    300        1.2052             nan     0.0010    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3787             nan     0.0010    0.0003
#&gt;      2        1.3779             nan     0.0010    0.0004
#&gt;      3        1.3770             nan     0.0010    0.0003
#&gt;      4        1.3762             nan     0.0010    0.0003
#&gt;      5        1.3754             nan     0.0010    0.0004
#&gt;      6        1.3746             nan     0.0010    0.0004
#&gt;      7        1.3738             nan     0.0010    0.0004
#&gt;      8        1.3729             nan     0.0010    0.0004
#&gt;      9        1.3721             nan     0.0010    0.0004
#&gt;     10        1.3713             nan     0.0010    0.0003
#&gt;     20        1.3632             nan     0.0010    0.0003
#&gt;     40        1.3476             nan     0.0010    0.0003
#&gt;     60        1.3325             nan     0.0010    0.0004
#&gt;     80        1.3177             nan     0.0010    0.0003
#&gt;    100        1.3029             nan     0.0010    0.0003
#&gt;    120        1.2892             nan     0.0010    0.0002
#&gt;    140        1.2758             nan     0.0010    0.0002
#&gt;    160        1.2627             nan     0.0010    0.0003
#&gt;    180        1.2497             nan     0.0010    0.0003
#&gt;    200        1.2373             nan     0.0010    0.0002
#&gt;    220        1.2255             nan     0.0010    0.0003
#&gt;    240        1.2137             nan     0.0010    0.0003
#&gt;    260        1.2020             nan     0.0010    0.0002
#&gt;    280        1.1904             nan     0.0010    0.0002
#&gt;    300        1.1794             nan     0.0010    0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3732             nan     0.0100    0.0027
#&gt;      2        1.3677             nan     0.0100    0.0027
#&gt;      3        1.3629             nan     0.0100    0.0012
#&gt;      4        1.3575             nan     0.0100    0.0023
#&gt;      5        1.3538             nan     0.0100    0.0013
#&gt;      6        1.3479             nan     0.0100    0.0025
#&gt;      7        1.3432             nan     0.0100    0.0025
#&gt;      8        1.3382             nan     0.0100    0.0024
#&gt;      9        1.3341             nan     0.0100    0.0013
#&gt;     10        1.3303             nan     0.0100    0.0011
#&gt;     20        1.2862             nan     0.0100    0.0020
#&gt;     40        1.2106             nan     0.0100    0.0013
#&gt;     60        1.1495             nan     0.0100    0.0011
#&gt;     80        1.0980             nan     0.0100    0.0009
#&gt;    100        1.0529             nan     0.0100    0.0008
#&gt;    120        1.0167             nan     0.0100    0.0007
#&gt;    140        0.9843             nan     0.0100    0.0004
#&gt;    160        0.9573             nan     0.0100    0.0004
#&gt;    180        0.9320             nan     0.0100    0.0002
#&gt;    200        0.9099             nan     0.0100    0.0004
#&gt;    220        0.8894             nan     0.0100    0.0003
#&gt;    240        0.8721             nan     0.0100   -0.0001
#&gt;    260        0.8563             nan     0.0100    0.0001
#&gt;    280        0.8403             nan     0.0100    0.0000
#&gt;    300        0.8276             nan     0.0100    0.0000
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3719             nan     0.0100    0.0034
#&gt;      2        1.3644             nan     0.0100    0.0027
#&gt;      3        1.3575             nan     0.0100    0.0031
#&gt;      4        1.3512             nan     0.0100    0.0026
#&gt;      5        1.3441             nan     0.0100    0.0034
#&gt;      6        1.3378             nan     0.0100    0.0026
#&gt;      7        1.3318             nan     0.0100    0.0025
#&gt;      8        1.3249             nan     0.0100    0.0024
#&gt;      9        1.3190             nan     0.0100    0.0029
#&gt;     10        1.3136             nan     0.0100    0.0027
#&gt;     20        1.2572             nan     0.0100    0.0022
#&gt;     40        1.1606             nan     0.0100    0.0018
#&gt;     60        1.0869             nan     0.0100    0.0014
#&gt;     80        1.0233             nan     0.0100    0.0010
#&gt;    100        0.9709             nan     0.0100    0.0007
#&gt;    120        0.9272             nan     0.0100    0.0005
#&gt;    140        0.8880             nan     0.0100    0.0007
#&gt;    160        0.8536             nan     0.0100    0.0004
#&gt;    180        0.8228             nan     0.0100    0.0003
#&gt;    200        0.7975             nan     0.0100    0.0002
#&gt;    220        0.7747             nan     0.0100   -0.0000
#&gt;    240        0.7528             nan     0.0100    0.0002
#&gt;    260        0.7325             nan     0.0100    0.0000
#&gt;    280        0.7148             nan     0.0100    0.0002
#&gt;    300        0.6992             nan     0.0100    0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3714             nan     0.0100    0.0035
#&gt;      2        1.3637             nan     0.0100    0.0031
#&gt;      3        1.3572             nan     0.0100    0.0028
#&gt;      4        1.3490             nan     0.0100    0.0034
#&gt;      5        1.3420             nan     0.0100    0.0029
#&gt;      6        1.3346             nan     0.0100    0.0034
#&gt;      7        1.3269             nan     0.0100    0.0033
#&gt;      8        1.3191             nan     0.0100    0.0030
#&gt;      9        1.3123             nan     0.0100    0.0031
#&gt;     10        1.3051             nan     0.0100    0.0027
#&gt;     20        1.2385             nan     0.0100    0.0021
#&gt;     40        1.1259             nan     0.0100    0.0012
#&gt;     60        1.0405             nan     0.0100    0.0014
#&gt;     80        0.9687             nan     0.0100    0.0010
#&gt;    100        0.9114             nan     0.0100    0.0007
#&gt;    120        0.8619             nan     0.0100    0.0002
#&gt;    140        0.8184             nan     0.0100    0.0004
#&gt;    160        0.7825             nan     0.0100    0.0007
#&gt;    180        0.7488             nan     0.0100    0.0006
#&gt;    200        0.7201             nan     0.0100   -0.0000
#&gt;    220        0.6954             nan     0.0100   -0.0001
#&gt;    240        0.6729             nan     0.0100    0.0002
#&gt;    260        0.6504             nan     0.0100   -0.0003
#&gt;    280        0.6319             nan     0.0100    0.0000
#&gt;    300        0.6138             nan     0.0100   -0.0003
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3203             nan     0.1000    0.0213
#&gt;      2        1.2744             nan     0.1000    0.0171
#&gt;      3        1.2347             nan     0.1000    0.0193
#&gt;      4        1.2056             nan     0.1000    0.0102
#&gt;      5        1.1638             nan     0.1000    0.0138
#&gt;      6        1.1321             nan     0.1000    0.0087
#&gt;      7        1.0982             nan     0.1000    0.0112
#&gt;      8        1.0728             nan     0.1000    0.0098
#&gt;      9        1.0555             nan     0.1000    0.0081
#&gt;     10        1.0388             nan     0.1000    0.0062
#&gt;     20        0.9076             nan     0.1000   -0.0010
#&gt;     40        0.7698             nan     0.1000   -0.0003
#&gt;     60        0.7099             nan     0.1000    0.0011
#&gt;     80        0.6602             nan     0.1000   -0.0019
#&gt;    100        0.6201             nan     0.1000   -0.0007
#&gt;    120        0.5844             nan     0.1000   -0.0009
#&gt;    140        0.5694             nan     0.1000   -0.0013
#&gt;    160        0.5540             nan     0.1000   -0.0028
#&gt;    180        0.5323             nan     0.1000   -0.0021
#&gt;    200        0.5190             nan     0.1000   -0.0026
#&gt;    220        0.5047             nan     0.1000   -0.0028
#&gt;    240        0.4899             nan     0.1000    0.0004
#&gt;    260        0.4829             nan     0.1000   -0.0045
#&gt;    280        0.4664             nan     0.1000   -0.0028
#&gt;    300        0.4565             nan     0.1000   -0.0042
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.2990             nan     0.1000    0.0328
#&gt;      2        1.2442             nan     0.1000    0.0219
#&gt;      3        1.1939             nan     0.1000    0.0202
#&gt;      4        1.1515             nan     0.1000    0.0194
#&gt;      5        1.1088             nan     0.1000    0.0171
#&gt;      6        1.0744             nan     0.1000    0.0106
#&gt;      7        1.0433             nan     0.1000    0.0111
#&gt;      8        1.0136             nan     0.1000    0.0091
#&gt;      9        0.9908             nan     0.1000    0.0078
#&gt;     10        0.9697             nan     0.1000    0.0084
#&gt;     20        0.8006             nan     0.1000    0.0052
#&gt;     40        0.6557             nan     0.1000   -0.0008
#&gt;     60        0.5613             nan     0.1000   -0.0010
#&gt;     80        0.5066             nan     0.1000   -0.0010
#&gt;    100        0.4532             nan     0.1000    0.0004
#&gt;    120        0.4087             nan     0.1000   -0.0016
#&gt;    140        0.3820             nan     0.1000   -0.0017
#&gt;    160        0.3488             nan     0.1000   -0.0011
#&gt;    180        0.3177             nan     0.1000   -0.0022
#&gt;    200        0.2914             nan     0.1000   -0.0024
#&gt;    220        0.2718             nan     0.1000   -0.0008
#&gt;    240        0.2544             nan     0.1000   -0.0012
#&gt;    260        0.2407             nan     0.1000   -0.0016
#&gt;    280        0.2258             nan     0.1000   -0.0025
#&gt;    300        0.2145             nan     0.1000   -0.0009
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3017             nan     0.1000    0.0286
#&gt;      2        1.2365             nan     0.1000    0.0259
#&gt;      3        1.1764             nan     0.1000    0.0216
#&gt;      4        1.1179             nan     0.1000    0.0166
#&gt;      5        1.0735             nan     0.1000    0.0153
#&gt;      6        1.0257             nan     0.1000    0.0227
#&gt;      7        0.9861             nan     0.1000    0.0158
#&gt;      8        0.9569             nan     0.1000    0.0090
#&gt;      9        0.9250             nan     0.1000    0.0113
#&gt;     10        0.8992             nan     0.1000    0.0088
#&gt;     20        0.7127             nan     0.1000    0.0030
#&gt;     40        0.5468             nan     0.1000   -0.0027
#&gt;     60        0.4531             nan     0.1000   -0.0034
#&gt;     80        0.3779             nan     0.1000   -0.0005
#&gt;    100        0.3191             nan     0.1000   -0.0011
#&gt;    120        0.2791             nan     0.1000   -0.0026
#&gt;    140        0.2448             nan     0.1000   -0.0026
#&gt;    160        0.2166             nan     0.1000   -0.0019
#&gt;    180        0.1951             nan     0.1000   -0.0009
#&gt;    200        0.1741             nan     0.1000   -0.0011
#&gt;    220        0.1563             nan     0.1000   -0.0005
#&gt;    240        0.1423             nan     0.1000   -0.0011
#&gt;    260        0.1276             nan     0.1000   -0.0008
#&gt;    280        0.1183             nan     0.1000   -0.0016
#&gt;    300        0.1056             nan     0.1000   -0.0007
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3791             nan     0.0010    0.0002
#&gt;      2        1.3787             nan     0.0010    0.0002
#&gt;      3        1.3782             nan     0.0010    0.0002
#&gt;      4        1.3777             nan     0.0010    0.0002
#&gt;      5        1.3773             nan     0.0010    0.0002
#&gt;      6        1.3767             nan     0.0010    0.0002
#&gt;      7        1.3762             nan     0.0010    0.0002
#&gt;      8        1.3757             nan     0.0010    0.0002
#&gt;      9        1.3752             nan     0.0010    0.0003
#&gt;     10        1.3747             nan     0.0010    0.0003
#&gt;     20        1.3698             nan     0.0010    0.0002
#&gt;     40        1.3600             nan     0.0010    0.0002
#&gt;     60        1.3500             nan     0.0010    0.0002
#&gt;     80        1.3410             nan     0.0010    0.0002
#&gt;    100        1.3318             nan     0.0010    0.0002
#&gt;    120        1.3233             nan     0.0010    0.0002
#&gt;    140        1.3146             nan     0.0010    0.0002
#&gt;    160        1.3065             nan     0.0010    0.0002
#&gt;    180        1.2979             nan     0.0010    0.0002
#&gt;    200        1.2897             nan     0.0010    0.0002
#&gt;    220        1.2816             nan     0.0010    0.0002
#&gt;    240        1.2733             nan     0.0010    0.0002
#&gt;    260        1.2657             nan     0.0010    0.0002
#&gt;    280        1.2585             nan     0.0010    0.0002
#&gt;    300        1.2514             nan     0.0010    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3789             nan     0.0010    0.0003
#&gt;      2        1.3783             nan     0.0010    0.0003
#&gt;      3        1.3775             nan     0.0010    0.0003
#&gt;      4        1.3767             nan     0.0010    0.0003
#&gt;      5        1.3761             nan     0.0010    0.0003
#&gt;      6        1.3753             nan     0.0010    0.0003
#&gt;      7        1.3747             nan     0.0010    0.0003
#&gt;      8        1.3740             nan     0.0010    0.0003
#&gt;      9        1.3734             nan     0.0010    0.0002
#&gt;     10        1.3727             nan     0.0010    0.0003
#&gt;     20        1.3660             nan     0.0010    0.0002
#&gt;     40        1.3531             nan     0.0010    0.0003
#&gt;     60        1.3405             nan     0.0010    0.0002
#&gt;     80        1.3279             nan     0.0010    0.0003
#&gt;    100        1.3161             nan     0.0010    0.0001
#&gt;    120        1.3043             nan     0.0010    0.0002
#&gt;    140        1.2931             nan     0.0010    0.0003
#&gt;    160        1.2821             nan     0.0010    0.0002
#&gt;    180        1.2709             nan     0.0010    0.0003
#&gt;    200        1.2605             nan     0.0010    0.0002
#&gt;    220        1.2505             nan     0.0010    0.0002
#&gt;    240        1.2403             nan     0.0010    0.0002
#&gt;    260        1.2306             nan     0.0010    0.0001
#&gt;    280        1.2206             nan     0.0010    0.0002
#&gt;    300        1.2113             nan     0.0010    0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3787             nan     0.0010    0.0003
#&gt;      2        1.3779             nan     0.0010    0.0004
#&gt;      3        1.3771             nan     0.0010    0.0004
#&gt;      4        1.3762             nan     0.0010    0.0004
#&gt;      5        1.3755             nan     0.0010    0.0004
#&gt;      6        1.3748             nan     0.0010    0.0002
#&gt;      7        1.3740             nan     0.0010    0.0003
#&gt;      8        1.3733             nan     0.0010    0.0003
#&gt;      9        1.3725             nan     0.0010    0.0003
#&gt;     10        1.3717             nan     0.0010    0.0003
#&gt;     20        1.3637             nan     0.0010    0.0003
#&gt;     40        1.3487             nan     0.0010    0.0003
#&gt;     60        1.3340             nan     0.0010    0.0003
#&gt;     80        1.3196             nan     0.0010    0.0002
#&gt;    100        1.3056             nan     0.0010    0.0003
#&gt;    120        1.2927             nan     0.0010    0.0002
#&gt;    140        1.2792             nan     0.0010    0.0002
#&gt;    160        1.2663             nan     0.0010    0.0003
#&gt;    180        1.2534             nan     0.0010    0.0002
#&gt;    200        1.2415             nan     0.0010    0.0002
#&gt;    220        1.2294             nan     0.0010    0.0002
#&gt;    240        1.2174             nan     0.0010    0.0003
#&gt;    260        1.2063             nan     0.0010    0.0002
#&gt;    280        1.1955             nan     0.0010    0.0002
#&gt;    300        1.1850             nan     0.0010    0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3746             nan     0.0100    0.0025
#&gt;      2        1.3695             nan     0.0100    0.0025
#&gt;      3        1.3647             nan     0.0100    0.0020
#&gt;      4        1.3601             nan     0.0100    0.0020
#&gt;      5        1.3560             nan     0.0100    0.0011
#&gt;      6        1.3510             nan     0.0100    0.0023
#&gt;      7        1.3464             nan     0.0100    0.0018
#&gt;      8        1.3419             nan     0.0100    0.0023
#&gt;      9        1.3375             nan     0.0100    0.0023
#&gt;     10        1.3323             nan     0.0100    0.0020
#&gt;     20        1.2871             nan     0.0100    0.0015
#&gt;     40        1.2150             nan     0.0100    0.0015
#&gt;     60        1.1526             nan     0.0100    0.0012
#&gt;     80        1.1083             nan     0.0100    0.0010
#&gt;    100        1.0663             nan     0.0100    0.0008
#&gt;    120        1.0287             nan     0.0100    0.0007
#&gt;    140        0.9954             nan     0.0100    0.0006
#&gt;    160        0.9660             nan     0.0100    0.0004
#&gt;    180        0.9404             nan     0.0100    0.0003
#&gt;    200        0.9187             nan     0.0100    0.0002
#&gt;    220        0.8997             nan     0.0100    0.0002
#&gt;    240        0.8828             nan     0.0100   -0.0003
#&gt;    260        0.8655             nan     0.0100    0.0003
#&gt;    280        0.8510             nan     0.0100    0.0002
#&gt;    300        0.8362             nan     0.0100    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3737             nan     0.0100    0.0024
#&gt;      2        1.3686             nan     0.0100    0.0020
#&gt;      3        1.3624             nan     0.0100    0.0032
#&gt;      4        1.3553             nan     0.0100    0.0034
#&gt;      5        1.3479             nan     0.0100    0.0028
#&gt;      6        1.3418             nan     0.0100    0.0030
#&gt;      7        1.3352             nan     0.0100    0.0027
#&gt;      8        1.3296             nan     0.0100    0.0027
#&gt;      9        1.3242             nan     0.0100    0.0020
#&gt;     10        1.3183             nan     0.0100    0.0026
#&gt;     20        1.2624             nan     0.0100    0.0020
#&gt;     40        1.1705             nan     0.0100    0.0013
#&gt;     60        1.0950             nan     0.0100    0.0013
#&gt;     80        1.0332             nan     0.0100    0.0011
#&gt;    100        0.9793             nan     0.0100    0.0008
#&gt;    120        0.9334             nan     0.0100    0.0007
#&gt;    140        0.8954             nan     0.0100    0.0007
#&gt;    160        0.8611             nan     0.0100    0.0006
#&gt;    180        0.8323             nan     0.0100    0.0005
#&gt;    200        0.8088             nan     0.0100    0.0002
#&gt;    220        0.7865             nan     0.0100    0.0001
#&gt;    240        0.7675             nan     0.0100   -0.0003
#&gt;    260        0.7491             nan     0.0100    0.0001
#&gt;    280        0.7330             nan     0.0100    0.0000
#&gt;    300        0.7179             nan     0.0100   -0.0000
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3726             nan     0.0100    0.0024
#&gt;      2        1.3646             nan     0.0100    0.0036
#&gt;      3        1.3562             nan     0.0100    0.0034
#&gt;      4        1.3496             nan     0.0100    0.0026
#&gt;      5        1.3421             nan     0.0100    0.0028
#&gt;      6        1.3341             nan     0.0100    0.0033
#&gt;      7        1.3271             nan     0.0100    0.0033
#&gt;      8        1.3212             nan     0.0100    0.0026
#&gt;      9        1.3141             nan     0.0100    0.0028
#&gt;     10        1.3066             nan     0.0100    0.0033
#&gt;     20        1.2426             nan     0.0100    0.0025
#&gt;     40        1.1360             nan     0.0100    0.0023
#&gt;     60        1.0510             nan     0.0100    0.0012
#&gt;     80        0.9804             nan     0.0100    0.0009
#&gt;    100        0.9230             nan     0.0100    0.0006
#&gt;    120        0.8762             nan     0.0100    0.0007
#&gt;    140        0.8328             nan     0.0100    0.0004
#&gt;    160        0.7971             nan     0.0100   -0.0002
#&gt;    180        0.7632             nan     0.0100    0.0000
#&gt;    200        0.7352             nan     0.0100    0.0001
#&gt;    220        0.7115             nan     0.0100    0.0002
#&gt;    240        0.6867             nan     0.0100    0.0003
#&gt;    260        0.6655             nan     0.0100    0.0002
#&gt;    280        0.6464             nan     0.0100    0.0003
#&gt;    300        0.6308             nan     0.0100   -0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3282             nan     0.1000    0.0232
#&gt;      2        1.2846             nan     0.1000    0.0146
#&gt;      3        1.2470             nan     0.1000    0.0173
#&gt;      4        1.2125             nan     0.1000    0.0151
#&gt;      5        1.1819             nan     0.1000    0.0133
#&gt;      6        1.1555             nan     0.1000    0.0081
#&gt;      7        1.1217             nan     0.1000    0.0139
#&gt;      8        1.0987             nan     0.1000    0.0066
#&gt;      9        1.0759             nan     0.1000    0.0091
#&gt;     10        1.0505             nan     0.1000    0.0089
#&gt;     20        0.9220             nan     0.1000    0.0044
#&gt;     40        0.7892             nan     0.1000   -0.0038
#&gt;     60        0.7165             nan     0.1000   -0.0039
#&gt;     80        0.6602             nan     0.1000   -0.0005
#&gt;    100        0.6246             nan     0.1000   -0.0019
#&gt;    120        0.5946             nan     0.1000   -0.0023
#&gt;    140        0.5709             nan     0.1000   -0.0016
#&gt;    160        0.5514             nan     0.1000   -0.0018
#&gt;    180        0.5323             nan     0.1000   -0.0013
#&gt;    200        0.5174             nan     0.1000   -0.0048
#&gt;    220        0.5032             nan     0.1000   -0.0006
#&gt;    240        0.4893             nan     0.1000   -0.0025
#&gt;    260        0.4736             nan     0.1000   -0.0004
#&gt;    280        0.4617             nan     0.1000   -0.0016
#&gt;    300        0.4507             nan     0.1000   -0.0026
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3138             nan     0.1000    0.0261
#&gt;      2        1.2597             nan     0.1000    0.0246
#&gt;      3        1.2046             nan     0.1000    0.0197
#&gt;      4        1.1622             nan     0.1000    0.0164
#&gt;      5        1.1313             nan     0.1000    0.0111
#&gt;      6        1.1016             nan     0.1000    0.0129
#&gt;      7        1.0581             nan     0.1000    0.0174
#&gt;      8        1.0315             nan     0.1000    0.0091
#&gt;      9        1.0037             nan     0.1000    0.0081
#&gt;     10        0.9806             nan     0.1000    0.0047
#&gt;     20        0.8209             nan     0.1000    0.0017
#&gt;     40        0.6627             nan     0.1000   -0.0018
#&gt;     60        0.5797             nan     0.1000   -0.0045
#&gt;     80        0.5279             nan     0.1000   -0.0037
#&gt;    100        0.4753             nan     0.1000   -0.0021
#&gt;    120        0.4313             nan     0.1000   -0.0031
#&gt;    140        0.3905             nan     0.1000   -0.0018
#&gt;    160        0.3676             nan     0.1000   -0.0009
#&gt;    180        0.3434             nan     0.1000   -0.0025
#&gt;    200        0.3148             nan     0.1000   -0.0023
#&gt;    220        0.2924             nan     0.1000   -0.0004
#&gt;    240        0.2763             nan     0.1000   -0.0023
#&gt;    260        0.2586             nan     0.1000   -0.0030
#&gt;    280        0.2412             nan     0.1000    0.0001
#&gt;    300        0.2250             nan     0.1000   -0.0013
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3103             nan     0.1000    0.0292
#&gt;      2        1.2408             nan     0.1000    0.0314
#&gt;      3        1.1853             nan     0.1000    0.0218
#&gt;      4        1.1338             nan     0.1000    0.0165
#&gt;      5        1.0900             nan     0.1000    0.0187
#&gt;      6        1.0505             nan     0.1000    0.0175
#&gt;      7        1.0135             nan     0.1000    0.0110
#&gt;      8        0.9800             nan     0.1000    0.0101
#&gt;      9        0.9583             nan     0.1000    0.0035
#&gt;     10        0.9319             nan     0.1000    0.0072
#&gt;     20        0.7535             nan     0.1000   -0.0015
#&gt;     40        0.5700             nan     0.1000   -0.0033
#&gt;     60        0.4760             nan     0.1000   -0.0009
#&gt;     80        0.4140             nan     0.1000   -0.0058
#&gt;    100        0.3553             nan     0.1000   -0.0032
#&gt;    120        0.3058             nan     0.1000   -0.0013
#&gt;    140        0.2713             nan     0.1000   -0.0011
#&gt;    160        0.2425             nan     0.1000   -0.0011
#&gt;    180        0.2178             nan     0.1000   -0.0018
#&gt;    200        0.2012             nan     0.1000   -0.0007
#&gt;    220        0.1837             nan     0.1000   -0.0017
#&gt;    240        0.1663             nan     0.1000   -0.0009
#&gt;    260        0.1499             nan     0.1000   -0.0011
#&gt;    280        0.1356             nan     0.1000   -0.0008
#&gt;    300        0.1233             nan     0.1000   -0.0006
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3788             nan     0.0010    0.0002
#&gt;      2        1.3783             nan     0.0010    0.0003
#&gt;      3        1.3777             nan     0.0010    0.0003
#&gt;      4        1.3772             nan     0.0010    0.0002
#&gt;      5        1.3766             nan     0.0010    0.0003
#&gt;      6        1.3761             nan     0.0010    0.0002
#&gt;      7        1.3755             nan     0.0010    0.0002
#&gt;      8        1.3750             nan     0.0010    0.0002
#&gt;      9        1.3745             nan     0.0010    0.0002
#&gt;     10        1.3739             nan     0.0010    0.0002
#&gt;     20        1.3684             nan     0.0010    0.0002
#&gt;     40        1.3581             nan     0.0010    0.0002
#&gt;     60        1.3480             nan     0.0010    0.0002
#&gt;     80        1.3380             nan     0.0010    0.0002
#&gt;    100        1.3280             nan     0.0010    0.0002
#&gt;    120        1.3186             nan     0.0010    0.0001
#&gt;    140        1.3091             nan     0.0010    0.0002
#&gt;    160        1.3008             nan     0.0010    0.0002
#&gt;    180        1.2922             nan     0.0010    0.0002
#&gt;    200        1.2829             nan     0.0010    0.0002
#&gt;    220        1.2744             nan     0.0010    0.0001
#&gt;    240        1.2661             nan     0.0010    0.0002
#&gt;    260        1.2579             nan     0.0010    0.0001
#&gt;    280        1.2500             nan     0.0010    0.0001
#&gt;    300        1.2419             nan     0.0010    0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3786             nan     0.0010    0.0003
#&gt;      2        1.3780             nan     0.0010    0.0003
#&gt;      3        1.3773             nan     0.0010    0.0003
#&gt;      4        1.3765             nan     0.0010    0.0003
#&gt;      5        1.3758             nan     0.0010    0.0003
#&gt;      6        1.3751             nan     0.0010    0.0003
#&gt;      7        1.3744             nan     0.0010    0.0003
#&gt;      8        1.3736             nan     0.0010    0.0003
#&gt;      9        1.3729             nan     0.0010    0.0003
#&gt;     10        1.3721             nan     0.0010    0.0003
#&gt;     20        1.3650             nan     0.0010    0.0003
#&gt;     40        1.3510             nan     0.0010    0.0003
#&gt;     60        1.3381             nan     0.0010    0.0003
#&gt;     80        1.3250             nan     0.0010    0.0003
#&gt;    100        1.3128             nan     0.0010    0.0003
#&gt;    120        1.3002             nan     0.0010    0.0003
#&gt;    140        1.2882             nan     0.0010    0.0002
#&gt;    160        1.2764             nan     0.0010    0.0003
#&gt;    180        1.2649             nan     0.0010    0.0002
#&gt;    200        1.2535             nan     0.0010    0.0002
#&gt;    220        1.2426             nan     0.0010    0.0002
#&gt;    240        1.2321             nan     0.0010    0.0002
#&gt;    260        1.2217             nan     0.0010    0.0002
#&gt;    280        1.2116             nan     0.0010    0.0002
#&gt;    300        1.2013             nan     0.0010    0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3787             nan     0.0010    0.0003
#&gt;      2        1.3779             nan     0.0010    0.0004
#&gt;      3        1.3771             nan     0.0010    0.0003
#&gt;      4        1.3762             nan     0.0010    0.0003
#&gt;      5        1.3753             nan     0.0010    0.0004
#&gt;      6        1.3745             nan     0.0010    0.0003
#&gt;      7        1.3738             nan     0.0010    0.0002
#&gt;      8        1.3730             nan     0.0010    0.0004
#&gt;      9        1.3721             nan     0.0010    0.0003
#&gt;     10        1.3714             nan     0.0010    0.0004
#&gt;     20        1.3628             nan     0.0010    0.0003
#&gt;     40        1.3474             nan     0.0010    0.0004
#&gt;     60        1.3324             nan     0.0010    0.0003
#&gt;     80        1.3173             nan     0.0010    0.0003
#&gt;    100        1.3029             nan     0.0010    0.0002
#&gt;    120        1.2888             nan     0.0010    0.0003
#&gt;    140        1.2752             nan     0.0010    0.0001
#&gt;    160        1.2619             nan     0.0010    0.0003
#&gt;    180        1.2487             nan     0.0010    0.0003
#&gt;    200        1.2360             nan     0.0010    0.0003
#&gt;    220        1.2236             nan     0.0010    0.0002
#&gt;    240        1.2113             nan     0.0010    0.0001
#&gt;    260        1.1996             nan     0.0010    0.0002
#&gt;    280        1.1881             nan     0.0010    0.0002
#&gt;    300        1.1772             nan     0.0010    0.0003
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3739             nan     0.0100    0.0024
#&gt;      2        1.3693             nan     0.0100    0.0018
#&gt;      3        1.3644             nan     0.0100    0.0024
#&gt;      4        1.3590             nan     0.0100    0.0025
#&gt;      5        1.3529             nan     0.0100    0.0023
#&gt;      6        1.3475             nan     0.0100    0.0024
#&gt;      7        1.3425             nan     0.0100    0.0023
#&gt;      8        1.3374             nan     0.0100    0.0018
#&gt;      9        1.3318             nan     0.0100    0.0021
#&gt;     10        1.3268             nan     0.0100    0.0022
#&gt;     20        1.2824             nan     0.0100    0.0015
#&gt;     40        1.2042             nan     0.0100    0.0016
#&gt;     60        1.1399             nan     0.0100    0.0011
#&gt;     80        1.0874             nan     0.0100    0.0005
#&gt;    100        1.0424             nan     0.0100    0.0009
#&gt;    120        1.0039             nan     0.0100    0.0005
#&gt;    140        0.9698             nan     0.0100    0.0002
#&gt;    160        0.9401             nan     0.0100    0.0002
#&gt;    180        0.9157             nan     0.0100    0.0001
#&gt;    200        0.8927             nan     0.0100    0.0004
#&gt;    220        0.8722             nan     0.0100    0.0001
#&gt;    240        0.8536             nan     0.0100    0.0001
#&gt;    260        0.8365             nan     0.0100    0.0003
#&gt;    280        0.8220             nan     0.0100    0.0001
#&gt;    300        0.8071             nan     0.0100    0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3719             nan     0.0100    0.0028
#&gt;      2        1.3651             nan     0.0100    0.0023
#&gt;      3        1.3583             nan     0.0100    0.0032
#&gt;      4        1.3511             nan     0.0100    0.0032
#&gt;      5        1.3436             nan     0.0100    0.0032
#&gt;      6        1.3370             nan     0.0100    0.0028
#&gt;      7        1.3310             nan     0.0100    0.0027
#&gt;      8        1.3252             nan     0.0100    0.0026
#&gt;      9        1.3189             nan     0.0100    0.0029
#&gt;     10        1.3128             nan     0.0100    0.0027
#&gt;     20        1.2567             nan     0.0100    0.0027
#&gt;     40        1.1590             nan     0.0100    0.0018
#&gt;     60        1.0804             nan     0.0100    0.0016
#&gt;     80        1.0153             nan     0.0100    0.0011
#&gt;    100        0.9613             nan     0.0100    0.0007
#&gt;    120        0.9160             nan     0.0100    0.0010
#&gt;    140        0.8758             nan     0.0100    0.0005
#&gt;    160        0.8438             nan     0.0100    0.0002
#&gt;    180        0.8159             nan     0.0100    0.0003
#&gt;    200        0.7912             nan     0.0100    0.0005
#&gt;    220        0.7686             nan     0.0100    0.0002
#&gt;    240        0.7491             nan     0.0100    0.0002
#&gt;    260        0.7302             nan     0.0100    0.0003
#&gt;    280        0.7126             nan     0.0100   -0.0001
#&gt;    300        0.6969             nan     0.0100    0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3705             nan     0.0100    0.0031
#&gt;      2        1.3633             nan     0.0100    0.0031
#&gt;      3        1.3557             nan     0.0100    0.0036
#&gt;      4        1.3476             nan     0.0100    0.0032
#&gt;      5        1.3401             nan     0.0100    0.0020
#&gt;      6        1.3315             nan     0.0100    0.0039
#&gt;      7        1.3242             nan     0.0100    0.0039
#&gt;      8        1.3173             nan     0.0100    0.0029
#&gt;      9        1.3085             nan     0.0100    0.0031
#&gt;     10        1.3016             nan     0.0100    0.0027
#&gt;     20        1.2338             nan     0.0100    0.0030
#&gt;     40        1.1212             nan     0.0100    0.0022
#&gt;     60        1.0358             nan     0.0100    0.0016
#&gt;     80        0.9656             nan     0.0100    0.0009
#&gt;    100        0.9055             nan     0.0100    0.0009
#&gt;    120        0.8564             nan     0.0100    0.0009
#&gt;    140        0.8122             nan     0.0100    0.0004
#&gt;    160        0.7761             nan     0.0100    0.0002
#&gt;    180        0.7425             nan     0.0100   -0.0000
#&gt;    200        0.7152             nan     0.0100    0.0003
#&gt;    220        0.6914             nan     0.0100    0.0002
#&gt;    240        0.6682             nan     0.0100    0.0002
#&gt;    260        0.6465             nan     0.0100    0.0001
#&gt;    280        0.6282             nan     0.0100   -0.0003
#&gt;    300        0.6112             nan     0.0100   -0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3233             nan     0.1000    0.0226
#&gt;      2        1.2783             nan     0.1000    0.0188
#&gt;      3        1.2300             nan     0.1000    0.0159
#&gt;      4        1.1901             nan     0.1000    0.0206
#&gt;      5        1.1605             nan     0.1000    0.0115
#&gt;      6        1.1290             nan     0.1000    0.0117
#&gt;      7        1.1089             nan     0.1000    0.0095
#&gt;      8        1.0826             nan     0.1000    0.0098
#&gt;      9        1.0494             nan     0.1000    0.0105
#&gt;     10        1.0243             nan     0.1000    0.0103
#&gt;     20        0.8811             nan     0.1000    0.0021
#&gt;     40        0.7475             nan     0.1000   -0.0007
#&gt;     60        0.6810             nan     0.1000   -0.0007
#&gt;     80        0.6275             nan     0.1000    0.0001
#&gt;    100        0.5903             nan     0.1000   -0.0009
#&gt;    120        0.5633             nan     0.1000   -0.0014
#&gt;    140        0.5390             nan     0.1000   -0.0042
#&gt;    160        0.5217             nan     0.1000   -0.0009
#&gt;    180        0.5001             nan     0.1000   -0.0005
#&gt;    200        0.4834             nan     0.1000   -0.0026
#&gt;    220        0.4684             nan     0.1000   -0.0017
#&gt;    240        0.4551             nan     0.1000   -0.0024
#&gt;    260        0.4422             nan     0.1000   -0.0032
#&gt;    280        0.4309             nan     0.1000   -0.0014
#&gt;    300        0.4221             nan     0.1000   -0.0007
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3107             nan     0.1000    0.0331
#&gt;      2        1.2436             nan     0.1000    0.0281
#&gt;      3        1.1947             nan     0.1000    0.0211
#&gt;      4        1.1486             nan     0.1000    0.0143
#&gt;      5        1.1097             nan     0.1000    0.0133
#&gt;      6        1.0753             nan     0.1000    0.0113
#&gt;      7        1.0344             nan     0.1000    0.0173
#&gt;      8        0.9969             nan     0.1000    0.0109
#&gt;      9        0.9688             nan     0.1000    0.0124
#&gt;     10        0.9489             nan     0.1000    0.0047
#&gt;     20        0.7926             nan     0.1000   -0.0008
#&gt;     40        0.6370             nan     0.1000   -0.0013
#&gt;     60        0.5444             nan     0.1000   -0.0020
#&gt;     80        0.4859             nan     0.1000   -0.0022
#&gt;    100        0.4444             nan     0.1000   -0.0025
#&gt;    120        0.3968             nan     0.1000   -0.0026
#&gt;    140        0.3585             nan     0.1000   -0.0020
#&gt;    160        0.3295             nan     0.1000   -0.0006
#&gt;    180        0.3069             nan     0.1000   -0.0020
#&gt;    200        0.2786             nan     0.1000   -0.0004
#&gt;    220        0.2545             nan     0.1000   -0.0011
#&gt;    240        0.2383             nan     0.1000   -0.0008
#&gt;    260        0.2208             nan     0.1000   -0.0010
#&gt;    280        0.2081             nan     0.1000   -0.0025
#&gt;    300        0.1934             nan     0.1000   -0.0007
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3010             nan     0.1000    0.0351
#&gt;      2        1.2168             nan     0.1000    0.0272
#&gt;      3        1.1563             nan     0.1000    0.0232
#&gt;      4        1.1108             nan     0.1000    0.0188
#&gt;      5        1.0611             nan     0.1000    0.0212
#&gt;      6        1.0260             nan     0.1000    0.0143
#&gt;      7        0.9971             nan     0.1000    0.0049
#&gt;      8        0.9612             nan     0.1000    0.0128
#&gt;      9        0.9322             nan     0.1000    0.0077
#&gt;     10        0.8992             nan     0.1000    0.0089
#&gt;     20        0.7163             nan     0.1000   -0.0000
#&gt;     40        0.5384             nan     0.1000   -0.0007
#&gt;     60        0.4519             nan     0.1000   -0.0017
#&gt;     80        0.3947             nan     0.1000   -0.0026
#&gt;    100        0.3415             nan     0.1000   -0.0028
#&gt;    120        0.2949             nan     0.1000   -0.0013
#&gt;    140        0.2558             nan     0.1000   -0.0028
#&gt;    160        0.2224             nan     0.1000   -0.0012
#&gt;    180        0.1932             nan     0.1000   -0.0018
#&gt;    200        0.1718             nan     0.1000   -0.0008
#&gt;    220        0.1537             nan     0.1000   -0.0016
#&gt;    240        0.1386             nan     0.1000   -0.0014
#&gt;    260        0.1264             nan     0.1000   -0.0007
#&gt;    280        0.1094             nan     0.1000   -0.0001
#&gt;    300        0.0967             nan     0.1000   -0.0004
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3299             nan     0.1000    0.0257
#&gt;      2        1.2844             nan     0.1000    0.0208
#&gt;      3        1.2443             nan     0.1000    0.0159
#&gt;      4        1.2034             nan     0.1000    0.0178
#&gt;      5        1.1749             nan     0.1000    0.0127
#&gt;      6        1.1487             nan     0.1000    0.0110
#&gt;      7        1.1213             nan     0.1000    0.0132
#&gt;      8        1.0953             nan     0.1000    0.0103
#&gt;      9        1.0744             nan     0.1000    0.0090
#&gt;     10        1.0565             nan     0.1000    0.0078
#&gt;     20        0.9156             nan     0.1000    0.0034
#&gt;     40        0.7795             nan     0.1000    0.0013
#&gt;     60        0.7094             nan     0.1000   -0.0009
#&gt;     80        0.6646             nan     0.1000   -0.0006
#&gt;    100        0.6353             nan     0.1000   -0.0014
#&gt;    120        0.6104             nan     0.1000   -0.0014
#&gt;    140        0.5877             nan     0.1000   -0.0016
#&gt;    160        0.5640             nan     0.1000   -0.0020
#&gt;    180        0.5497             nan     0.1000   -0.0018
#&gt;    200        0.5358             nan     0.1000   -0.0018
#&gt;    204        0.5339             nan     0.1000   -0.0020
```


```r
# Set the seed
set.seed(12345)
# Train the random forest
heart_boost = train(
  heart_disease ~ .,
  data = heart_df,
  method = "gbm",
  trControl = trainControl(
    method = "cv",
    number = 5
  ),
  tuneGrid = expand.grid(
    "n.trees" = seq(1, 1e3, by = 1),
    "interaction.depth" = 1:3,
    "shrinkage" = c(0.1, 0.01, 0.001),
    "n.minobsinnode" = 5
  )
)
```

```
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3789             nan     0.0010    0.0003
#&gt;      2        1.3784             nan     0.0010    0.0003
#&gt;      3        1.3778             nan     0.0010    0.0002
#&gt;      4        1.3773             nan     0.0010    0.0003
#&gt;      5        1.3767             nan     0.0010    0.0002
#&gt;      6        1.3761             nan     0.0010    0.0002
#&gt;      7        1.3757             nan     0.0010    0.0002
#&gt;      8        1.3751             nan     0.0010    0.0002
#&gt;      9        1.3745             nan     0.0010    0.0002
#&gt;     10        1.3740             nan     0.0010    0.0002
#&gt;     20        1.3688             nan     0.0010    0.0002
#&gt;     40        1.3582             nan     0.0010    0.0002
#&gt;     60        1.3486             nan     0.0010    0.0002
#&gt;     80        1.3391             nan     0.0010    0.0002
#&gt;    100        1.3295             nan     0.0010    0.0002
#&gt;    120        1.3198             nan     0.0010    0.0002
#&gt;    140        1.3106             nan     0.0010    0.0002
#&gt;    160        1.3016             nan     0.0010    0.0002
#&gt;    180        1.2932             nan     0.0010    0.0002
#&gt;    200        1.2847             nan     0.0010    0.0001
#&gt;    220        1.2761             nan     0.0010    0.0002
#&gt;    240        1.2679             nan     0.0010    0.0002
#&gt;    260        1.2597             nan     0.0010    0.0002
#&gt;    280        1.2516             nan     0.0010    0.0002
#&gt;    300        1.2441             nan     0.0010    0.0002
#&gt;    320        1.2364             nan     0.0010    0.0002
#&gt;    340        1.2293             nan     0.0010    0.0002
#&gt;    360        1.2219             nan     0.0010    0.0001
#&gt;    380        1.2149             nan     0.0010    0.0002
#&gt;    400        1.2079             nan     0.0010    0.0001
#&gt;    420        1.2010             nan     0.0010    0.0002
#&gt;    440        1.1942             nan     0.0010    0.0001
#&gt;    460        1.1875             nan     0.0010    0.0001
#&gt;    480        1.1811             nan     0.0010    0.0001
#&gt;    500        1.1746             nan     0.0010    0.0001
#&gt;    520        1.1682             nan     0.0010    0.0001
#&gt;    540        1.1619             nan     0.0010    0.0001
#&gt;    560        1.1554             nan     0.0010    0.0001
#&gt;    580        1.1493             nan     0.0010    0.0001
#&gt;    600        1.1432             nan     0.0010    0.0001
#&gt;    620        1.1374             nan     0.0010    0.0001
#&gt;    640        1.1314             nan     0.0010    0.0001
#&gt;    660        1.1256             nan     0.0010    0.0001
#&gt;    680        1.1202             nan     0.0010    0.0001
#&gt;    700        1.1147             nan     0.0010    0.0001
#&gt;    720        1.1094             nan     0.0010    0.0001
#&gt;    740        1.1042             nan     0.0010    0.0001
#&gt;    760        1.0992             nan     0.0010    0.0001
#&gt;    780        1.0941             nan     0.0010    0.0001
#&gt;    800        1.0889             nan     0.0010    0.0001
#&gt;    820        1.0837             nan     0.0010    0.0001
#&gt;    840        1.0786             nan     0.0010    0.0001
#&gt;    860        1.0740             nan     0.0010    0.0001
#&gt;    880        1.0692             nan     0.0010    0.0001
#&gt;    900        1.0645             nan     0.0010    0.0001
#&gt;    920        1.0600             nan     0.0010    0.0001
#&gt;    940        1.0552             nan     0.0010    0.0001
#&gt;    960        1.0506             nan     0.0010    0.0001
#&gt;    980        1.0463             nan     0.0010    0.0001
#&gt;   1000        1.0418             nan     0.0010    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3788             nan     0.0010    0.0003
#&gt;      2        1.3781             nan     0.0010    0.0003
#&gt;      3        1.3773             nan     0.0010    0.0003
#&gt;      4        1.3765             nan     0.0010    0.0003
#&gt;      5        1.3758             nan     0.0010    0.0004
#&gt;      6        1.3750             nan     0.0010    0.0003
#&gt;      7        1.3743             nan     0.0010    0.0003
#&gt;      8        1.3736             nan     0.0010    0.0003
#&gt;      9        1.3728             nan     0.0010    0.0003
#&gt;     10        1.3722             nan     0.0010    0.0003
#&gt;     20        1.3649             nan     0.0010    0.0003
#&gt;     40        1.3510             nan     0.0010    0.0003
#&gt;     60        1.3373             nan     0.0010    0.0003
#&gt;     80        1.3239             nan     0.0010    0.0003
#&gt;    100        1.3114             nan     0.0010    0.0003
#&gt;    120        1.2987             nan     0.0010    0.0002
#&gt;    140        1.2867             nan     0.0010    0.0003
#&gt;    160        1.2750             nan     0.0010    0.0003
#&gt;    180        1.2634             nan     0.0010    0.0002
#&gt;    200        1.2521             nan     0.0010    0.0003
#&gt;    220        1.2409             nan     0.0010    0.0002
#&gt;    240        1.2304             nan     0.0010    0.0002
#&gt;    260        1.2199             nan     0.0010    0.0002
#&gt;    280        1.2096             nan     0.0010    0.0002
#&gt;    300        1.1995             nan     0.0010    0.0002
#&gt;    320        1.1894             nan     0.0010    0.0002
#&gt;    340        1.1800             nan     0.0010    0.0002
#&gt;    360        1.1704             nan     0.0010    0.0002
#&gt;    380        1.1612             nan     0.0010    0.0002
#&gt;    400        1.1522             nan     0.0010    0.0002
#&gt;    420        1.1435             nan     0.0010    0.0001
#&gt;    440        1.1349             nan     0.0010    0.0002
#&gt;    460        1.1267             nan     0.0010    0.0002
#&gt;    480        1.1183             nan     0.0010    0.0002
#&gt;    500        1.1098             nan     0.0010    0.0002
#&gt;    520        1.1017             nan     0.0010    0.0001
#&gt;    540        1.0939             nan     0.0010    0.0002
#&gt;    560        1.0862             nan     0.0010    0.0002
#&gt;    580        1.0788             nan     0.0010    0.0002
#&gt;    600        1.0714             nan     0.0010    0.0002
#&gt;    620        1.0643             nan     0.0010    0.0001
#&gt;    640        1.0570             nan     0.0010    0.0002
#&gt;    660        1.0500             nan     0.0010    0.0001
#&gt;    680        1.0431             nan     0.0010    0.0001
#&gt;    700        1.0364             nan     0.0010    0.0001
#&gt;    720        1.0300             nan     0.0010    0.0001
#&gt;    740        1.0236             nan     0.0010    0.0002
#&gt;    760        1.0173             nan     0.0010    0.0001
#&gt;    780        1.0109             nan     0.0010    0.0001
#&gt;    800        1.0048             nan     0.0010    0.0001
#&gt;    820        0.9988             nan     0.0010    0.0001
#&gt;    840        0.9927             nan     0.0010    0.0001
#&gt;    860        0.9868             nan     0.0010    0.0001
#&gt;    880        0.9809             nan     0.0010    0.0001
#&gt;    900        0.9753             nan     0.0010    0.0001
#&gt;    920        0.9698             nan     0.0010    0.0001
#&gt;    940        0.9644             nan     0.0010    0.0001
#&gt;    960        0.9591             nan     0.0010    0.0001
#&gt;    980        0.9539             nan     0.0010    0.0001
#&gt;   1000        0.9489             nan     0.0010    0.0000
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3785             nan     0.0010    0.0004
#&gt;      2        1.3777             nan     0.0010    0.0004
#&gt;      3        1.3767             nan     0.0010    0.0004
#&gt;      4        1.3759             nan     0.0010    0.0004
#&gt;      5        1.3750             nan     0.0010    0.0004
#&gt;      6        1.3743             nan     0.0010    0.0003
#&gt;      7        1.3734             nan     0.0010    0.0004
#&gt;      8        1.3725             nan     0.0010    0.0003
#&gt;      9        1.3717             nan     0.0010    0.0004
#&gt;     10        1.3707             nan     0.0010    0.0004
#&gt;     20        1.3626             nan     0.0010    0.0003
#&gt;     40        1.3455             nan     0.0010    0.0002
#&gt;     60        1.3298             nan     0.0010    0.0002
#&gt;     80        1.3144             nan     0.0010    0.0002
#&gt;    100        1.2997             nan     0.0010    0.0003
#&gt;    120        1.2850             nan     0.0010    0.0003
#&gt;    140        1.2711             nan     0.0010    0.0003
#&gt;    160        1.2577             nan     0.0010    0.0002
#&gt;    180        1.2439             nan     0.0010    0.0002
#&gt;    200        1.2309             nan     0.0010    0.0002
#&gt;    220        1.2179             nan     0.0010    0.0003
#&gt;    240        1.2055             nan     0.0010    0.0002
#&gt;    260        1.1935             nan     0.0010    0.0002
#&gt;    280        1.1817             nan     0.0010    0.0002
#&gt;    300        1.1702             nan     0.0010    0.0002
#&gt;    320        1.1589             nan     0.0010    0.0002
#&gt;    340        1.1478             nan     0.0010    0.0002
#&gt;    360        1.1376             nan     0.0010    0.0002
#&gt;    380        1.1267             nan     0.0010    0.0002
#&gt;    400        1.1164             nan     0.0010    0.0002
#&gt;    420        1.1066             nan     0.0010    0.0002
#&gt;    440        1.0967             nan     0.0010    0.0002
#&gt;    460        1.0873             nan     0.0010    0.0002
#&gt;    480        1.0781             nan     0.0010    0.0002
#&gt;    500        1.0690             nan     0.0010    0.0002
#&gt;    520        1.0601             nan     0.0010    0.0002
#&gt;    540        1.0514             nan     0.0010    0.0002
#&gt;    560        1.0425             nan     0.0010    0.0002
#&gt;    580        1.0337             nan     0.0010    0.0001
#&gt;    600        1.0252             nan     0.0010    0.0002
#&gt;    620        1.0172             nan     0.0010    0.0001
#&gt;    640        1.0094             nan     0.0010    0.0001
#&gt;    660        1.0015             nan     0.0010    0.0001
#&gt;    680        0.9942             nan     0.0010    0.0000
#&gt;    700        0.9868             nan     0.0010    0.0001
#&gt;    720        0.9796             nan     0.0010    0.0001
#&gt;    740        0.9725             nan     0.0010    0.0001
#&gt;    760        0.9654             nan     0.0010    0.0002
#&gt;    780        0.9584             nan     0.0010    0.0001
#&gt;    800        0.9516             nan     0.0010    0.0001
#&gt;    820        0.9449             nan     0.0010    0.0001
#&gt;    840        0.9385             nan     0.0010    0.0001
#&gt;    860        0.9320             nan     0.0010    0.0001
#&gt;    880        0.9257             nan     0.0010    0.0001
#&gt;    900        0.9194             nan     0.0010    0.0001
#&gt;    920        0.9133             nan     0.0010    0.0001
#&gt;    940        0.9075             nan     0.0010    0.0001
#&gt;    960        0.9018             nan     0.0010    0.0000
#&gt;    980        0.8963             nan     0.0010    0.0001
#&gt;   1000        0.8904             nan     0.0010    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3743             nan     0.0100    0.0025
#&gt;      2        1.3689             nan     0.0100    0.0025
#&gt;      3        1.3638             nan     0.0100    0.0025
#&gt;      4        1.3587             nan     0.0100    0.0023
#&gt;      5        1.3534             nan     0.0100    0.0023
#&gt;      6        1.3490             nan     0.0100    0.0022
#&gt;      7        1.3448             nan     0.0100    0.0018
#&gt;      8        1.3405             nan     0.0100    0.0017
#&gt;      9        1.3364             nan     0.0100    0.0017
#&gt;     10        1.3319             nan     0.0100    0.0024
#&gt;     20        1.2861             nan     0.0100    0.0021
#&gt;     40        1.2063             nan     0.0100    0.0016
#&gt;     60        1.1410             nan     0.0100    0.0013
#&gt;     80        1.0853             nan     0.0100    0.0011
#&gt;    100        1.0379             nan     0.0100    0.0006
#&gt;    120        0.9957             nan     0.0100    0.0008
#&gt;    140        0.9619             nan     0.0100    0.0007
#&gt;    160        0.9308             nan     0.0100    0.0004
#&gt;    180        0.9021             nan     0.0100    0.0005
#&gt;    200        0.8773             nan     0.0100    0.0004
#&gt;    220        0.8546             nan     0.0100    0.0001
#&gt;    240        0.8349             nan     0.0100   -0.0002
#&gt;    260        0.8163             nan     0.0100    0.0001
#&gt;    280        0.7977             nan     0.0100    0.0003
#&gt;    300        0.7823             nan     0.0100    0.0001
#&gt;    320        0.7687             nan     0.0100   -0.0001
#&gt;    340        0.7566             nan     0.0100    0.0001
#&gt;    360        0.7449             nan     0.0100    0.0000
#&gt;    380        0.7337             nan     0.0100    0.0001
#&gt;    400        0.7245             nan     0.0100   -0.0002
#&gt;    420        0.7157             nan     0.0100    0.0001
#&gt;    440        0.7063             nan     0.0100   -0.0002
#&gt;    460        0.6986             nan     0.0100   -0.0001
#&gt;    480        0.6910             nan     0.0100   -0.0001
#&gt;    500        0.6833             nan     0.0100   -0.0001
#&gt;    520        0.6767             nan     0.0100    0.0000
#&gt;    540        0.6700             nan     0.0100   -0.0001
#&gt;    560        0.6632             nan     0.0100   -0.0002
#&gt;    580        0.6564             nan     0.0100   -0.0001
#&gt;    600        0.6505             nan     0.0100   -0.0000
#&gt;    620        0.6452             nan     0.0100   -0.0001
#&gt;    640        0.6391             nan     0.0100   -0.0000
#&gt;    660        0.6327             nan     0.0100   -0.0001
#&gt;    680        0.6272             nan     0.0100   -0.0001
#&gt;    700        0.6222             nan     0.0100   -0.0000
#&gt;    720        0.6174             nan     0.0100   -0.0002
#&gt;    740        0.6127             nan     0.0100   -0.0001
#&gt;    760        0.6077             nan     0.0100    0.0000
#&gt;    780        0.6035             nan     0.0100   -0.0001
#&gt;    800        0.5996             nan     0.0100   -0.0000
#&gt;    820        0.5948             nan     0.0100   -0.0002
#&gt;    840        0.5902             nan     0.0100   -0.0001
#&gt;    860        0.5857             nan     0.0100   -0.0003
#&gt;    880        0.5820             nan     0.0100   -0.0001
#&gt;    900        0.5784             nan     0.0100   -0.0001
#&gt;    920        0.5759             nan     0.0100   -0.0001
#&gt;    940        0.5724             nan     0.0100   -0.0001
#&gt;    960        0.5685             nan     0.0100   -0.0001
#&gt;    980        0.5648             nan     0.0100    0.0000
#&gt;   1000        0.5624             nan     0.0100   -0.0000
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3721             nan     0.0100    0.0032
#&gt;      2        1.3651             nan     0.0100    0.0028
#&gt;      3        1.3584             nan     0.0100    0.0030
#&gt;      4        1.3518             nan     0.0100    0.0032
#&gt;      5        1.3451             nan     0.0100    0.0029
#&gt;      6        1.3378             nan     0.0100    0.0027
#&gt;      7        1.3310             nan     0.0100    0.0027
#&gt;      8        1.3236             nan     0.0100    0.0030
#&gt;      9        1.3166             nan     0.0100    0.0028
#&gt;     10        1.3108             nan     0.0100    0.0026
#&gt;     20        1.2511             nan     0.0100    0.0020
#&gt;     40        1.1560             nan     0.0100    0.0012
#&gt;     60        1.0728             nan     0.0100    0.0017
#&gt;     80        1.0024             nan     0.0100    0.0011
#&gt;    100        0.9466             nan     0.0100    0.0007
#&gt;    120        0.8970             nan     0.0100    0.0007
#&gt;    140        0.8553             nan     0.0100    0.0004
#&gt;    160        0.8201             nan     0.0100    0.0003
#&gt;    180        0.7901             nan     0.0100    0.0003
#&gt;    200        0.7633             nan     0.0100    0.0005
#&gt;    220        0.7384             nan     0.0100    0.0002
#&gt;    240        0.7178             nan     0.0100    0.0000
#&gt;    260        0.6975             nan     0.0100    0.0001
#&gt;    280        0.6794             nan     0.0100    0.0001
#&gt;    300        0.6622             nan     0.0100   -0.0001
#&gt;    320        0.6484             nan     0.0100   -0.0002
#&gt;    340        0.6347             nan     0.0100    0.0001
#&gt;    360        0.6225             nan     0.0100    0.0000
#&gt;    380        0.6108             nan     0.0100   -0.0001
#&gt;    400        0.5997             nan     0.0100   -0.0001
#&gt;    420        0.5884             nan     0.0100    0.0000
#&gt;    440        0.5783             nan     0.0100   -0.0001
#&gt;    460        0.5691             nan     0.0100   -0.0004
#&gt;    480        0.5591             nan     0.0100   -0.0002
#&gt;    500        0.5505             nan     0.0100   -0.0004
#&gt;    520        0.5423             nan     0.0100   -0.0001
#&gt;    540        0.5342             nan     0.0100   -0.0000
#&gt;    560        0.5259             nan     0.0100   -0.0001
#&gt;    580        0.5179             nan     0.0100   -0.0005
#&gt;    600        0.5113             nan     0.0100   -0.0001
#&gt;    620        0.5044             nan     0.0100   -0.0001
#&gt;    640        0.4983             nan     0.0100   -0.0003
#&gt;    660        0.4911             nan     0.0100   -0.0003
#&gt;    680        0.4844             nan     0.0100   -0.0002
#&gt;    700        0.4781             nan     0.0100    0.0000
#&gt;    720        0.4720             nan     0.0100   -0.0001
#&gt;    740        0.4656             nan     0.0100   -0.0000
#&gt;    760        0.4601             nan     0.0100   -0.0000
#&gt;    780        0.4543             nan     0.0100   -0.0001
#&gt;    800        0.4481             nan     0.0100   -0.0001
#&gt;    820        0.4431             nan     0.0100   -0.0003
#&gt;    840        0.4381             nan     0.0100   -0.0002
#&gt;    860        0.4336             nan     0.0100   -0.0002
#&gt;    880        0.4286             nan     0.0100   -0.0001
#&gt;    900        0.4233             nan     0.0100   -0.0001
#&gt;    920        0.4184             nan     0.0100   -0.0001
#&gt;    940        0.4134             nan     0.0100   -0.0001
#&gt;    960        0.4087             nan     0.0100   -0.0002
#&gt;    980        0.4043             nan     0.0100   -0.0004
#&gt;   1000        0.4003             nan     0.0100   -0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3711             nan     0.0100    0.0038
#&gt;      2        1.3631             nan     0.0100    0.0035
#&gt;      3        1.3550             nan     0.0100    0.0035
#&gt;      4        1.3481             nan     0.0100    0.0027
#&gt;      5        1.3410             nan     0.0100    0.0027
#&gt;      6        1.3322             nan     0.0100    0.0035
#&gt;      7        1.3232             nan     0.0100    0.0030
#&gt;      8        1.3151             nan     0.0100    0.0036
#&gt;      9        1.3080             nan     0.0100    0.0027
#&gt;     10        1.3004             nan     0.0100    0.0032
#&gt;     20        1.2307             nan     0.0100    0.0031
#&gt;     40        1.1166             nan     0.0100    0.0021
#&gt;     60        1.0272             nan     0.0100    0.0016
#&gt;     80        0.9544             nan     0.0100    0.0011
#&gt;    100        0.8921             nan     0.0100    0.0008
#&gt;    120        0.8418             nan     0.0100    0.0008
#&gt;    140        0.7982             nan     0.0100    0.0004
#&gt;    160        0.7582             nan     0.0100    0.0003
#&gt;    180        0.7245             nan     0.0100    0.0004
#&gt;    200        0.6943             nan     0.0100    0.0005
#&gt;    220        0.6671             nan     0.0100    0.0002
#&gt;    240        0.6453             nan     0.0100    0.0002
#&gt;    260        0.6244             nan     0.0100    0.0002
#&gt;    280        0.6052             nan     0.0100   -0.0001
#&gt;    300        0.5881             nan     0.0100   -0.0003
#&gt;    320        0.5696             nan     0.0100   -0.0001
#&gt;    340        0.5544             nan     0.0100   -0.0002
#&gt;    360        0.5402             nan     0.0100   -0.0001
#&gt;    380        0.5261             nan     0.0100   -0.0002
#&gt;    400        0.5135             nan     0.0100   -0.0004
#&gt;    420        0.5011             nan     0.0100   -0.0002
#&gt;    440        0.4906             nan     0.0100   -0.0002
#&gt;    460        0.4801             nan     0.0100   -0.0001
#&gt;    480        0.4701             nan     0.0100   -0.0001
#&gt;    500        0.4597             nan     0.0100   -0.0001
#&gt;    520        0.4505             nan     0.0100   -0.0001
#&gt;    540        0.4412             nan     0.0100   -0.0002
#&gt;    560        0.4325             nan     0.0100   -0.0001
#&gt;    580        0.4235             nan     0.0100   -0.0001
#&gt;    600        0.4154             nan     0.0100   -0.0004
#&gt;    620        0.4064             nan     0.0100   -0.0002
#&gt;    640        0.3983             nan     0.0100   -0.0002
#&gt;    660        0.3914             nan     0.0100   -0.0002
#&gt;    680        0.3851             nan     0.0100   -0.0001
#&gt;    700        0.3778             nan     0.0100   -0.0001
#&gt;    720        0.3712             nan     0.0100   -0.0001
#&gt;    740        0.3650             nan     0.0100   -0.0001
#&gt;    760        0.3591             nan     0.0100   -0.0001
#&gt;    780        0.3530             nan     0.0100   -0.0001
#&gt;    800        0.3475             nan     0.0100   -0.0004
#&gt;    820        0.3418             nan     0.0100   -0.0002
#&gt;    840        0.3353             nan     0.0100   -0.0002
#&gt;    860        0.3301             nan     0.0100   -0.0003
#&gt;    880        0.3246             nan     0.0100   -0.0002
#&gt;    900        0.3195             nan     0.0100   -0.0001
#&gt;    920        0.3148             nan     0.0100   -0.0003
#&gt;    940        0.3092             nan     0.0100   -0.0001
#&gt;    960        0.3039             nan     0.0100   -0.0001
#&gt;    980        0.2993             nan     0.0100   -0.0002
#&gt;   1000        0.2939             nan     0.0100   -0.0003
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3256             nan     0.1000    0.0224
#&gt;      2        1.2901             nan     0.1000    0.0121
#&gt;      3        1.2369             nan     0.1000    0.0193
#&gt;      4        1.2055             nan     0.1000    0.0129
#&gt;      5        1.1709             nan     0.1000    0.0171
#&gt;      6        1.1386             nan     0.1000    0.0136
#&gt;      7        1.1102             nan     0.1000    0.0136
#&gt;      8        1.0887             nan     0.1000    0.0077
#&gt;      9        1.0628             nan     0.1000    0.0099
#&gt;     10        1.0381             nan     0.1000    0.0089
#&gt;     20        0.8709             nan     0.1000    0.0044
#&gt;     40        0.7222             nan     0.1000    0.0005
#&gt;     60        0.6488             nan     0.1000    0.0010
#&gt;     80        0.5940             nan     0.1000   -0.0023
#&gt;    100        0.5579             nan     0.1000   -0.0019
#&gt;    120        0.5335             nan     0.1000   -0.0021
#&gt;    140        0.5083             nan     0.1000   -0.0021
#&gt;    160        0.4864             nan     0.1000   -0.0021
#&gt;    180        0.4620             nan     0.1000   -0.0020
#&gt;    200        0.4497             nan     0.1000   -0.0007
#&gt;    220        0.4433             nan     0.1000   -0.0016
#&gt;    240        0.4360             nan     0.1000   -0.0013
#&gt;    260        0.4233             nan     0.1000   -0.0011
#&gt;    280        0.4105             nan     0.1000   -0.0018
#&gt;    300        0.3961             nan     0.1000   -0.0032
#&gt;    320        0.3855             nan     0.1000   -0.0015
#&gt;    340        0.3744             nan     0.1000   -0.0038
#&gt;    360        0.3673             nan     0.1000   -0.0017
#&gt;    380        0.3587             nan     0.1000   -0.0021
#&gt;    400        0.3484             nan     0.1000   -0.0004
#&gt;    420        0.3412             nan     0.1000   -0.0017
#&gt;    440        0.3301             nan     0.1000   -0.0006
#&gt;    460        0.3196             nan     0.1000   -0.0023
#&gt;    480        0.3102             nan     0.1000   -0.0012
#&gt;    500        0.3049             nan     0.1000   -0.0008
#&gt;    520        0.2969             nan     0.1000   -0.0011
#&gt;    540        0.2906             nan     0.1000   -0.0019
#&gt;    560        0.2829             nan     0.1000   -0.0019
#&gt;    580        0.2762             nan     0.1000   -0.0006
#&gt;    600        0.2714             nan     0.1000   -0.0016
#&gt;    620        0.2674             nan     0.1000   -0.0007
#&gt;    640        0.2604             nan     0.1000   -0.0016
#&gt;    660        0.2552             nan     0.1000   -0.0011
#&gt;    680        0.2520             nan     0.1000   -0.0014
#&gt;    700        0.2455             nan     0.1000   -0.0006
#&gt;    720        0.2383             nan     0.1000   -0.0016
#&gt;    740        0.2326             nan     0.1000   -0.0017
#&gt;    760        0.2291             nan     0.1000   -0.0012
#&gt;    780        0.2244             nan     0.1000   -0.0009
#&gt;    800        0.2203             nan     0.1000   -0.0011
#&gt;    820        0.2159             nan     0.1000   -0.0006
#&gt;    840        0.2106             nan     0.1000   -0.0007
#&gt;    860        0.2052             nan     0.1000   -0.0008
#&gt;    880        0.2012             nan     0.1000   -0.0014
#&gt;    900        0.1986             nan     0.1000   -0.0011
#&gt;    920        0.1955             nan     0.1000   -0.0012
#&gt;    940        0.1924             nan     0.1000   -0.0024
#&gt;    960        0.1888             nan     0.1000   -0.0009
#&gt;    980        0.1863             nan     0.1000   -0.0009
#&gt;   1000        0.1821             nan     0.1000   -0.0006
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3080             nan     0.1000    0.0279
#&gt;      2        1.2508             nan     0.1000    0.0162
#&gt;      3        1.1915             nan     0.1000    0.0255
#&gt;      4        1.1473             nan     0.1000    0.0219
#&gt;      5        1.1061             nan     0.1000    0.0171
#&gt;      6        1.0639             nan     0.1000    0.0173
#&gt;      7        1.0319             nan     0.1000    0.0125
#&gt;      8        0.9988             nan     0.1000    0.0090
#&gt;      9        0.9691             nan     0.1000    0.0134
#&gt;     10        0.9403             nan     0.1000    0.0099
#&gt;     20        0.7631             nan     0.1000    0.0023
#&gt;     40        0.6010             nan     0.1000   -0.0018
#&gt;     60        0.5020             nan     0.1000    0.0002
#&gt;     80        0.4489             nan     0.1000   -0.0024
#&gt;    100        0.4023             nan     0.1000   -0.0015
#&gt;    120        0.3596             nan     0.1000   -0.0031
#&gt;    140        0.3224             nan     0.1000   -0.0019
#&gt;    160        0.2922             nan     0.1000   -0.0023
#&gt;    180        0.2700             nan     0.1000   -0.0019
#&gt;    200        0.2496             nan     0.1000   -0.0000
#&gt;    220        0.2306             nan     0.1000   -0.0009
#&gt;    240        0.2132             nan     0.1000   -0.0013
#&gt;    260        0.1954             nan     0.1000   -0.0015
#&gt;    280        0.1797             nan     0.1000   -0.0016
#&gt;    300        0.1661             nan     0.1000   -0.0012
#&gt;    320        0.1535             nan     0.1000   -0.0014
#&gt;    340        0.1436             nan     0.1000   -0.0006
#&gt;    360        0.1340             nan     0.1000   -0.0006
#&gt;    380        0.1260             nan     0.1000   -0.0007
#&gt;    400        0.1169             nan     0.1000   -0.0000
#&gt;    420        0.1073             nan     0.1000   -0.0011
#&gt;    440        0.1012             nan     0.1000   -0.0007
#&gt;    460        0.0919             nan     0.1000   -0.0004
#&gt;    480        0.0864             nan     0.1000   -0.0002
#&gt;    500        0.0807             nan     0.1000   -0.0003
#&gt;    520        0.0761             nan     0.1000   -0.0006
#&gt;    540        0.0721             nan     0.1000   -0.0002
#&gt;    560        0.0674             nan     0.1000   -0.0008
#&gt;    580        0.0611             nan     0.1000   -0.0001
#&gt;    600        0.0563             nan     0.1000   -0.0003
#&gt;    620        0.0537             nan     0.1000   -0.0005
#&gt;    640        0.0499             nan     0.1000   -0.0001
#&gt;    660        0.0464             nan     0.1000   -0.0002
#&gt;    680        0.0438             nan     0.1000   -0.0004
#&gt;    700        0.0414             nan     0.1000   -0.0002
#&gt;    720        0.0396             nan     0.1000   -0.0001
#&gt;    740        0.0369             nan     0.1000   -0.0003
#&gt;    760        0.0344             nan     0.1000   -0.0003
#&gt;    780        0.0329             nan     0.1000   -0.0001
#&gt;    800        0.0305             nan     0.1000   -0.0001
#&gt;    820        0.0288             nan     0.1000   -0.0001
#&gt;    840        0.0274             nan     0.1000   -0.0001
#&gt;    860        0.0259             nan     0.1000   -0.0001
#&gt;    880        0.0245             nan     0.1000   -0.0003
#&gt;    900        0.0231             nan     0.1000   -0.0002
#&gt;    920        0.0217             nan     0.1000   -0.0001
#&gt;    940        0.0204             nan     0.1000   -0.0001
#&gt;    960        0.0194             nan     0.1000   -0.0002
#&gt;    980        0.0180             nan     0.1000   -0.0000
#&gt;   1000        0.0172             nan     0.1000   -0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.2894             nan     0.1000    0.0348
#&gt;      2        1.2188             nan     0.1000    0.0264
#&gt;      3        1.1611             nan     0.1000    0.0244
#&gt;      4        1.1102             nan     0.1000    0.0229
#&gt;      5        1.0717             nan     0.1000    0.0073
#&gt;      6        1.0299             nan     0.1000    0.0140
#&gt;      7        0.9893             nan     0.1000    0.0127
#&gt;      8        0.9543             nan     0.1000    0.0121
#&gt;      9        0.9208             nan     0.1000    0.0102
#&gt;     10        0.8992             nan     0.1000    0.0039
#&gt;     20        0.6925             nan     0.1000   -0.0009
#&gt;     40        0.5036             nan     0.1000   -0.0003
#&gt;     60        0.4148             nan     0.1000   -0.0015
#&gt;     80        0.3437             nan     0.1000   -0.0017
#&gt;    100        0.2907             nan     0.1000   -0.0035
#&gt;    120        0.2463             nan     0.1000   -0.0017
#&gt;    140        0.2135             nan     0.1000   -0.0012
#&gt;    160        0.1886             nan     0.1000   -0.0022
#&gt;    180        0.1668             nan     0.1000   -0.0005
#&gt;    200        0.1488             nan     0.1000   -0.0010
#&gt;    220        0.1309             nan     0.1000   -0.0016
#&gt;    240        0.1148             nan     0.1000   -0.0009
#&gt;    260        0.1011             nan     0.1000   -0.0009
#&gt;    280        0.0895             nan     0.1000   -0.0006
#&gt;    300        0.0816             nan     0.1000   -0.0006
#&gt;    320        0.0728             nan     0.1000   -0.0002
#&gt;    340        0.0635             nan     0.1000   -0.0001
#&gt;    360        0.0567             nan     0.1000   -0.0004
#&gt;    380        0.0508             nan     0.1000   -0.0003
#&gt;    400        0.0448             nan     0.1000   -0.0005
#&gt;    420        0.0399             nan     0.1000   -0.0003
#&gt;    440        0.0359             nan     0.1000   -0.0002
#&gt;    460        0.0315             nan     0.1000   -0.0002
#&gt;    480        0.0283             nan     0.1000   -0.0001
#&gt;    500        0.0249             nan     0.1000   -0.0002
#&gt;    520        0.0223             nan     0.1000   -0.0001
#&gt;    540        0.0204             nan     0.1000   -0.0001
#&gt;    560        0.0183             nan     0.1000   -0.0002
#&gt;    580        0.0164             nan     0.1000   -0.0001
#&gt;    600        0.0148             nan     0.1000   -0.0001
#&gt;    620        0.0134             nan     0.1000   -0.0001
#&gt;    640        0.0123             nan     0.1000   -0.0001
#&gt;    660        0.0107             nan     0.1000   -0.0000
#&gt;    680        0.0096             nan     0.1000   -0.0001
#&gt;    700        0.0087             nan     0.1000   -0.0001
#&gt;    720        0.0077             nan     0.1000   -0.0001
#&gt;    740        0.0069             nan     0.1000   -0.0001
#&gt;    760        0.0061             nan     0.1000   -0.0000
#&gt;    780        0.0056             nan     0.1000   -0.0000
#&gt;    800        0.0051             nan     0.1000   -0.0000
#&gt;    820        0.0046             nan     0.1000   -0.0000
#&gt;    840        0.0042             nan     0.1000   -0.0000
#&gt;    860        0.0037             nan     0.1000   -0.0000
#&gt;    880        0.0034             nan     0.1000   -0.0000
#&gt;    900        0.0030             nan     0.1000   -0.0000
#&gt;    920        0.0027             nan     0.1000   -0.0000
#&gt;    940        0.0024             nan     0.1000   -0.0000
#&gt;    960        0.0022             nan     0.1000   -0.0000
#&gt;    980        0.0020             nan     0.1000   -0.0000
#&gt;   1000        0.0018             nan     0.1000   -0.0000
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3788             nan     0.0010    0.0003
#&gt;      2        1.3782             nan     0.0010    0.0003
#&gt;      3        1.3776             nan     0.0010    0.0003
#&gt;      4        1.3771             nan     0.0010    0.0003
#&gt;      5        1.3764             nan     0.0010    0.0003
#&gt;      6        1.3758             nan     0.0010    0.0003
#&gt;      7        1.3751             nan     0.0010    0.0003
#&gt;      8        1.3745             nan     0.0010    0.0003
#&gt;      9        1.3739             nan     0.0010    0.0003
#&gt;     10        1.3735             nan     0.0010    0.0001
#&gt;     20        1.3672             nan     0.0010    0.0003
#&gt;     40        1.3554             nan     0.0010    0.0003
#&gt;     60        1.3438             nan     0.0010    0.0003
#&gt;     80        1.3327             nan     0.0010    0.0002
#&gt;    100        1.3220             nan     0.0010    0.0003
#&gt;    120        1.3125             nan     0.0010    0.0003
#&gt;    140        1.3028             nan     0.0010    0.0002
#&gt;    160        1.2929             nan     0.0010    0.0002
#&gt;    180        1.2840             nan     0.0010    0.0002
#&gt;    200        1.2747             nan     0.0010    0.0002
#&gt;    220        1.2662             nan     0.0010    0.0002
#&gt;    240        1.2577             nan     0.0010    0.0001
#&gt;    260        1.2491             nan     0.0010    0.0001
#&gt;    280        1.2415             nan     0.0010    0.0001
#&gt;    300        1.2335             nan     0.0010    0.0002
#&gt;    320        1.2253             nan     0.0010    0.0002
#&gt;    340        1.2178             nan     0.0010    0.0002
#&gt;    360        1.2100             nan     0.0010    0.0002
#&gt;    380        1.2032             nan     0.0010    0.0001
#&gt;    400        1.1965             nan     0.0010    0.0001
#&gt;    420        1.1898             nan     0.0010    0.0001
#&gt;    440        1.1835             nan     0.0010    0.0001
#&gt;    460        1.1769             nan     0.0010    0.0001
#&gt;    480        1.1707             nan     0.0010    0.0001
#&gt;    500        1.1649             nan     0.0010    0.0001
#&gt;    520        1.1589             nan     0.0010    0.0001
#&gt;    540        1.1531             nan     0.0010    0.0000
#&gt;    560        1.1472             nan     0.0010    0.0001
#&gt;    580        1.1416             nan     0.0010    0.0001
#&gt;    600        1.1361             nan     0.0010    0.0001
#&gt;    620        1.1307             nan     0.0010    0.0001
#&gt;    640        1.1252             nan     0.0010    0.0001
#&gt;    660        1.1197             nan     0.0010    0.0001
#&gt;    680        1.1145             nan     0.0010    0.0001
#&gt;    700        1.1096             nan     0.0010    0.0001
#&gt;    720        1.1045             nan     0.0010    0.0001
#&gt;    740        1.0996             nan     0.0010    0.0001
#&gt;    760        1.0948             nan     0.0010    0.0001
#&gt;    780        1.0900             nan     0.0010    0.0001
#&gt;    800        1.0853             nan     0.0010    0.0001
#&gt;    820        1.0807             nan     0.0010    0.0000
#&gt;    840        1.0764             nan     0.0010    0.0001
#&gt;    860        1.0719             nan     0.0010    0.0001
#&gt;    880        1.0674             nan     0.0010    0.0001
#&gt;    900        1.0632             nan     0.0010    0.0001
#&gt;    920        1.0589             nan     0.0010    0.0000
#&gt;    940        1.0547             nan     0.0010    0.0001
#&gt;    960        1.0505             nan     0.0010    0.0001
#&gt;    980        1.0466             nan     0.0010    0.0001
#&gt;   1000        1.0427             nan     0.0010    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3786             nan     0.0010    0.0003
#&gt;      2        1.3780             nan     0.0010    0.0004
#&gt;      3        1.3772             nan     0.0010    0.0003
#&gt;      4        1.3765             nan     0.0010    0.0003
#&gt;      5        1.3757             nan     0.0010    0.0003
#&gt;      6        1.3749             nan     0.0010    0.0004
#&gt;      7        1.3741             nan     0.0010    0.0003
#&gt;      8        1.3734             nan     0.0010    0.0004
#&gt;      9        1.3726             nan     0.0010    0.0003
#&gt;     10        1.3718             nan     0.0010    0.0003
#&gt;     20        1.3643             nan     0.0010    0.0003
#&gt;     40        1.3504             nan     0.0010    0.0003
#&gt;     60        1.3369             nan     0.0010    0.0003
#&gt;     80        1.3236             nan     0.0010    0.0003
#&gt;    100        1.3106             nan     0.0010    0.0003
#&gt;    120        1.2980             nan     0.0010    0.0003
#&gt;    140        1.2860             nan     0.0010    0.0002
#&gt;    160        1.2741             nan     0.0010    0.0003
#&gt;    180        1.2627             nan     0.0010    0.0003
#&gt;    200        1.2521             nan     0.0010    0.0002
#&gt;    220        1.2410             nan     0.0010    0.0002
#&gt;    240        1.2312             nan     0.0010    0.0002
#&gt;    260        1.2210             nan     0.0010    0.0001
#&gt;    280        1.2112             nan     0.0010    0.0002
#&gt;    300        1.2016             nan     0.0010    0.0002
#&gt;    320        1.1925             nan     0.0010    0.0002
#&gt;    340        1.1832             nan     0.0010    0.0002
#&gt;    360        1.1743             nan     0.0010    0.0002
#&gt;    380        1.1655             nan     0.0010    0.0002
#&gt;    400        1.1575             nan     0.0010    0.0001
#&gt;    420        1.1494             nan     0.0010    0.0002
#&gt;    440        1.1411             nan     0.0010    0.0001
#&gt;    460        1.1332             nan     0.0010    0.0002
#&gt;    480        1.1256             nan     0.0010    0.0002
#&gt;    500        1.1182             nan     0.0010    0.0002
#&gt;    520        1.1107             nan     0.0010    0.0001
#&gt;    540        1.1034             nan     0.0010    0.0002
#&gt;    560        1.0966             nan     0.0010    0.0001
#&gt;    580        1.0893             nan     0.0010    0.0001
#&gt;    600        1.0825             nan     0.0010    0.0001
#&gt;    620        1.0757             nan     0.0010    0.0001
#&gt;    640        1.0689             nan     0.0010    0.0001
#&gt;    660        1.0624             nan     0.0010    0.0001
#&gt;    680        1.0560             nan     0.0010    0.0001
#&gt;    700        1.0498             nan     0.0010    0.0001
#&gt;    720        1.0436             nan     0.0010    0.0001
#&gt;    740        1.0377             nan     0.0010    0.0001
#&gt;    760        1.0322             nan     0.0010    0.0001
#&gt;    780        1.0264             nan     0.0010    0.0000
#&gt;    800        1.0205             nan     0.0010    0.0001
#&gt;    820        1.0150             nan     0.0010    0.0001
#&gt;    840        1.0098             nan     0.0010    0.0001
#&gt;    860        1.0045             nan     0.0010    0.0001
#&gt;    880        0.9992             nan     0.0010    0.0000
#&gt;    900        0.9942             nan     0.0010    0.0001
#&gt;    920        0.9892             nan     0.0010    0.0001
#&gt;    940        0.9842             nan     0.0010    0.0001
#&gt;    960        0.9792             nan     0.0010    0.0001
#&gt;    980        0.9743             nan     0.0010    0.0001
#&gt;   1000        0.9697             nan     0.0010    0.0000
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3786             nan     0.0010    0.0003
#&gt;      2        1.3779             nan     0.0010    0.0003
#&gt;      3        1.3770             nan     0.0010    0.0003
#&gt;      4        1.3762             nan     0.0010    0.0003
#&gt;      5        1.3754             nan     0.0010    0.0004
#&gt;      6        1.3746             nan     0.0010    0.0004
#&gt;      7        1.3738             nan     0.0010    0.0004
#&gt;      8        1.3730             nan     0.0010    0.0004
#&gt;      9        1.3721             nan     0.0010    0.0004
#&gt;     10        1.3712             nan     0.0010    0.0004
#&gt;     20        1.3628             nan     0.0010    0.0003
#&gt;     40        1.3467             nan     0.0010    0.0003
#&gt;     60        1.3309             nan     0.0010    0.0004
#&gt;     80        1.3159             nan     0.0010    0.0003
#&gt;    100        1.3013             nan     0.0010    0.0003
#&gt;    120        1.2871             nan     0.0010    0.0003
#&gt;    140        1.2732             nan     0.0010    0.0003
#&gt;    160        1.2602             nan     0.0010    0.0003
#&gt;    180        1.2473             nan     0.0010    0.0002
#&gt;    200        1.2347             nan     0.0010    0.0002
#&gt;    220        1.2228             nan     0.0010    0.0002
#&gt;    240        1.2108             nan     0.0010    0.0002
#&gt;    260        1.1990             nan     0.0010    0.0002
#&gt;    280        1.1876             nan     0.0010    0.0002
#&gt;    300        1.1764             nan     0.0010    0.0002
#&gt;    320        1.1662             nan     0.0010    0.0002
#&gt;    340        1.1562             nan     0.0010    0.0002
#&gt;    360        1.1461             nan     0.0010    0.0002
#&gt;    380        1.1365             nan     0.0010    0.0002
#&gt;    400        1.1271             nan     0.0010    0.0001
#&gt;    420        1.1176             nan     0.0010    0.0002
#&gt;    440        1.1084             nan     0.0010    0.0002
#&gt;    460        1.0995             nan     0.0010    0.0002
#&gt;    480        1.0906             nan     0.0010    0.0002
#&gt;    500        1.0820             nan     0.0010    0.0002
#&gt;    520        1.0736             nan     0.0010    0.0001
#&gt;    540        1.0654             nan     0.0010    0.0001
#&gt;    560        1.0572             nan     0.0010    0.0001
#&gt;    580        1.0497             nan     0.0010    0.0002
#&gt;    600        1.0419             nan     0.0010    0.0001
#&gt;    620        1.0345             nan     0.0010    0.0001
#&gt;    640        1.0276             nan     0.0010    0.0001
#&gt;    660        1.0200             nan     0.0010    0.0001
#&gt;    680        1.0132             nan     0.0010    0.0001
#&gt;    700        1.0065             nan     0.0010    0.0001
#&gt;    720        0.9996             nan     0.0010    0.0001
#&gt;    740        0.9930             nan     0.0010    0.0001
#&gt;    760        0.9866             nan     0.0010    0.0001
#&gt;    780        0.9804             nan     0.0010    0.0001
#&gt;    800        0.9744             nan     0.0010    0.0001
#&gt;    820        0.9680             nan     0.0010    0.0001
#&gt;    840        0.9621             nan     0.0010    0.0001
#&gt;    860        0.9565             nan     0.0010    0.0001
#&gt;    880        0.9511             nan     0.0010    0.0001
#&gt;    900        0.9457             nan     0.0010    0.0001
#&gt;    920        0.9403             nan     0.0010    0.0001
#&gt;    940        0.9346             nan     0.0010    0.0001
#&gt;    960        0.9293             nan     0.0010    0.0001
#&gt;    980        0.9239             nan     0.0010    0.0001
#&gt;   1000        0.9188             nan     0.0010    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3741             nan     0.0100    0.0031
#&gt;      2        1.3679             nan     0.0100    0.0032
#&gt;      3        1.3610             nan     0.0100    0.0031
#&gt;      4        1.3556             nan     0.0100    0.0026
#&gt;      5        1.3504             nan     0.0100    0.0017
#&gt;      6        1.3444             nan     0.0100    0.0029
#&gt;      7        1.3388             nan     0.0100    0.0025
#&gt;      8        1.3329             nan     0.0100    0.0028
#&gt;      9        1.3292             nan     0.0100    0.0021
#&gt;     10        1.3236             nan     0.0100    0.0021
#&gt;     20        1.2713             nan     0.0100    0.0019
#&gt;     40        1.1987             nan     0.0100    0.0010
#&gt;     60        1.1360             nan     0.0100    0.0009
#&gt;     80        1.0841             nan     0.0100    0.0009
#&gt;    100        1.0413             nan     0.0100    0.0007
#&gt;    120        1.0040             nan     0.0100    0.0004
#&gt;    140        0.9733             nan     0.0100    0.0004
#&gt;    160        0.9450             nan     0.0100    0.0006
#&gt;    180        0.9196             nan     0.0100    0.0002
#&gt;    200        0.8987             nan     0.0100    0.0001
#&gt;    220        0.8800             nan     0.0100    0.0002
#&gt;    240        0.8626             nan     0.0100    0.0001
#&gt;    260        0.8479             nan     0.0100    0.0001
#&gt;    280        0.8327             nan     0.0100    0.0002
#&gt;    300        0.8213             nan     0.0100    0.0002
#&gt;    320        0.8108             nan     0.0100    0.0001
#&gt;    340        0.8000             nan     0.0100   -0.0001
#&gt;    360        0.7907             nan     0.0100   -0.0000
#&gt;    380        0.7810             nan     0.0100    0.0000
#&gt;    400        0.7724             nan     0.0100   -0.0001
#&gt;    420        0.7648             nan     0.0100   -0.0000
#&gt;    440        0.7571             nan     0.0100   -0.0001
#&gt;    460        0.7497             nan     0.0100   -0.0000
#&gt;    480        0.7431             nan     0.0100   -0.0000
#&gt;    500        0.7358             nan     0.0100   -0.0001
#&gt;    520        0.7291             nan     0.0100   -0.0002
#&gt;    540        0.7225             nan     0.0100   -0.0001
#&gt;    560        0.7168             nan     0.0100   -0.0001
#&gt;    580        0.7113             nan     0.0100   -0.0000
#&gt;    600        0.7061             nan     0.0100   -0.0000
#&gt;    620        0.7009             nan     0.0100   -0.0001
#&gt;    640        0.6962             nan     0.0100   -0.0002
#&gt;    660        0.6912             nan     0.0100   -0.0002
#&gt;    680        0.6869             nan     0.0100    0.0000
#&gt;    700        0.6827             nan     0.0100   -0.0001
#&gt;    720        0.6788             nan     0.0100   -0.0004
#&gt;    740        0.6749             nan     0.0100   -0.0002
#&gt;    760        0.6712             nan     0.0100   -0.0000
#&gt;    780        0.6680             nan     0.0100   -0.0000
#&gt;    800        0.6650             nan     0.0100   -0.0002
#&gt;    820        0.6614             nan     0.0100   -0.0001
#&gt;    840        0.6576             nan     0.0100   -0.0001
#&gt;    860        0.6541             nan     0.0100   -0.0002
#&gt;    880        0.6509             nan     0.0100   -0.0002
#&gt;    900        0.6478             nan     0.0100   -0.0000
#&gt;    920        0.6449             nan     0.0100   -0.0003
#&gt;    940        0.6420             nan     0.0100   -0.0000
#&gt;    960        0.6394             nan     0.0100   -0.0002
#&gt;    980        0.6366             nan     0.0100   -0.0003
#&gt;   1000        0.6339             nan     0.0100   -0.0003
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3723             nan     0.0100    0.0037
#&gt;      2        1.3658             nan     0.0100    0.0017
#&gt;      3        1.3588             nan     0.0100    0.0033
#&gt;      4        1.3519             nan     0.0100    0.0033
#&gt;      5        1.3450             nan     0.0100    0.0034
#&gt;      6        1.3377             nan     0.0100    0.0027
#&gt;      7        1.3311             nan     0.0100    0.0032
#&gt;      8        1.3264             nan     0.0100    0.0020
#&gt;      9        1.3195             nan     0.0100    0.0033
#&gt;     10        1.3146             nan     0.0100    0.0021
#&gt;     20        1.2547             nan     0.0100    0.0024
#&gt;     40        1.1567             nan     0.0100    0.0017
#&gt;     60        1.0820             nan     0.0100    0.0013
#&gt;     80        1.0185             nan     0.0100    0.0011
#&gt;    100        0.9689             nan     0.0100    0.0008
#&gt;    120        0.9257             nan     0.0100    0.0004
#&gt;    140        0.8878             nan     0.0100    0.0005
#&gt;    160        0.8561             nan     0.0100    0.0006
#&gt;    180        0.8282             nan     0.0100    0.0002
#&gt;    200        0.8047             nan     0.0100   -0.0001
#&gt;    220        0.7846             nan     0.0100    0.0001
#&gt;    240        0.7650             nan     0.0100   -0.0003
#&gt;    260        0.7497             nan     0.0100    0.0000
#&gt;    280        0.7326             nan     0.0100    0.0002
#&gt;    300        0.7169             nan     0.0100    0.0003
#&gt;    320        0.7044             nan     0.0100   -0.0001
#&gt;    340        0.6909             nan     0.0100   -0.0003
#&gt;    360        0.6795             nan     0.0100   -0.0000
#&gt;    380        0.6687             nan     0.0100   -0.0000
#&gt;    400        0.6576             nan     0.0100   -0.0002
#&gt;    420        0.6493             nan     0.0100    0.0000
#&gt;    440        0.6398             nan     0.0100   -0.0000
#&gt;    460        0.6311             nan     0.0100   -0.0003
#&gt;    480        0.6225             nan     0.0100   -0.0003
#&gt;    500        0.6144             nan     0.0100   -0.0001
#&gt;    520        0.6063             nan     0.0100   -0.0002
#&gt;    540        0.5997             nan     0.0100   -0.0003
#&gt;    560        0.5935             nan     0.0100   -0.0002
#&gt;    580        0.5876             nan     0.0100   -0.0002
#&gt;    600        0.5817             nan     0.0100   -0.0002
#&gt;    620        0.5753             nan     0.0100   -0.0003
#&gt;    640        0.5692             nan     0.0100   -0.0002
#&gt;    660        0.5626             nan     0.0100   -0.0001
#&gt;    680        0.5569             nan     0.0100   -0.0003
#&gt;    700        0.5516             nan     0.0100   -0.0003
#&gt;    720        0.5461             nan     0.0100   -0.0003
#&gt;    740        0.5403             nan     0.0100   -0.0001
#&gt;    760        0.5357             nan     0.0100   -0.0004
#&gt;    780        0.5307             nan     0.0100   -0.0002
#&gt;    800        0.5251             nan     0.0100   -0.0003
#&gt;    820        0.5203             nan     0.0100   -0.0004
#&gt;    840        0.5153             nan     0.0100   -0.0001
#&gt;    860        0.5111             nan     0.0100   -0.0002
#&gt;    880        0.5067             nan     0.0100   -0.0004
#&gt;    900        0.5027             nan     0.0100   -0.0003
#&gt;    920        0.4986             nan     0.0100   -0.0003
#&gt;    940        0.4939             nan     0.0100   -0.0002
#&gt;    960        0.4889             nan     0.0100   -0.0002
#&gt;    980        0.4851             nan     0.0100   -0.0005
#&gt;   1000        0.4814             nan     0.0100   -0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3712             nan     0.0100    0.0037
#&gt;      2        1.3627             nan     0.0100    0.0037
#&gt;      3        1.3548             nan     0.0100    0.0034
#&gt;      4        1.3477             nan     0.0100    0.0032
#&gt;      5        1.3397             nan     0.0100    0.0027
#&gt;      6        1.3312             nan     0.0100    0.0033
#&gt;      7        1.3234             nan     0.0100    0.0034
#&gt;      8        1.3155             nan     0.0100    0.0034
#&gt;      9        1.3092             nan     0.0100    0.0031
#&gt;     10        1.3015             nan     0.0100    0.0033
#&gt;     20        1.2337             nan     0.0100    0.0026
#&gt;     40        1.1297             nan     0.0100    0.0015
#&gt;     60        1.0470             nan     0.0100    0.0021
#&gt;     80        0.9771             nan     0.0100    0.0009
#&gt;    100        0.9222             nan     0.0100    0.0009
#&gt;    120        0.8747             nan     0.0100    0.0005
#&gt;    140        0.8336             nan     0.0100    0.0007
#&gt;    160        0.7973             nan     0.0100    0.0003
#&gt;    180        0.7662             nan     0.0100    0.0000
#&gt;    200        0.7385             nan     0.0100    0.0001
#&gt;    220        0.7164             nan     0.0100   -0.0002
#&gt;    240        0.6957             nan     0.0100   -0.0000
#&gt;    260        0.6759             nan     0.0100   -0.0003
#&gt;    280        0.6592             nan     0.0100   -0.0002
#&gt;    300        0.6433             nan     0.0100    0.0000
#&gt;    320        0.6286             nan     0.0100    0.0000
#&gt;    340        0.6151             nan     0.0100   -0.0001
#&gt;    360        0.6014             nan     0.0100   -0.0003
#&gt;    380        0.5894             nan     0.0100    0.0001
#&gt;    400        0.5766             nan     0.0100   -0.0003
#&gt;    420        0.5651             nan     0.0100    0.0002
#&gt;    440        0.5547             nan     0.0100    0.0000
#&gt;    460        0.5449             nan     0.0100    0.0001
#&gt;    480        0.5356             nan     0.0100   -0.0003
#&gt;    500        0.5264             nan     0.0100   -0.0001
#&gt;    520        0.5177             nan     0.0100   -0.0002
#&gt;    540        0.5088             nan     0.0100   -0.0003
#&gt;    560        0.5001             nan     0.0100   -0.0001
#&gt;    580        0.4924             nan     0.0100   -0.0002
#&gt;    600        0.4846             nan     0.0100   -0.0001
#&gt;    620        0.4777             nan     0.0100   -0.0003
#&gt;    640        0.4706             nan     0.0100   -0.0005
#&gt;    660        0.4635             nan     0.0100   -0.0003
#&gt;    680        0.4562             nan     0.0100   -0.0003
#&gt;    700        0.4501             nan     0.0100   -0.0000
#&gt;    720        0.4432             nan     0.0100   -0.0004
#&gt;    740        0.4372             nan     0.0100   -0.0003
#&gt;    760        0.4312             nan     0.0100   -0.0002
#&gt;    780        0.4252             nan     0.0100   -0.0000
#&gt;    800        0.4205             nan     0.0100   -0.0003
#&gt;    820        0.4146             nan     0.0100   -0.0002
#&gt;    840        0.4099             nan     0.0100   -0.0003
#&gt;    860        0.4047             nan     0.0100   -0.0002
#&gt;    880        0.3999             nan     0.0100   -0.0005
#&gt;    900        0.3946             nan     0.0100   -0.0004
#&gt;    920        0.3898             nan     0.0100   -0.0002
#&gt;    940        0.3846             nan     0.0100   -0.0003
#&gt;    960        0.3791             nan     0.0100   -0.0001
#&gt;    980        0.3746             nan     0.0100   -0.0003
#&gt;   1000        0.3701             nan     0.0100   -0.0003
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3160             nan     0.1000    0.0307
#&gt;      2        1.2688             nan     0.1000    0.0245
#&gt;      3        1.2404             nan     0.1000    0.0120
#&gt;      4        1.2127             nan     0.1000    0.0102
#&gt;      5        1.1765             nan     0.1000    0.0180
#&gt;      6        1.1425             nan     0.1000    0.0139
#&gt;      7        1.1207             nan     0.1000    0.0050
#&gt;      8        1.0924             nan     0.1000    0.0133
#&gt;      9        1.0688             nan     0.1000    0.0056
#&gt;     10        1.0477             nan     0.1000    0.0106
#&gt;     20        0.9010             nan     0.1000    0.0052
#&gt;     40        0.7725             nan     0.1000   -0.0020
#&gt;     60        0.7098             nan     0.1000   -0.0004
#&gt;     80        0.6683             nan     0.1000   -0.0038
#&gt;    100        0.6377             nan     0.1000   -0.0015
#&gt;    120        0.6139             nan     0.1000   -0.0020
#&gt;    140        0.5907             nan     0.1000   -0.0003
#&gt;    160        0.5720             nan     0.1000   -0.0013
#&gt;    180        0.5581             nan     0.1000   -0.0007
#&gt;    200        0.5423             nan     0.1000   -0.0020
#&gt;    220        0.5285             nan     0.1000   -0.0008
#&gt;    240        0.5220             nan     0.1000   -0.0028
#&gt;    260        0.5074             nan     0.1000   -0.0004
#&gt;    280        0.4970             nan     0.1000   -0.0022
#&gt;    300        0.4917             nan     0.1000   -0.0025
#&gt;    320        0.4755             nan     0.1000   -0.0023
#&gt;    340        0.4747             nan     0.1000   -0.0021
#&gt;    360        0.4654             nan     0.1000   -0.0028
#&gt;    380        0.4577             nan     0.1000   -0.0043
#&gt;    400        0.4459             nan     0.1000   -0.0038
#&gt;    420        0.4337             nan     0.1000   -0.0030
#&gt;    440        0.4252             nan     0.1000   -0.0012
#&gt;    460        0.4183             nan     0.1000   -0.0008
#&gt;    480        0.4104             nan     0.1000   -0.0020
#&gt;    500        0.4037             nan     0.1000    0.0001
#&gt;    520        0.3957             nan     0.1000   -0.0024
#&gt;    540        0.3904             nan     0.1000   -0.0021
#&gt;    560        0.3826             nan     0.1000   -0.0010
#&gt;    580        0.3761             nan     0.1000   -0.0012
#&gt;    600        0.3686             nan     0.1000   -0.0032
#&gt;    620        0.3631             nan     0.1000   -0.0020
#&gt;    640        0.3555             nan     0.1000   -0.0017
#&gt;    660        0.3508             nan     0.1000   -0.0008
#&gt;    680        0.3468             nan     0.1000   -0.0011
#&gt;    700        0.3413             nan     0.1000   -0.0013
#&gt;    720        0.3410             nan     0.1000   -0.0009
#&gt;    740        0.3368             nan     0.1000   -0.0041
#&gt;    760        0.3315             nan     0.1000   -0.0013
#&gt;    780        0.3247             nan     0.1000   -0.0007
#&gt;    800        0.3201             nan     0.1000   -0.0007
#&gt;    820        0.3146             nan     0.1000   -0.0008
#&gt;    840        0.3097             nan     0.1000   -0.0027
#&gt;    860        0.3067             nan     0.1000   -0.0014
#&gt;    880        0.3026             nan     0.1000   -0.0012
#&gt;    900        0.3021             nan     0.1000   -0.0019
#&gt;    920        0.2964             nan     0.1000   -0.0013
#&gt;    940        0.2928             nan     0.1000   -0.0008
#&gt;    960        0.2923             nan     0.1000   -0.0016
#&gt;    980        0.2928             nan     0.1000   -0.0007
#&gt;   1000        0.2874             nan     0.1000   -0.0021
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3056             nan     0.1000    0.0331
#&gt;      2        1.2552             nan     0.1000    0.0191
#&gt;      3        1.1962             nan     0.1000    0.0234
#&gt;      4        1.1519             nan     0.1000    0.0174
#&gt;      5        1.1183             nan     0.1000    0.0094
#&gt;      6        1.0796             nan     0.1000    0.0140
#&gt;      7        1.0469             nan     0.1000    0.0106
#&gt;      8        1.0200             nan     0.1000    0.0105
#&gt;      9        0.9930             nan     0.1000    0.0082
#&gt;     10        0.9664             nan     0.1000    0.0092
#&gt;     20        0.8026             nan     0.1000    0.0005
#&gt;     40        0.6610             nan     0.1000   -0.0003
#&gt;     60        0.5878             nan     0.1000   -0.0026
#&gt;     80        0.5259             nan     0.1000   -0.0023
#&gt;    100        0.4881             nan     0.1000   -0.0020
#&gt;    120        0.4477             nan     0.1000   -0.0030
#&gt;    140        0.4215             nan     0.1000   -0.0019
#&gt;    160        0.3942             nan     0.1000   -0.0031
#&gt;    180        0.3657             nan     0.1000   -0.0007
#&gt;    200        0.3415             nan     0.1000   -0.0017
#&gt;    220        0.3241             nan     0.1000   -0.0021
#&gt;    240        0.3061             nan     0.1000   -0.0011
#&gt;    260        0.2863             nan     0.1000   -0.0032
#&gt;    280        0.2678             nan     0.1000   -0.0014
#&gt;    300        0.2521             nan     0.1000   -0.0020
#&gt;    320        0.2401             nan     0.1000   -0.0022
#&gt;    340        0.2269             nan     0.1000   -0.0015
#&gt;    360        0.2115             nan     0.1000   -0.0026
#&gt;    380        0.1990             nan     0.1000   -0.0022
#&gt;    400        0.1881             nan     0.1000   -0.0010
#&gt;    420        0.1771             nan     0.1000   -0.0001
#&gt;    440        0.1666             nan     0.1000   -0.0013
#&gt;    460        0.1613             nan     0.1000   -0.0006
#&gt;    480        0.1524             nan     0.1000   -0.0016
#&gt;    500        0.1453             nan     0.1000   -0.0013
#&gt;    520        0.1400             nan     0.1000   -0.0007
#&gt;    540        0.1332             nan     0.1000   -0.0010
#&gt;    560        0.1299             nan     0.1000   -0.0019
#&gt;    580        0.1234             nan     0.1000   -0.0011
#&gt;    600        0.1169             nan     0.1000   -0.0011
#&gt;    620        0.1123             nan     0.1000   -0.0007
#&gt;    640        0.1047             nan     0.1000   -0.0004
#&gt;    660        0.1000             nan     0.1000   -0.0005
#&gt;    680        0.0966             nan     0.1000   -0.0006
#&gt;    700        0.0913             nan     0.1000   -0.0004
#&gt;    720        0.0873             nan     0.1000   -0.0006
#&gt;    740        0.0837             nan     0.1000   -0.0009
#&gt;    760        0.0805             nan     0.1000   -0.0004
#&gt;    780        0.0773             nan     0.1000   -0.0008
#&gt;    800        0.0732             nan     0.1000   -0.0006
#&gt;    820        0.0706             nan     0.1000   -0.0007
#&gt;    840        0.0677             nan     0.1000   -0.0007
#&gt;    860        0.0654             nan     0.1000   -0.0004
#&gt;    880        0.0635             nan     0.1000   -0.0005
#&gt;    900        0.0592             nan     0.1000   -0.0001
#&gt;    920        0.0567             nan     0.1000   -0.0004
#&gt;    940        0.0540             nan     0.1000   -0.0003
#&gt;    960        0.0515             nan     0.1000   -0.0002
#&gt;    980        0.0485             nan     0.1000   -0.0004
#&gt;   1000        0.0466             nan     0.1000   -0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.2916             nan     0.1000    0.0386
#&gt;      2        1.2245             nan     0.1000    0.0296
#&gt;      3        1.1656             nan     0.1000    0.0268
#&gt;      4        1.1110             nan     0.1000    0.0144
#&gt;      5        1.0679             nan     0.1000    0.0142
#&gt;      6        1.0252             nan     0.1000    0.0144
#&gt;      7        0.9897             nan     0.1000    0.0124
#&gt;      8        0.9729             nan     0.1000   -0.0008
#&gt;      9        0.9469             nan     0.1000    0.0076
#&gt;     10        0.9296             nan     0.1000    0.0007
#&gt;     20        0.7427             nan     0.1000    0.0027
#&gt;     40        0.5822             nan     0.1000   -0.0016
#&gt;     60        0.4878             nan     0.1000   -0.0034
#&gt;     80        0.4210             nan     0.1000   -0.0028
#&gt;    100        0.3702             nan     0.1000   -0.0024
#&gt;    120        0.3286             nan     0.1000   -0.0012
#&gt;    140        0.2951             nan     0.1000   -0.0043
#&gt;    160        0.2642             nan     0.1000   -0.0014
#&gt;    180        0.2343             nan     0.1000   -0.0009
#&gt;    200        0.2086             nan     0.1000   -0.0007
#&gt;    220        0.1896             nan     0.1000   -0.0016
#&gt;    240        0.1725             nan     0.1000   -0.0010
#&gt;    260        0.1583             nan     0.1000   -0.0007
#&gt;    280        0.1454             nan     0.1000   -0.0002
#&gt;    300        0.1315             nan     0.1000   -0.0010
#&gt;    320        0.1184             nan     0.1000   -0.0010
#&gt;    340        0.1082             nan     0.1000   -0.0008
#&gt;    360        0.0999             nan     0.1000   -0.0005
#&gt;    380        0.0921             nan     0.1000   -0.0002
#&gt;    400        0.0837             nan     0.1000   -0.0006
#&gt;    420        0.0782             nan     0.1000   -0.0012
#&gt;    440        0.0714             nan     0.1000   -0.0005
#&gt;    460        0.0651             nan     0.1000   -0.0003
#&gt;    480        0.0600             nan     0.1000   -0.0004
#&gt;    500        0.0551             nan     0.1000   -0.0004
#&gt;    520        0.0510             nan     0.1000   -0.0007
#&gt;    540        0.0468             nan     0.1000   -0.0003
#&gt;    560        0.0423             nan     0.1000   -0.0003
#&gt;    580        0.0380             nan     0.1000   -0.0002
#&gt;    600        0.0354             nan     0.1000   -0.0004
#&gt;    620        0.0327             nan     0.1000   -0.0004
#&gt;    640        0.0305             nan     0.1000   -0.0002
#&gt;    660        0.0280             nan     0.1000   -0.0003
#&gt;    680        0.0258             nan     0.1000   -0.0002
#&gt;    700        0.0243             nan     0.1000   -0.0002
#&gt;    720        0.0226             nan     0.1000   -0.0002
#&gt;    740        0.0211             nan     0.1000   -0.0001
#&gt;    760        0.0194             nan     0.1000   -0.0002
#&gt;    780        0.0175             nan     0.1000   -0.0002
#&gt;    800        0.0161             nan     0.1000   -0.0001
#&gt;    820        0.0150             nan     0.1000   -0.0001
#&gt;    840        0.0140             nan     0.1000   -0.0001
#&gt;    860        0.0129             nan     0.1000   -0.0000
#&gt;    880        0.0117             nan     0.1000   -0.0001
#&gt;    900        0.0106             nan     0.1000   -0.0001
#&gt;    920        0.0098             nan     0.1000   -0.0001
#&gt;    940        0.0092             nan     0.1000   -0.0001
#&gt;    960        0.0085             nan     0.1000   -0.0000
#&gt;    980        0.0079             nan     0.1000   -0.0001
#&gt;   1000        0.0073             nan     0.1000   -0.0000
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3790             nan     0.0010    0.0002
#&gt;      2        1.3784             nan     0.0010    0.0003
#&gt;      3        1.3779             nan     0.0010    0.0002
#&gt;      4        1.3773             nan     0.0010    0.0002
#&gt;      5        1.3766             nan     0.0010    0.0003
#&gt;      6        1.3760             nan     0.0010    0.0003
#&gt;      7        1.3756             nan     0.0010    0.0001
#&gt;      8        1.3751             nan     0.0010    0.0003
#&gt;      9        1.3746             nan     0.0010    0.0002
#&gt;     10        1.3740             nan     0.0010    0.0003
#&gt;     20        1.3686             nan     0.0010    0.0003
#&gt;     40        1.3581             nan     0.0010    0.0001
#&gt;     60        1.3476             nan     0.0010    0.0002
#&gt;     80        1.3372             nan     0.0010    0.0002
#&gt;    100        1.3276             nan     0.0010    0.0002
#&gt;    120        1.3182             nan     0.0010    0.0002
#&gt;    140        1.3092             nan     0.0010    0.0002
#&gt;    160        1.3003             nan     0.0010    0.0001
#&gt;    180        1.2916             nan     0.0010    0.0002
#&gt;    200        1.2831             nan     0.0010    0.0002
#&gt;    220        1.2750             nan     0.0010    0.0002
#&gt;    240        1.2670             nan     0.0010    0.0002
#&gt;    260        1.2588             nan     0.0010    0.0002
#&gt;    280        1.2510             nan     0.0010    0.0002
#&gt;    300        1.2433             nan     0.0010    0.0001
#&gt;    320        1.2358             nan     0.0010    0.0002
#&gt;    340        1.2289             nan     0.0010    0.0001
#&gt;    360        1.2220             nan     0.0010    0.0001
#&gt;    380        1.2149             nan     0.0010    0.0001
#&gt;    400        1.2078             nan     0.0010    0.0001
#&gt;    420        1.2011             nan     0.0010    0.0002
#&gt;    440        1.1948             nan     0.0010    0.0001
#&gt;    460        1.1882             nan     0.0010    0.0001
#&gt;    480        1.1818             nan     0.0010    0.0001
#&gt;    500        1.1758             nan     0.0010    0.0001
#&gt;    520        1.1697             nan     0.0010    0.0001
#&gt;    540        1.1636             nan     0.0010    0.0001
#&gt;    560        1.1574             nan     0.0010    0.0001
#&gt;    580        1.1516             nan     0.0010    0.0001
#&gt;    600        1.1462             nan     0.0010    0.0001
#&gt;    620        1.1406             nan     0.0010    0.0001
#&gt;    640        1.1352             nan     0.0010    0.0001
#&gt;    660        1.1299             nan     0.0010    0.0001
#&gt;    680        1.1247             nan     0.0010    0.0001
#&gt;    700        1.1196             nan     0.0010    0.0001
#&gt;    720        1.1145             nan     0.0010    0.0001
#&gt;    740        1.1094             nan     0.0010    0.0001
#&gt;    760        1.1047             nan     0.0010    0.0001
#&gt;    780        1.0999             nan     0.0010    0.0001
#&gt;    800        1.0952             nan     0.0010    0.0001
#&gt;    820        1.0903             nan     0.0010    0.0001
#&gt;    840        1.0857             nan     0.0010    0.0001
#&gt;    860        1.0809             nan     0.0010    0.0001
#&gt;    880        1.0766             nan     0.0010    0.0001
#&gt;    900        1.0726             nan     0.0010    0.0000
#&gt;    920        1.0682             nan     0.0010    0.0001
#&gt;    940        1.0641             nan     0.0010    0.0000
#&gt;    960        1.0600             nan     0.0010    0.0000
#&gt;    980        1.0558             nan     0.0010    0.0001
#&gt;   1000        1.0517             nan     0.0010    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3788             nan     0.0010    0.0003
#&gt;      2        1.3782             nan     0.0010    0.0002
#&gt;      3        1.3775             nan     0.0010    0.0003
#&gt;      4        1.3768             nan     0.0010    0.0003
#&gt;      5        1.3762             nan     0.0010    0.0003
#&gt;      6        1.3755             nan     0.0010    0.0002
#&gt;      7        1.3747             nan     0.0010    0.0003
#&gt;      8        1.3740             nan     0.0010    0.0003
#&gt;      9        1.3734             nan     0.0010    0.0002
#&gt;     10        1.3728             nan     0.0010    0.0003
#&gt;     20        1.3662             nan     0.0010    0.0003
#&gt;     40        1.3527             nan     0.0010    0.0003
#&gt;     60        1.3395             nan     0.0010    0.0003
#&gt;     80        1.3265             nan     0.0010    0.0002
#&gt;    100        1.3137             nan     0.0010    0.0003
#&gt;    120        1.3010             nan     0.0010    0.0003
#&gt;    140        1.2891             nan     0.0010    0.0002
#&gt;    160        1.2775             nan     0.0010    0.0002
#&gt;    180        1.2667             nan     0.0010    0.0001
#&gt;    200        1.2556             nan     0.0010    0.0002
#&gt;    220        1.2449             nan     0.0010    0.0002
#&gt;    240        1.2347             nan     0.0010    0.0002
#&gt;    260        1.2248             nan     0.0010    0.0002
#&gt;    280        1.2148             nan     0.0010    0.0002
#&gt;    300        1.2052             nan     0.0010    0.0001
#&gt;    320        1.1962             nan     0.0010    0.0002
#&gt;    340        1.1867             nan     0.0010    0.0002
#&gt;    360        1.1778             nan     0.0010    0.0002
#&gt;    380        1.1691             nan     0.0010    0.0002
#&gt;    400        1.1606             nan     0.0010    0.0001
#&gt;    420        1.1522             nan     0.0010    0.0002
#&gt;    440        1.1437             nan     0.0010    0.0002
#&gt;    460        1.1357             nan     0.0010    0.0002
#&gt;    480        1.1281             nan     0.0010    0.0002
#&gt;    500        1.1201             nan     0.0010    0.0001
#&gt;    520        1.1129             nan     0.0010    0.0001
#&gt;    540        1.1054             nan     0.0010    0.0001
#&gt;    560        1.0982             nan     0.0010    0.0001
#&gt;    580        1.0910             nan     0.0010    0.0001
#&gt;    600        1.0841             nan     0.0010    0.0002
#&gt;    620        1.0773             nan     0.0010    0.0001
#&gt;    640        1.0707             nan     0.0010    0.0001
#&gt;    660        1.0640             nan     0.0010    0.0001
#&gt;    680        1.0574             nan     0.0010    0.0001
#&gt;    700        1.0511             nan     0.0010    0.0001
#&gt;    720        1.0448             nan     0.0010    0.0001
#&gt;    740        1.0389             nan     0.0010    0.0001
#&gt;    760        1.0331             nan     0.0010    0.0001
#&gt;    780        1.0272             nan     0.0010    0.0001
#&gt;    800        1.0212             nan     0.0010    0.0001
#&gt;    820        1.0158             nan     0.0010    0.0001
#&gt;    840        1.0102             nan     0.0010    0.0001
#&gt;    860        1.0048             nan     0.0010    0.0001
#&gt;    880        0.9994             nan     0.0010    0.0001
#&gt;    900        0.9943             nan     0.0010    0.0001
#&gt;    920        0.9889             nan     0.0010    0.0001
#&gt;    940        0.9837             nan     0.0010    0.0001
#&gt;    960        0.9789             nan     0.0010    0.0001
#&gt;    980        0.9740             nan     0.0010    0.0001
#&gt;   1000        0.9691             nan     0.0010    0.0000
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3787             nan     0.0010    0.0003
#&gt;      2        1.3779             nan     0.0010    0.0004
#&gt;      3        1.3770             nan     0.0010    0.0003
#&gt;      4        1.3762             nan     0.0010    0.0003
#&gt;      5        1.3754             nan     0.0010    0.0004
#&gt;      6        1.3746             nan     0.0010    0.0004
#&gt;      7        1.3738             nan     0.0010    0.0004
#&gt;      8        1.3729             nan     0.0010    0.0004
#&gt;      9        1.3721             nan     0.0010    0.0004
#&gt;     10        1.3713             nan     0.0010    0.0003
#&gt;     20        1.3632             nan     0.0010    0.0003
#&gt;     40        1.3476             nan     0.0010    0.0003
#&gt;     60        1.3325             nan     0.0010    0.0004
#&gt;     80        1.3177             nan     0.0010    0.0003
#&gt;    100        1.3029             nan     0.0010    0.0003
#&gt;    120        1.2892             nan     0.0010    0.0002
#&gt;    140        1.2758             nan     0.0010    0.0002
#&gt;    160        1.2627             nan     0.0010    0.0003
#&gt;    180        1.2497             nan     0.0010    0.0003
#&gt;    200        1.2373             nan     0.0010    0.0002
#&gt;    220        1.2255             nan     0.0010    0.0003
#&gt;    240        1.2137             nan     0.0010    0.0003
#&gt;    260        1.2020             nan     0.0010    0.0002
#&gt;    280        1.1904             nan     0.0010    0.0002
#&gt;    300        1.1794             nan     0.0010    0.0002
#&gt;    320        1.1688             nan     0.0010    0.0002
#&gt;    340        1.1584             nan     0.0010    0.0001
#&gt;    360        1.1480             nan     0.0010    0.0002
#&gt;    380        1.1381             nan     0.0010    0.0002
#&gt;    400        1.1282             nan     0.0010    0.0002
#&gt;    420        1.1184             nan     0.0010    0.0002
#&gt;    440        1.1092             nan     0.0010    0.0002
#&gt;    460        1.1003             nan     0.0010    0.0002
#&gt;    480        1.0914             nan     0.0010    0.0001
#&gt;    500        1.0824             nan     0.0010    0.0001
#&gt;    520        1.0737             nan     0.0010    0.0001
#&gt;    540        1.0650             nan     0.0010    0.0001
#&gt;    560        1.0567             nan     0.0010    0.0001
#&gt;    580        1.0486             nan     0.0010    0.0001
#&gt;    600        1.0409             nan     0.0010    0.0001
#&gt;    620        1.0329             nan     0.0010    0.0002
#&gt;    640        1.0254             nan     0.0010    0.0001
#&gt;    660        1.0181             nan     0.0010    0.0001
#&gt;    680        1.0105             nan     0.0010    0.0001
#&gt;    700        1.0032             nan     0.0010    0.0001
#&gt;    720        0.9961             nan     0.0010    0.0001
#&gt;    740        0.9894             nan     0.0010    0.0001
#&gt;    760        0.9827             nan     0.0010    0.0001
#&gt;    780        0.9763             nan     0.0010    0.0001
#&gt;    800        0.9698             nan     0.0010    0.0001
#&gt;    820        0.9636             nan     0.0010    0.0001
#&gt;    840        0.9572             nan     0.0010    0.0001
#&gt;    860        0.9510             nan     0.0010    0.0001
#&gt;    880        0.9455             nan     0.0010    0.0001
#&gt;    900        0.9396             nan     0.0010    0.0001
#&gt;    920        0.9338             nan     0.0010    0.0001
#&gt;    940        0.9278             nan     0.0010    0.0001
#&gt;    960        0.9220             nan     0.0010    0.0001
#&gt;    980        0.9163             nan     0.0010    0.0001
#&gt;   1000        0.9111             nan     0.0010    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3732             nan     0.0100    0.0027
#&gt;      2        1.3677             nan     0.0100    0.0027
#&gt;      3        1.3629             nan     0.0100    0.0012
#&gt;      4        1.3575             nan     0.0100    0.0023
#&gt;      5        1.3538             nan     0.0100    0.0013
#&gt;      6        1.3479             nan     0.0100    0.0025
#&gt;      7        1.3432             nan     0.0100    0.0025
#&gt;      8        1.3382             nan     0.0100    0.0024
#&gt;      9        1.3341             nan     0.0100    0.0013
#&gt;     10        1.3303             nan     0.0100    0.0011
#&gt;     20        1.2862             nan     0.0100    0.0020
#&gt;     40        1.2106             nan     0.0100    0.0013
#&gt;     60        1.1495             nan     0.0100    0.0011
#&gt;     80        1.0980             nan     0.0100    0.0009
#&gt;    100        1.0529             nan     0.0100    0.0008
#&gt;    120        1.0167             nan     0.0100    0.0007
#&gt;    140        0.9843             nan     0.0100    0.0004
#&gt;    160        0.9573             nan     0.0100    0.0004
#&gt;    180        0.9320             nan     0.0100    0.0002
#&gt;    200        0.9099             nan     0.0100    0.0004
#&gt;    220        0.8894             nan     0.0100    0.0003
#&gt;    240        0.8721             nan     0.0100   -0.0001
#&gt;    260        0.8563             nan     0.0100    0.0001
#&gt;    280        0.8403             nan     0.0100    0.0000
#&gt;    300        0.8276             nan     0.0100    0.0000
#&gt;    320        0.8147             nan     0.0100   -0.0002
#&gt;    340        0.8019             nan     0.0100    0.0000
#&gt;    360        0.7902             nan     0.0100   -0.0002
#&gt;    380        0.7807             nan     0.0100   -0.0000
#&gt;    400        0.7700             nan     0.0100    0.0002
#&gt;    420        0.7621             nan     0.0100   -0.0001
#&gt;    440        0.7533             nan     0.0100    0.0000
#&gt;    460        0.7458             nan     0.0100    0.0000
#&gt;    480        0.7373             nan     0.0100    0.0000
#&gt;    500        0.7297             nan     0.0100    0.0001
#&gt;    520        0.7231             nan     0.0100   -0.0003
#&gt;    540        0.7169             nan     0.0100   -0.0003
#&gt;    560        0.7104             nan     0.0100   -0.0001
#&gt;    580        0.7044             nan     0.0100    0.0001
#&gt;    600        0.6990             nan     0.0100    0.0000
#&gt;    620        0.6933             nan     0.0100   -0.0001
#&gt;    640        0.6883             nan     0.0100   -0.0000
#&gt;    660        0.6835             nan     0.0100   -0.0000
#&gt;    680        0.6780             nan     0.0100   -0.0002
#&gt;    700        0.6731             nan     0.0100   -0.0004
#&gt;    720        0.6687             nan     0.0100   -0.0003
#&gt;    740        0.6643             nan     0.0100   -0.0002
#&gt;    760        0.6586             nan     0.0100   -0.0001
#&gt;    780        0.6534             nan     0.0100   -0.0001
#&gt;    800        0.6497             nan     0.0100   -0.0001
#&gt;    820        0.6458             nan     0.0100   -0.0000
#&gt;    840        0.6417             nan     0.0100   -0.0002
#&gt;    860        0.6383             nan     0.0100   -0.0002
#&gt;    880        0.6343             nan     0.0100   -0.0001
#&gt;    900        0.6307             nan     0.0100   -0.0000
#&gt;    920        0.6272             nan     0.0100   -0.0001
#&gt;    940        0.6243             nan     0.0100   -0.0002
#&gt;    960        0.6208             nan     0.0100   -0.0002
#&gt;    980        0.6175             nan     0.0100   -0.0003
#&gt;   1000        0.6142             nan     0.0100   -0.0003
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3719             nan     0.0100    0.0034
#&gt;      2        1.3644             nan     0.0100    0.0027
#&gt;      3        1.3575             nan     0.0100    0.0031
#&gt;      4        1.3512             nan     0.0100    0.0026
#&gt;      5        1.3441             nan     0.0100    0.0034
#&gt;      6        1.3378             nan     0.0100    0.0026
#&gt;      7        1.3318             nan     0.0100    0.0025
#&gt;      8        1.3249             nan     0.0100    0.0024
#&gt;      9        1.3190             nan     0.0100    0.0029
#&gt;     10        1.3136             nan     0.0100    0.0027
#&gt;     20        1.2572             nan     0.0100    0.0022
#&gt;     40        1.1606             nan     0.0100    0.0018
#&gt;     60        1.0869             nan     0.0100    0.0014
#&gt;     80        1.0233             nan     0.0100    0.0010
#&gt;    100        0.9709             nan     0.0100    0.0007
#&gt;    120        0.9272             nan     0.0100    0.0005
#&gt;    140        0.8880             nan     0.0100    0.0007
#&gt;    160        0.8536             nan     0.0100    0.0004
#&gt;    180        0.8228             nan     0.0100    0.0003
#&gt;    200        0.7975             nan     0.0100    0.0002
#&gt;    220        0.7747             nan     0.0100   -0.0000
#&gt;    240        0.7528             nan     0.0100    0.0002
#&gt;    260        0.7325             nan     0.0100    0.0000
#&gt;    280        0.7148             nan     0.0100    0.0002
#&gt;    300        0.6992             nan     0.0100    0.0002
#&gt;    320        0.6849             nan     0.0100   -0.0001
#&gt;    340        0.6706             nan     0.0100    0.0000
#&gt;    360        0.6585             nan     0.0100    0.0000
#&gt;    380        0.6469             nan     0.0100   -0.0001
#&gt;    400        0.6357             nan     0.0100   -0.0002
#&gt;    420        0.6241             nan     0.0100    0.0000
#&gt;    440        0.6145             nan     0.0100   -0.0000
#&gt;    460        0.6057             nan     0.0100   -0.0003
#&gt;    480        0.5967             nan     0.0100    0.0000
#&gt;    500        0.5884             nan     0.0100   -0.0004
#&gt;    520        0.5797             nan     0.0100   -0.0001
#&gt;    540        0.5715             nan     0.0100   -0.0003
#&gt;    560        0.5637             nan     0.0100   -0.0002
#&gt;    580        0.5562             nan     0.0100   -0.0002
#&gt;    600        0.5493             nan     0.0100   -0.0002
#&gt;    620        0.5426             nan     0.0100   -0.0002
#&gt;    640        0.5356             nan     0.0100   -0.0000
#&gt;    660        0.5293             nan     0.0100   -0.0002
#&gt;    680        0.5221             nan     0.0100   -0.0002
#&gt;    700        0.5168             nan     0.0100   -0.0005
#&gt;    720        0.5121             nan     0.0100   -0.0003
#&gt;    740        0.5048             nan     0.0100   -0.0003
#&gt;    760        0.4987             nan     0.0100   -0.0001
#&gt;    780        0.4922             nan     0.0100   -0.0001
#&gt;    800        0.4864             nan     0.0100   -0.0002
#&gt;    820        0.4806             nan     0.0100   -0.0003
#&gt;    840        0.4759             nan     0.0100   -0.0004
#&gt;    860        0.4711             nan     0.0100   -0.0002
#&gt;    880        0.4660             nan     0.0100   -0.0003
#&gt;    900        0.4605             nan     0.0100   -0.0003
#&gt;    920        0.4563             nan     0.0100   -0.0003
#&gt;    940        0.4518             nan     0.0100   -0.0002
#&gt;    960        0.4479             nan     0.0100   -0.0003
#&gt;    980        0.4435             nan     0.0100   -0.0005
#&gt;   1000        0.4394             nan     0.0100   -0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3714             nan     0.0100    0.0035
#&gt;      2        1.3637             nan     0.0100    0.0031
#&gt;      3        1.3572             nan     0.0100    0.0028
#&gt;      4        1.3490             nan     0.0100    0.0034
#&gt;      5        1.3420             nan     0.0100    0.0029
#&gt;      6        1.3346             nan     0.0100    0.0034
#&gt;      7        1.3269             nan     0.0100    0.0033
#&gt;      8        1.3191             nan     0.0100    0.0030
#&gt;      9        1.3123             nan     0.0100    0.0031
#&gt;     10        1.3051             nan     0.0100    0.0027
#&gt;     20        1.2385             nan     0.0100    0.0021
#&gt;     40        1.1259             nan     0.0100    0.0012
#&gt;     60        1.0405             nan     0.0100    0.0014
#&gt;     80        0.9687             nan     0.0100    0.0010
#&gt;    100        0.9114             nan     0.0100    0.0007
#&gt;    120        0.8619             nan     0.0100    0.0002
#&gt;    140        0.8184             nan     0.0100    0.0004
#&gt;    160        0.7825             nan     0.0100    0.0007
#&gt;    180        0.7488             nan     0.0100    0.0006
#&gt;    200        0.7201             nan     0.0100   -0.0000
#&gt;    220        0.6954             nan     0.0100   -0.0001
#&gt;    240        0.6729             nan     0.0100    0.0002
#&gt;    260        0.6504             nan     0.0100   -0.0003
#&gt;    280        0.6319             nan     0.0100    0.0000
#&gt;    300        0.6138             nan     0.0100   -0.0003
#&gt;    320        0.5975             nan     0.0100   -0.0001
#&gt;    340        0.5834             nan     0.0100   -0.0001
#&gt;    360        0.5673             nan     0.0100    0.0000
#&gt;    380        0.5538             nan     0.0100    0.0000
#&gt;    400        0.5414             nan     0.0100   -0.0001
#&gt;    420        0.5287             nan     0.0100   -0.0001
#&gt;    440        0.5175             nan     0.0100   -0.0001
#&gt;    460        0.5061             nan     0.0100   -0.0001
#&gt;    480        0.4958             nan     0.0100   -0.0002
#&gt;    500        0.4860             nan     0.0100   -0.0003
#&gt;    520        0.4769             nan     0.0100    0.0000
#&gt;    540        0.4680             nan     0.0100   -0.0001
#&gt;    560        0.4597             nan     0.0100   -0.0001
#&gt;    580        0.4524             nan     0.0100   -0.0003
#&gt;    600        0.4434             nan     0.0100   -0.0000
#&gt;    620        0.4358             nan     0.0100   -0.0000
#&gt;    640        0.4288             nan     0.0100   -0.0003
#&gt;    660        0.4212             nan     0.0100    0.0000
#&gt;    680        0.4138             nan     0.0100   -0.0001
#&gt;    700        0.4074             nan     0.0100    0.0000
#&gt;    720        0.4015             nan     0.0100   -0.0003
#&gt;    740        0.3951             nan     0.0100   -0.0001
#&gt;    760        0.3885             nan     0.0100   -0.0005
#&gt;    780        0.3824             nan     0.0100   -0.0002
#&gt;    800        0.3759             nan     0.0100   -0.0001
#&gt;    820        0.3706             nan     0.0100   -0.0002
#&gt;    840        0.3656             nan     0.0100   -0.0003
#&gt;    860        0.3609             nan     0.0100   -0.0001
#&gt;    880        0.3560             nan     0.0100   -0.0003
#&gt;    900        0.3512             nan     0.0100   -0.0002
#&gt;    920        0.3458             nan     0.0100   -0.0002
#&gt;    940        0.3406             nan     0.0100   -0.0002
#&gt;    960        0.3348             nan     0.0100   -0.0001
#&gt;    980        0.3293             nan     0.0100   -0.0003
#&gt;   1000        0.3247             nan     0.0100   -0.0005
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3203             nan     0.1000    0.0213
#&gt;      2        1.2744             nan     0.1000    0.0171
#&gt;      3        1.2347             nan     0.1000    0.0193
#&gt;      4        1.2056             nan     0.1000    0.0102
#&gt;      5        1.1638             nan     0.1000    0.0138
#&gt;      6        1.1321             nan     0.1000    0.0087
#&gt;      7        1.0982             nan     0.1000    0.0112
#&gt;      8        1.0728             nan     0.1000    0.0098
#&gt;      9        1.0555             nan     0.1000    0.0081
#&gt;     10        1.0388             nan     0.1000    0.0062
#&gt;     20        0.9076             nan     0.1000   -0.0010
#&gt;     40        0.7698             nan     0.1000   -0.0003
#&gt;     60        0.7099             nan     0.1000    0.0011
#&gt;     80        0.6602             nan     0.1000   -0.0019
#&gt;    100        0.6201             nan     0.1000   -0.0007
#&gt;    120        0.5844             nan     0.1000   -0.0009
#&gt;    140        0.5694             nan     0.1000   -0.0013
#&gt;    160        0.5540             nan     0.1000   -0.0028
#&gt;    180        0.5323             nan     0.1000   -0.0021
#&gt;    200        0.5190             nan     0.1000   -0.0026
#&gt;    220        0.5047             nan     0.1000   -0.0028
#&gt;    240        0.4899             nan     0.1000    0.0004
#&gt;    260        0.4829             nan     0.1000   -0.0045
#&gt;    280        0.4664             nan     0.1000   -0.0028
#&gt;    300        0.4565             nan     0.1000   -0.0042
#&gt;    320        0.4477             nan     0.1000   -0.0023
#&gt;    340        0.4382             nan     0.1000   -0.0024
#&gt;    360        0.4288             nan     0.1000   -0.0051
#&gt;    380        0.4191             nan     0.1000   -0.0025
#&gt;    400        0.4111             nan     0.1000   -0.0019
#&gt;    420        0.4018             nan     0.1000   -0.0022
#&gt;    440        0.3940             nan     0.1000   -0.0005
#&gt;    460        0.3841             nan     0.1000   -0.0009
#&gt;    480        0.3818             nan     0.1000   -0.0052
#&gt;    500        0.3744             nan     0.1000   -0.0026
#&gt;    520        0.3652             nan     0.1000   -0.0026
#&gt;    540        0.3614             nan     0.1000   -0.0020
#&gt;    560        0.3578             nan     0.1000   -0.0019
#&gt;    580        0.3512             nan     0.1000   -0.0008
#&gt;    600        0.3438             nan     0.1000   -0.0003
#&gt;    620        0.3384             nan     0.1000   -0.0015
#&gt;    640        0.3375             nan     0.1000   -0.0019
#&gt;    660        0.3311             nan     0.1000   -0.0013
#&gt;    680        0.3245             nan     0.1000   -0.0002
#&gt;    700        0.3198             nan     0.1000   -0.0014
#&gt;    720        0.3159             nan     0.1000   -0.0012
#&gt;    740        0.3102             nan     0.1000   -0.0023
#&gt;    760        0.3057             nan     0.1000   -0.0015
#&gt;    780        0.3022             nan     0.1000   -0.0010
#&gt;    800        0.2982             nan     0.1000   -0.0023
#&gt;    820        0.2944             nan     0.1000   -0.0013
#&gt;    840        0.2887             nan     0.1000   -0.0021
#&gt;    860        0.2848             nan     0.1000   -0.0013
#&gt;    880        0.2787             nan     0.1000   -0.0001
#&gt;    900        0.2748             nan     0.1000   -0.0015
#&gt;    920        0.2731             nan     0.1000   -0.0018
#&gt;    940        0.2682             nan     0.1000   -0.0007
#&gt;    960        0.2635             nan     0.1000   -0.0015
#&gt;    980        0.2604             nan     0.1000   -0.0024
#&gt;   1000        0.2557             nan     0.1000   -0.0011
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.2990             nan     0.1000    0.0328
#&gt;      2        1.2442             nan     0.1000    0.0219
#&gt;      3        1.1939             nan     0.1000    0.0202
#&gt;      4        1.1515             nan     0.1000    0.0194
#&gt;      5        1.1088             nan     0.1000    0.0171
#&gt;      6        1.0744             nan     0.1000    0.0106
#&gt;      7        1.0433             nan     0.1000    0.0111
#&gt;      8        1.0136             nan     0.1000    0.0091
#&gt;      9        0.9908             nan     0.1000    0.0078
#&gt;     10        0.9697             nan     0.1000    0.0084
#&gt;     20        0.8006             nan     0.1000    0.0052
#&gt;     40        0.6557             nan     0.1000   -0.0008
#&gt;     60        0.5613             nan     0.1000   -0.0010
#&gt;     80        0.5066             nan     0.1000   -0.0010
#&gt;    100        0.4532             nan     0.1000    0.0004
#&gt;    120        0.4087             nan     0.1000   -0.0016
#&gt;    140        0.3820             nan     0.1000   -0.0017
#&gt;    160        0.3488             nan     0.1000   -0.0011
#&gt;    180        0.3177             nan     0.1000   -0.0022
#&gt;    200        0.2914             nan     0.1000   -0.0024
#&gt;    220        0.2718             nan     0.1000   -0.0008
#&gt;    240        0.2544             nan     0.1000   -0.0012
#&gt;    260        0.2407             nan     0.1000   -0.0016
#&gt;    280        0.2258             nan     0.1000   -0.0025
#&gt;    300        0.2145             nan     0.1000   -0.0009
#&gt;    320        0.2005             nan     0.1000   -0.0014
#&gt;    340        0.1879             nan     0.1000   -0.0014
#&gt;    360        0.1768             nan     0.1000   -0.0017
#&gt;    380        0.1691             nan     0.1000   -0.0018
#&gt;    400        0.1590             nan     0.1000   -0.0015
#&gt;    420        0.1490             nan     0.1000   -0.0017
#&gt;    440        0.1429             nan     0.1000   -0.0010
#&gt;    460        0.1351             nan     0.1000   -0.0013
#&gt;    480        0.1301             nan     0.1000   -0.0004
#&gt;    500        0.1212             nan     0.1000   -0.0009
#&gt;    520        0.1141             nan     0.1000   -0.0005
#&gt;    540        0.1082             nan     0.1000   -0.0008
#&gt;    560        0.1007             nan     0.1000   -0.0005
#&gt;    580        0.0949             nan     0.1000   -0.0005
#&gt;    600        0.0894             nan     0.1000   -0.0005
#&gt;    620        0.0845             nan     0.1000   -0.0009
#&gt;    640        0.0787             nan     0.1000   -0.0004
#&gt;    660        0.0757             nan     0.1000   -0.0001
#&gt;    680        0.0717             nan     0.1000   -0.0005
#&gt;    700        0.0691             nan     0.1000   -0.0002
#&gt;    720        0.0655             nan     0.1000   -0.0006
#&gt;    740        0.0618             nan     0.1000   -0.0005
#&gt;    760        0.0590             nan     0.1000   -0.0004
#&gt;    780        0.0560             nan     0.1000   -0.0002
#&gt;    800        0.0533             nan     0.1000   -0.0003
#&gt;    820        0.0496             nan     0.1000   -0.0002
#&gt;    840        0.0473             nan     0.1000   -0.0003
#&gt;    860        0.0443             nan     0.1000   -0.0002
#&gt;    880        0.0421             nan     0.1000   -0.0003
#&gt;    900        0.0394             nan     0.1000   -0.0002
#&gt;    920        0.0374             nan     0.1000   -0.0002
#&gt;    940        0.0358             nan     0.1000   -0.0002
#&gt;    960        0.0336             nan     0.1000   -0.0003
#&gt;    980        0.0322             nan     0.1000   -0.0003
#&gt;   1000        0.0307             nan     0.1000   -0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3017             nan     0.1000    0.0286
#&gt;      2        1.2365             nan     0.1000    0.0259
#&gt;      3        1.1764             nan     0.1000    0.0216
#&gt;      4        1.1179             nan     0.1000    0.0166
#&gt;      5        1.0735             nan     0.1000    0.0153
#&gt;      6        1.0257             nan     0.1000    0.0227
#&gt;      7        0.9861             nan     0.1000    0.0158
#&gt;      8        0.9569             nan     0.1000    0.0090
#&gt;      9        0.9250             nan     0.1000    0.0113
#&gt;     10        0.8992             nan     0.1000    0.0088
#&gt;     20        0.7127             nan     0.1000    0.0030
#&gt;     40        0.5468             nan     0.1000   -0.0027
#&gt;     60        0.4531             nan     0.1000   -0.0034
#&gt;     80        0.3779             nan     0.1000   -0.0005
#&gt;    100        0.3191             nan     0.1000   -0.0011
#&gt;    120        0.2791             nan     0.1000   -0.0026
#&gt;    140        0.2448             nan     0.1000   -0.0026
#&gt;    160        0.2166             nan     0.1000   -0.0019
#&gt;    180        0.1951             nan     0.1000   -0.0009
#&gt;    200        0.1741             nan     0.1000   -0.0011
#&gt;    220        0.1563             nan     0.1000   -0.0005
#&gt;    240        0.1423             nan     0.1000   -0.0011
#&gt;    260        0.1276             nan     0.1000   -0.0008
#&gt;    280        0.1183             nan     0.1000   -0.0016
#&gt;    300        0.1056             nan     0.1000   -0.0007
#&gt;    320        0.0915             nan     0.1000   -0.0005
#&gt;    340        0.0844             nan     0.1000   -0.0010
#&gt;    360        0.0763             nan     0.1000   -0.0005
#&gt;    380        0.0690             nan     0.1000   -0.0006
#&gt;    400        0.0620             nan     0.1000   -0.0003
#&gt;    420        0.0565             nan     0.1000   -0.0003
#&gt;    440        0.0531             nan     0.1000   -0.0006
#&gt;    460        0.0483             nan     0.1000   -0.0001
#&gt;    480        0.0441             nan     0.1000   -0.0002
#&gt;    500        0.0405             nan     0.1000   -0.0001
#&gt;    520        0.0367             nan     0.1000   -0.0003
#&gt;    540        0.0332             nan     0.1000   -0.0003
#&gt;    560        0.0300             nan     0.1000   -0.0002
#&gt;    580        0.0272             nan     0.1000   -0.0002
#&gt;    600        0.0245             nan     0.1000   -0.0001
#&gt;    620        0.0229             nan     0.1000   -0.0001
#&gt;    640        0.0208             nan     0.1000   -0.0001
#&gt;    660        0.0190             nan     0.1000   -0.0003
#&gt;    680        0.0176             nan     0.1000   -0.0002
#&gt;    700        0.0159             nan     0.1000   -0.0001
#&gt;    720        0.0146             nan     0.1000   -0.0000
#&gt;    740        0.0133             nan     0.1000   -0.0000
#&gt;    760        0.0123             nan     0.1000   -0.0001
#&gt;    780        0.0111             nan     0.1000   -0.0001
#&gt;    800        0.0103             nan     0.1000   -0.0001
#&gt;    820        0.0093             nan     0.1000   -0.0001
#&gt;    840        0.0086             nan     0.1000   -0.0001
#&gt;    860        0.0077             nan     0.1000   -0.0000
#&gt;    880        0.0070             nan     0.1000   -0.0000
#&gt;    900        0.0064             nan     0.1000   -0.0000
#&gt;    920        0.0059             nan     0.1000   -0.0001
#&gt;    940        0.0053             nan     0.1000   -0.0000
#&gt;    960        0.0048             nan     0.1000   -0.0000
#&gt;    980        0.0043             nan     0.1000   -0.0000
#&gt;   1000        0.0039             nan     0.1000   -0.0000
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3791             nan     0.0010    0.0002
#&gt;      2        1.3787             nan     0.0010    0.0002
#&gt;      3        1.3782             nan     0.0010    0.0002
#&gt;      4        1.3777             nan     0.0010    0.0002
#&gt;      5        1.3773             nan     0.0010    0.0002
#&gt;      6        1.3767             nan     0.0010    0.0002
#&gt;      7        1.3762             nan     0.0010    0.0002
#&gt;      8        1.3757             nan     0.0010    0.0002
#&gt;      9        1.3752             nan     0.0010    0.0003
#&gt;     10        1.3747             nan     0.0010    0.0003
#&gt;     20        1.3698             nan     0.0010    0.0002
#&gt;     40        1.3600             nan     0.0010    0.0002
#&gt;     60        1.3500             nan     0.0010    0.0002
#&gt;     80        1.3410             nan     0.0010    0.0002
#&gt;    100        1.3318             nan     0.0010    0.0002
#&gt;    120        1.3233             nan     0.0010    0.0002
#&gt;    140        1.3146             nan     0.0010    0.0002
#&gt;    160        1.3065             nan     0.0010    0.0002
#&gt;    180        1.2979             nan     0.0010    0.0002
#&gt;    200        1.2897             nan     0.0010    0.0002
#&gt;    220        1.2816             nan     0.0010    0.0002
#&gt;    240        1.2733             nan     0.0010    0.0002
#&gt;    260        1.2657             nan     0.0010    0.0002
#&gt;    280        1.2585             nan     0.0010    0.0002
#&gt;    300        1.2514             nan     0.0010    0.0001
#&gt;    320        1.2443             nan     0.0010    0.0001
#&gt;    340        1.2374             nan     0.0010    0.0002
#&gt;    360        1.2307             nan     0.0010    0.0002
#&gt;    380        1.2235             nan     0.0010    0.0001
#&gt;    400        1.2166             nan     0.0010    0.0001
#&gt;    420        1.2099             nan     0.0010    0.0002
#&gt;    440        1.2036             nan     0.0010    0.0001
#&gt;    460        1.1970             nan     0.0010    0.0001
#&gt;    480        1.1908             nan     0.0010    0.0001
#&gt;    500        1.1846             nan     0.0010    0.0001
#&gt;    520        1.1785             nan     0.0010    0.0001
#&gt;    540        1.1725             nan     0.0010    0.0001
#&gt;    560        1.1668             nan     0.0010    0.0001
#&gt;    580        1.1613             nan     0.0010    0.0001
#&gt;    600        1.1558             nan     0.0010    0.0001
#&gt;    620        1.1504             nan     0.0010    0.0001
#&gt;    640        1.1451             nan     0.0010    0.0001
#&gt;    660        1.1400             nan     0.0010    0.0001
#&gt;    680        1.1350             nan     0.0010    0.0001
#&gt;    700        1.1300             nan     0.0010   -0.0000
#&gt;    720        1.1252             nan     0.0010    0.0001
#&gt;    740        1.1206             nan     0.0010    0.0001
#&gt;    760        1.1157             nan     0.0010    0.0001
#&gt;    780        1.1111             nan     0.0010    0.0001
#&gt;    800        1.1064             nan     0.0010    0.0001
#&gt;    820        1.1018             nan     0.0010    0.0000
#&gt;    840        1.0975             nan     0.0010    0.0001
#&gt;    860        1.0930             nan     0.0010    0.0001
#&gt;    880        1.0889             nan     0.0010    0.0001
#&gt;    900        1.0847             nan     0.0010    0.0001
#&gt;    920        1.0804             nan     0.0010    0.0000
#&gt;    940        1.0760             nan     0.0010    0.0001
#&gt;    960        1.0719             nan     0.0010    0.0001
#&gt;    980        1.0678             nan     0.0010    0.0001
#&gt;   1000        1.0640             nan     0.0010    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3789             nan     0.0010    0.0003
#&gt;      2        1.3783             nan     0.0010    0.0003
#&gt;      3        1.3775             nan     0.0010    0.0003
#&gt;      4        1.3767             nan     0.0010    0.0003
#&gt;      5        1.3761             nan     0.0010    0.0003
#&gt;      6        1.3753             nan     0.0010    0.0003
#&gt;      7        1.3747             nan     0.0010    0.0003
#&gt;      8        1.3740             nan     0.0010    0.0003
#&gt;      9        1.3734             nan     0.0010    0.0002
#&gt;     10        1.3727             nan     0.0010    0.0003
#&gt;     20        1.3660             nan     0.0010    0.0002
#&gt;     40        1.3531             nan     0.0010    0.0003
#&gt;     60        1.3405             nan     0.0010    0.0002
#&gt;     80        1.3279             nan     0.0010    0.0003
#&gt;    100        1.3161             nan     0.0010    0.0001
#&gt;    120        1.3043             nan     0.0010    0.0002
#&gt;    140        1.2931             nan     0.0010    0.0003
#&gt;    160        1.2821             nan     0.0010    0.0002
#&gt;    180        1.2709             nan     0.0010    0.0003
#&gt;    200        1.2605             nan     0.0010    0.0002
#&gt;    220        1.2505             nan     0.0010    0.0002
#&gt;    240        1.2403             nan     0.0010    0.0002
#&gt;    260        1.2306             nan     0.0010    0.0001
#&gt;    280        1.2206             nan     0.0010    0.0002
#&gt;    300        1.2113             nan     0.0010    0.0002
#&gt;    320        1.2022             nan     0.0010    0.0002
#&gt;    340        1.1930             nan     0.0010    0.0002
#&gt;    360        1.1843             nan     0.0010    0.0002
#&gt;    380        1.1760             nan     0.0010    0.0002
#&gt;    400        1.1673             nan     0.0010    0.0001
#&gt;    420        1.1592             nan     0.0010    0.0002
#&gt;    440        1.1511             nan     0.0010    0.0002
#&gt;    460        1.1437             nan     0.0010    0.0001
#&gt;    480        1.1359             nan     0.0010    0.0001
#&gt;    500        1.1285             nan     0.0010    0.0002
#&gt;    520        1.1209             nan     0.0010    0.0001
#&gt;    540        1.1135             nan     0.0010    0.0001
#&gt;    560        1.1061             nan     0.0010    0.0001
#&gt;    580        1.0992             nan     0.0010    0.0002
#&gt;    600        1.0925             nan     0.0010    0.0001
#&gt;    620        1.0860             nan     0.0010    0.0001
#&gt;    640        1.0796             nan     0.0010    0.0002
#&gt;    660        1.0733             nan     0.0010    0.0001
#&gt;    680        1.0670             nan     0.0010    0.0001
#&gt;    700        1.0607             nan     0.0010    0.0001
#&gt;    720        1.0545             nan     0.0010    0.0001
#&gt;    740        1.0488             nan     0.0010    0.0001
#&gt;    760        1.0426             nan     0.0010    0.0001
#&gt;    780        1.0368             nan     0.0010    0.0000
#&gt;    800        1.0314             nan     0.0010    0.0001
#&gt;    820        1.0259             nan     0.0010    0.0001
#&gt;    840        1.0206             nan     0.0010    0.0001
#&gt;    860        1.0152             nan     0.0010    0.0001
#&gt;    880        1.0101             nan     0.0010    0.0001
#&gt;    900        1.0051             nan     0.0010    0.0001
#&gt;    920        1.0002             nan     0.0010    0.0000
#&gt;    940        0.9952             nan     0.0010    0.0001
#&gt;    960        0.9903             nan     0.0010    0.0001
#&gt;    980        0.9856             nan     0.0010    0.0001
#&gt;   1000        0.9808             nan     0.0010    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3787             nan     0.0010    0.0003
#&gt;      2        1.3779             nan     0.0010    0.0004
#&gt;      3        1.3771             nan     0.0010    0.0004
#&gt;      4        1.3762             nan     0.0010    0.0004
#&gt;      5        1.3755             nan     0.0010    0.0004
#&gt;      6        1.3748             nan     0.0010    0.0002
#&gt;      7        1.3740             nan     0.0010    0.0003
#&gt;      8        1.3733             nan     0.0010    0.0003
#&gt;      9        1.3725             nan     0.0010    0.0003
#&gt;     10        1.3717             nan     0.0010    0.0003
#&gt;     20        1.3637             nan     0.0010    0.0003
#&gt;     40        1.3487             nan     0.0010    0.0003
#&gt;     60        1.3340             nan     0.0010    0.0003
#&gt;     80        1.3196             nan     0.0010    0.0002
#&gt;    100        1.3056             nan     0.0010    0.0003
#&gt;    120        1.2927             nan     0.0010    0.0002
#&gt;    140        1.2792             nan     0.0010    0.0002
#&gt;    160        1.2663             nan     0.0010    0.0003
#&gt;    180        1.2534             nan     0.0010    0.0002
#&gt;    200        1.2415             nan     0.0010    0.0002
#&gt;    220        1.2294             nan     0.0010    0.0002
#&gt;    240        1.2174             nan     0.0010    0.0003
#&gt;    260        1.2063             nan     0.0010    0.0002
#&gt;    280        1.1955             nan     0.0010    0.0002
#&gt;    300        1.1850             nan     0.0010    0.0002
#&gt;    320        1.1746             nan     0.0010    0.0002
#&gt;    340        1.1642             nan     0.0010    0.0002
#&gt;    360        1.1541             nan     0.0010    0.0002
#&gt;    380        1.1443             nan     0.0010    0.0002
#&gt;    400        1.1347             nan     0.0010    0.0001
#&gt;    420        1.1255             nan     0.0010    0.0002
#&gt;    440        1.1163             nan     0.0010    0.0002
#&gt;    460        1.1072             nan     0.0010    0.0002
#&gt;    480        1.0981             nan     0.0010    0.0002
#&gt;    500        1.0898             nan     0.0010    0.0002
#&gt;    520        1.0815             nan     0.0010    0.0001
#&gt;    540        1.0734             nan     0.0010    0.0002
#&gt;    560        1.0651             nan     0.0010    0.0002
#&gt;    580        1.0571             nan     0.0010    0.0001
#&gt;    600        1.0495             nan     0.0010    0.0001
#&gt;    620        1.0419             nan     0.0010    0.0002
#&gt;    640        1.0346             nan     0.0010    0.0001
#&gt;    660        1.0272             nan     0.0010    0.0001
#&gt;    680        1.0200             nan     0.0010    0.0001
#&gt;    700        1.0132             nan     0.0010    0.0001
#&gt;    720        1.0066             nan     0.0010    0.0001
#&gt;    740        0.9999             nan     0.0010    0.0001
#&gt;    760        0.9936             nan     0.0010    0.0001
#&gt;    780        0.9870             nan     0.0010    0.0001
#&gt;    800        0.9807             nan     0.0010    0.0001
#&gt;    820        0.9744             nan     0.0010    0.0001
#&gt;    840        0.9685             nan     0.0010    0.0001
#&gt;    860        0.9624             nan     0.0010    0.0001
#&gt;    880        0.9566             nan     0.0010    0.0001
#&gt;    900        0.9508             nan     0.0010    0.0001
#&gt;    920        0.9453             nan     0.0010    0.0000
#&gt;    940        0.9398             nan     0.0010    0.0001
#&gt;    960        0.9345             nan     0.0010    0.0001
#&gt;    980        0.9291             nan     0.0010    0.0000
#&gt;   1000        0.9236             nan     0.0010    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3746             nan     0.0100    0.0025
#&gt;      2        1.3695             nan     0.0100    0.0025
#&gt;      3        1.3647             nan     0.0100    0.0020
#&gt;      4        1.3601             nan     0.0100    0.0020
#&gt;      5        1.3560             nan     0.0100    0.0011
#&gt;      6        1.3510             nan     0.0100    0.0023
#&gt;      7        1.3464             nan     0.0100    0.0018
#&gt;      8        1.3419             nan     0.0100    0.0023
#&gt;      9        1.3375             nan     0.0100    0.0023
#&gt;     10        1.3323             nan     0.0100    0.0020
#&gt;     20        1.2871             nan     0.0100    0.0015
#&gt;     40        1.2150             nan     0.0100    0.0015
#&gt;     60        1.1526             nan     0.0100    0.0012
#&gt;     80        1.1083             nan     0.0100    0.0010
#&gt;    100        1.0663             nan     0.0100    0.0008
#&gt;    120        1.0287             nan     0.0100    0.0007
#&gt;    140        0.9954             nan     0.0100    0.0006
#&gt;    160        0.9660             nan     0.0100    0.0004
#&gt;    180        0.9404             nan     0.0100    0.0003
#&gt;    200        0.9187             nan     0.0100    0.0002
#&gt;    220        0.8997             nan     0.0100    0.0002
#&gt;    240        0.8828             nan     0.0100   -0.0003
#&gt;    260        0.8655             nan     0.0100    0.0003
#&gt;    280        0.8510             nan     0.0100    0.0002
#&gt;    300        0.8362             nan     0.0100    0.0001
#&gt;    320        0.8234             nan     0.0100   -0.0001
#&gt;    340        0.8119             nan     0.0100   -0.0002
#&gt;    360        0.8015             nan     0.0100    0.0001
#&gt;    380        0.7913             nan     0.0100    0.0001
#&gt;    400        0.7811             nan     0.0100   -0.0000
#&gt;    420        0.7717             nan     0.0100    0.0000
#&gt;    440        0.7633             nan     0.0100   -0.0002
#&gt;    460        0.7554             nan     0.0100   -0.0001
#&gt;    480        0.7481             nan     0.0100   -0.0005
#&gt;    500        0.7406             nan     0.0100   -0.0001
#&gt;    520        0.7330             nan     0.0100   -0.0000
#&gt;    540        0.7269             nan     0.0100   -0.0001
#&gt;    560        0.7207             nan     0.0100    0.0000
#&gt;    580        0.7139             nan     0.0100   -0.0001
#&gt;    600        0.7077             nan     0.0100    0.0000
#&gt;    620        0.7019             nan     0.0100   -0.0002
#&gt;    640        0.6960             nan     0.0100   -0.0002
#&gt;    660        0.6905             nan     0.0100   -0.0001
#&gt;    680        0.6849             nan     0.0100   -0.0002
#&gt;    700        0.6795             nan     0.0100   -0.0000
#&gt;    720        0.6738             nan     0.0100   -0.0002
#&gt;    740        0.6688             nan     0.0100   -0.0002
#&gt;    760        0.6642             nan     0.0100   -0.0000
#&gt;    780        0.6592             nan     0.0100   -0.0001
#&gt;    800        0.6550             nan     0.0100   -0.0004
#&gt;    820        0.6508             nan     0.0100   -0.0003
#&gt;    840        0.6464             nan     0.0100   -0.0001
#&gt;    860        0.6423             nan     0.0100   -0.0000
#&gt;    880        0.6389             nan     0.0100   -0.0002
#&gt;    900        0.6349             nan     0.0100   -0.0001
#&gt;    920        0.6317             nan     0.0100   -0.0001
#&gt;    940        0.6289             nan     0.0100   -0.0001
#&gt;    960        0.6254             nan     0.0100   -0.0000
#&gt;    980        0.6220             nan     0.0100   -0.0001
#&gt;   1000        0.6186             nan     0.0100    0.0000
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3737             nan     0.0100    0.0024
#&gt;      2        1.3686             nan     0.0100    0.0020
#&gt;      3        1.3624             nan     0.0100    0.0032
#&gt;      4        1.3553             nan     0.0100    0.0034
#&gt;      5        1.3479             nan     0.0100    0.0028
#&gt;      6        1.3418             nan     0.0100    0.0030
#&gt;      7        1.3352             nan     0.0100    0.0027
#&gt;      8        1.3296             nan     0.0100    0.0027
#&gt;      9        1.3242             nan     0.0100    0.0020
#&gt;     10        1.3183             nan     0.0100    0.0026
#&gt;     20        1.2624             nan     0.0100    0.0020
#&gt;     40        1.1705             nan     0.0100    0.0013
#&gt;     60        1.0950             nan     0.0100    0.0013
#&gt;     80        1.0332             nan     0.0100    0.0011
#&gt;    100        0.9793             nan     0.0100    0.0008
#&gt;    120        0.9334             nan     0.0100    0.0007
#&gt;    140        0.8954             nan     0.0100    0.0007
#&gt;    160        0.8611             nan     0.0100    0.0006
#&gt;    180        0.8323             nan     0.0100    0.0005
#&gt;    200        0.8088             nan     0.0100    0.0002
#&gt;    220        0.7865             nan     0.0100    0.0001
#&gt;    240        0.7675             nan     0.0100   -0.0003
#&gt;    260        0.7491             nan     0.0100    0.0001
#&gt;    280        0.7330             nan     0.0100    0.0000
#&gt;    300        0.7179             nan     0.0100   -0.0000
#&gt;    320        0.7026             nan     0.0100    0.0000
#&gt;    340        0.6880             nan     0.0100   -0.0001
#&gt;    360        0.6755             nan     0.0100   -0.0002
#&gt;    380        0.6643             nan     0.0100   -0.0003
#&gt;    400        0.6517             nan     0.0100   -0.0000
#&gt;    420        0.6401             nan     0.0100   -0.0002
#&gt;    440        0.6293             nan     0.0100   -0.0000
#&gt;    460        0.6194             nan     0.0100   -0.0005
#&gt;    480        0.6103             nan     0.0100   -0.0001
#&gt;    500        0.6019             nan     0.0100   -0.0003
#&gt;    520        0.5927             nan     0.0100   -0.0001
#&gt;    540        0.5844             nan     0.0100   -0.0001
#&gt;    560        0.5769             nan     0.0100   -0.0004
#&gt;    580        0.5701             nan     0.0100   -0.0003
#&gt;    600        0.5627             nan     0.0100   -0.0002
#&gt;    620        0.5557             nan     0.0100   -0.0001
#&gt;    640        0.5485             nan     0.0100   -0.0001
#&gt;    660        0.5419             nan     0.0100   -0.0001
#&gt;    680        0.5364             nan     0.0100   -0.0002
#&gt;    700        0.5309             nan     0.0100   -0.0001
#&gt;    720        0.5244             nan     0.0100   -0.0002
#&gt;    740        0.5190             nan     0.0100   -0.0002
#&gt;    760        0.5132             nan     0.0100   -0.0002
#&gt;    780        0.5090             nan     0.0100   -0.0001
#&gt;    800        0.5042             nan     0.0100   -0.0005
#&gt;    820        0.4994             nan     0.0100   -0.0003
#&gt;    840        0.4944             nan     0.0100   -0.0002
#&gt;    860        0.4902             nan     0.0100   -0.0003
#&gt;    880        0.4852             nan     0.0100   -0.0001
#&gt;    900        0.4803             nan     0.0100   -0.0002
#&gt;    920        0.4762             nan     0.0100   -0.0002
#&gt;    940        0.4718             nan     0.0100   -0.0002
#&gt;    960        0.4664             nan     0.0100   -0.0000
#&gt;    980        0.4624             nan     0.0100   -0.0003
#&gt;   1000        0.4581             nan     0.0100   -0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3726             nan     0.0100    0.0024
#&gt;      2        1.3646             nan     0.0100    0.0036
#&gt;      3        1.3562             nan     0.0100    0.0034
#&gt;      4        1.3496             nan     0.0100    0.0026
#&gt;      5        1.3421             nan     0.0100    0.0028
#&gt;      6        1.3341             nan     0.0100    0.0033
#&gt;      7        1.3271             nan     0.0100    0.0033
#&gt;      8        1.3212             nan     0.0100    0.0026
#&gt;      9        1.3141             nan     0.0100    0.0028
#&gt;     10        1.3066             nan     0.0100    0.0033
#&gt;     20        1.2426             nan     0.0100    0.0025
#&gt;     40        1.1360             nan     0.0100    0.0023
#&gt;     60        1.0510             nan     0.0100    0.0012
#&gt;     80        0.9804             nan     0.0100    0.0009
#&gt;    100        0.9230             nan     0.0100    0.0006
#&gt;    120        0.8762             nan     0.0100    0.0007
#&gt;    140        0.8328             nan     0.0100    0.0004
#&gt;    160        0.7971             nan     0.0100   -0.0002
#&gt;    180        0.7632             nan     0.0100    0.0000
#&gt;    200        0.7352             nan     0.0100    0.0001
#&gt;    220        0.7115             nan     0.0100    0.0002
#&gt;    240        0.6867             nan     0.0100    0.0003
#&gt;    260        0.6655             nan     0.0100    0.0002
#&gt;    280        0.6464             nan     0.0100    0.0003
#&gt;    300        0.6308             nan     0.0100   -0.0002
#&gt;    320        0.6146             nan     0.0100   -0.0000
#&gt;    340        0.5998             nan     0.0100    0.0001
#&gt;    360        0.5863             nan     0.0100   -0.0002
#&gt;    380        0.5736             nan     0.0100   -0.0003
#&gt;    400        0.5604             nan     0.0100    0.0001
#&gt;    420        0.5495             nan     0.0100   -0.0002
#&gt;    440        0.5378             nan     0.0100   -0.0003
#&gt;    460        0.5272             nan     0.0100    0.0001
#&gt;    480        0.5175             nan     0.0100   -0.0001
#&gt;    500        0.5089             nan     0.0100   -0.0001
#&gt;    520        0.4999             nan     0.0100   -0.0002
#&gt;    540        0.4905             nan     0.0100   -0.0001
#&gt;    560        0.4811             nan     0.0100   -0.0001
#&gt;    580        0.4737             nan     0.0100   -0.0002
#&gt;    600        0.4652             nan     0.0100   -0.0000
#&gt;    620        0.4583             nan     0.0100   -0.0002
#&gt;    640        0.4505             nan     0.0100   -0.0001
#&gt;    660        0.4429             nan     0.0100   -0.0003
#&gt;    680        0.4368             nan     0.0100   -0.0002
#&gt;    700        0.4302             nan     0.0100   -0.0002
#&gt;    720        0.4232             nan     0.0100   -0.0001
#&gt;    740        0.4177             nan     0.0100   -0.0003
#&gt;    760        0.4120             nan     0.0100   -0.0003
#&gt;    780        0.4062             nan     0.0100   -0.0002
#&gt;    800        0.4009             nan     0.0100   -0.0002
#&gt;    820        0.3952             nan     0.0100   -0.0003
#&gt;    840        0.3889             nan     0.0100   -0.0002
#&gt;    860        0.3837             nan     0.0100   -0.0002
#&gt;    880        0.3781             nan     0.0100   -0.0001
#&gt;    900        0.3736             nan     0.0100   -0.0003
#&gt;    920        0.3686             nan     0.0100   -0.0003
#&gt;    940        0.3647             nan     0.0100   -0.0002
#&gt;    960        0.3599             nan     0.0100   -0.0003
#&gt;    980        0.3541             nan     0.0100   -0.0005
#&gt;   1000        0.3493             nan     0.0100   -0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3282             nan     0.1000    0.0232
#&gt;      2        1.2846             nan     0.1000    0.0146
#&gt;      3        1.2470             nan     0.1000    0.0173
#&gt;      4        1.2125             nan     0.1000    0.0151
#&gt;      5        1.1819             nan     0.1000    0.0133
#&gt;      6        1.1555             nan     0.1000    0.0081
#&gt;      7        1.1217             nan     0.1000    0.0139
#&gt;      8        1.0987             nan     0.1000    0.0066
#&gt;      9        1.0759             nan     0.1000    0.0091
#&gt;     10        1.0505             nan     0.1000    0.0089
#&gt;     20        0.9220             nan     0.1000    0.0044
#&gt;     40        0.7892             nan     0.1000   -0.0038
#&gt;     60        0.7165             nan     0.1000   -0.0039
#&gt;     80        0.6602             nan     0.1000   -0.0005
#&gt;    100        0.6246             nan     0.1000   -0.0019
#&gt;    120        0.5946             nan     0.1000   -0.0023
#&gt;    140        0.5709             nan     0.1000   -0.0016
#&gt;    160        0.5514             nan     0.1000   -0.0018
#&gt;    180        0.5323             nan     0.1000   -0.0013
#&gt;    200        0.5174             nan     0.1000   -0.0048
#&gt;    220        0.5032             nan     0.1000   -0.0006
#&gt;    240        0.4893             nan     0.1000   -0.0025
#&gt;    260        0.4736             nan     0.1000   -0.0004
#&gt;    280        0.4617             nan     0.1000   -0.0016
#&gt;    300        0.4507             nan     0.1000   -0.0026
#&gt;    320        0.4407             nan     0.1000   -0.0015
#&gt;    340        0.4301             nan     0.1000   -0.0016
#&gt;    360        0.4205             nan     0.1000   -0.0012
#&gt;    380        0.4131             nan     0.1000   -0.0018
#&gt;    400        0.4094             nan     0.1000   -0.0013
#&gt;    420        0.4016             nan     0.1000   -0.0015
#&gt;    440        0.3902             nan     0.1000   -0.0020
#&gt;    460        0.3834             nan     0.1000   -0.0011
#&gt;    480        0.3758             nan     0.1000   -0.0018
#&gt;    500        0.3703             nan     0.1000   -0.0011
#&gt;    520        0.3683             nan     0.1000   -0.0015
#&gt;    540        0.3614             nan     0.1000   -0.0011
#&gt;    560        0.3548             nan     0.1000   -0.0016
#&gt;    580        0.3484             nan     0.1000   -0.0015
#&gt;    600        0.3425             nan     0.1000   -0.0009
#&gt;    620        0.3367             nan     0.1000   -0.0013
#&gt;    640        0.3314             nan     0.1000   -0.0005
#&gt;    660        0.3303             nan     0.1000   -0.0012
#&gt;    680        0.3246             nan     0.1000   -0.0010
#&gt;    700        0.3191             nan     0.1000   -0.0015
#&gt;    720        0.3139             nan     0.1000   -0.0017
#&gt;    740        0.3090             nan     0.1000   -0.0016
#&gt;    760        0.3042             nan     0.1000   -0.0012
#&gt;    780        0.3033             nan     0.1000   -0.0012
#&gt;    800        0.2992             nan     0.1000   -0.0014
#&gt;    820        0.2959             nan     0.1000   -0.0015
#&gt;    840        0.2948             nan     0.1000   -0.0007
#&gt;    860        0.2905             nan     0.1000   -0.0016
#&gt;    880        0.2901             nan     0.1000   -0.0029
#&gt;    900        0.2846             nan     0.1000   -0.0031
#&gt;    920        0.2782             nan     0.1000   -0.0015
#&gt;    940        0.2763             nan     0.1000   -0.0015
#&gt;    960        0.2698             nan     0.1000   -0.0013
#&gt;    980        0.2673             nan     0.1000   -0.0022
#&gt;   1000        0.2627             nan     0.1000   -0.0008
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3138             nan     0.1000    0.0261
#&gt;      2        1.2597             nan     0.1000    0.0246
#&gt;      3        1.2046             nan     0.1000    0.0197
#&gt;      4        1.1622             nan     0.1000    0.0164
#&gt;      5        1.1313             nan     0.1000    0.0111
#&gt;      6        1.1016             nan     0.1000    0.0129
#&gt;      7        1.0581             nan     0.1000    0.0174
#&gt;      8        1.0315             nan     0.1000    0.0091
#&gt;      9        1.0037             nan     0.1000    0.0081
#&gt;     10        0.9806             nan     0.1000    0.0047
#&gt;     20        0.8209             nan     0.1000    0.0017
#&gt;     40        0.6627             nan     0.1000   -0.0018
#&gt;     60        0.5797             nan     0.1000   -0.0045
#&gt;     80        0.5279             nan     0.1000   -0.0037
#&gt;    100        0.4753             nan     0.1000   -0.0021
#&gt;    120        0.4313             nan     0.1000   -0.0031
#&gt;    140        0.3905             nan     0.1000   -0.0018
#&gt;    160        0.3676             nan     0.1000   -0.0009
#&gt;    180        0.3434             nan     0.1000   -0.0025
#&gt;    200        0.3148             nan     0.1000   -0.0023
#&gt;    220        0.2924             nan     0.1000   -0.0004
#&gt;    240        0.2763             nan     0.1000   -0.0023
#&gt;    260        0.2586             nan     0.1000   -0.0030
#&gt;    280        0.2412             nan     0.1000    0.0001
#&gt;    300        0.2250             nan     0.1000   -0.0013
#&gt;    320        0.2132             nan     0.1000   -0.0009
#&gt;    340        0.2039             nan     0.1000   -0.0018
#&gt;    360        0.1919             nan     0.1000   -0.0024
#&gt;    380        0.1797             nan     0.1000   -0.0018
#&gt;    400        0.1700             nan     0.1000   -0.0011
#&gt;    420        0.1624             nan     0.1000   -0.0012
#&gt;    440        0.1550             nan     0.1000   -0.0002
#&gt;    460        0.1442             nan     0.1000   -0.0008
#&gt;    480        0.1387             nan     0.1000   -0.0010
#&gt;    500        0.1297             nan     0.1000   -0.0007
#&gt;    520        0.1216             nan     0.1000   -0.0005
#&gt;    540        0.1165             nan     0.1000   -0.0013
#&gt;    560        0.1107             nan     0.1000   -0.0003
#&gt;    580        0.1051             nan     0.1000   -0.0008
#&gt;    600        0.0998             nan     0.1000   -0.0004
#&gt;    620        0.0944             nan     0.1000   -0.0009
#&gt;    640        0.0903             nan     0.1000   -0.0001
#&gt;    660        0.0857             nan     0.1000   -0.0004
#&gt;    680        0.0831             nan     0.1000   -0.0004
#&gt;    700        0.0800             nan     0.1000   -0.0002
#&gt;    720        0.0763             nan     0.1000   -0.0002
#&gt;    740        0.0734             nan     0.1000   -0.0004
#&gt;    760        0.0700             nan     0.1000   -0.0007
#&gt;    780        0.0673             nan     0.1000   -0.0004
#&gt;    800        0.0645             nan     0.1000   -0.0006
#&gt;    820        0.0611             nan     0.1000   -0.0003
#&gt;    840        0.0586             nan     0.1000   -0.0004
#&gt;    860        0.0560             nan     0.1000   -0.0003
#&gt;    880        0.0548             nan     0.1000   -0.0003
#&gt;    900        0.0520             nan     0.1000   -0.0002
#&gt;    920        0.0498             nan     0.1000   -0.0003
#&gt;    940        0.0464             nan     0.1000   -0.0004
#&gt;    960        0.0442             nan     0.1000   -0.0003
#&gt;    980        0.0427             nan     0.1000   -0.0002
#&gt;   1000        0.0407             nan     0.1000   -0.0003
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3103             nan     0.1000    0.0292
#&gt;      2        1.2408             nan     0.1000    0.0314
#&gt;      3        1.1853             nan     0.1000    0.0218
#&gt;      4        1.1338             nan     0.1000    0.0165
#&gt;      5        1.0900             nan     0.1000    0.0187
#&gt;      6        1.0505             nan     0.1000    0.0175
#&gt;      7        1.0135             nan     0.1000    0.0110
#&gt;      8        0.9800             nan     0.1000    0.0101
#&gt;      9        0.9583             nan     0.1000    0.0035
#&gt;     10        0.9319             nan     0.1000    0.0072
#&gt;     20        0.7535             nan     0.1000   -0.0015
#&gt;     40        0.5700             nan     0.1000   -0.0033
#&gt;     60        0.4760             nan     0.1000   -0.0009
#&gt;     80        0.4140             nan     0.1000   -0.0058
#&gt;    100        0.3553             nan     0.1000   -0.0032
#&gt;    120        0.3058             nan     0.1000   -0.0013
#&gt;    140        0.2713             nan     0.1000   -0.0011
#&gt;    160        0.2425             nan     0.1000   -0.0011
#&gt;    180        0.2178             nan     0.1000   -0.0018
#&gt;    200        0.2012             nan     0.1000   -0.0007
#&gt;    220        0.1837             nan     0.1000   -0.0017
#&gt;    240        0.1663             nan     0.1000   -0.0009
#&gt;    260        0.1499             nan     0.1000   -0.0011
#&gt;    280        0.1356             nan     0.1000   -0.0008
#&gt;    300        0.1233             nan     0.1000   -0.0006
#&gt;    320        0.1096             nan     0.1000   -0.0006
#&gt;    340        0.1013             nan     0.1000   -0.0014
#&gt;    360        0.0908             nan     0.1000   -0.0004
#&gt;    380        0.0832             nan     0.1000   -0.0009
#&gt;    400        0.0768             nan     0.1000   -0.0005
#&gt;    420        0.0707             nan     0.1000   -0.0004
#&gt;    440        0.0642             nan     0.1000   -0.0007
#&gt;    460        0.0597             nan     0.1000    0.0000
#&gt;    480        0.0534             nan     0.1000   -0.0003
#&gt;    500        0.0494             nan     0.1000   -0.0004
#&gt;    520        0.0462             nan     0.1000   -0.0002
#&gt;    540        0.0430             nan     0.1000   -0.0002
#&gt;    560        0.0402             nan     0.1000   -0.0004
#&gt;    580        0.0373             nan     0.1000   -0.0005
#&gt;    600        0.0343             nan     0.1000   -0.0001
#&gt;    620        0.0312             nan     0.1000   -0.0002
#&gt;    640        0.0286             nan     0.1000   -0.0001
#&gt;    660        0.0265             nan     0.1000   -0.0002
#&gt;    680        0.0242             nan     0.1000   -0.0001
#&gt;    700        0.0228             nan     0.1000   -0.0002
#&gt;    720        0.0210             nan     0.1000   -0.0002
#&gt;    740        0.0193             nan     0.1000   -0.0002
#&gt;    760        0.0178             nan     0.1000   -0.0003
#&gt;    780        0.0165             nan     0.1000   -0.0001
#&gt;    800        0.0152             nan     0.1000   -0.0001
#&gt;    820        0.0141             nan     0.1000   -0.0001
#&gt;    840        0.0131             nan     0.1000   -0.0001
#&gt;    860        0.0121             nan     0.1000   -0.0001
#&gt;    880        0.0114             nan     0.1000   -0.0001
#&gt;    900        0.0104             nan     0.1000   -0.0001
#&gt;    920        0.0099             nan     0.1000   -0.0001
#&gt;    940        0.0091             nan     0.1000   -0.0000
#&gt;    960        0.0085             nan     0.1000   -0.0000
#&gt;    980        0.0079             nan     0.1000   -0.0001
#&gt;   1000        0.0070             nan     0.1000   -0.0000
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3788             nan     0.0010    0.0002
#&gt;      2        1.3783             nan     0.0010    0.0003
#&gt;      3        1.3777             nan     0.0010    0.0003
#&gt;      4        1.3772             nan     0.0010    0.0002
#&gt;      5        1.3766             nan     0.0010    0.0003
#&gt;      6        1.3761             nan     0.0010    0.0002
#&gt;      7        1.3755             nan     0.0010    0.0002
#&gt;      8        1.3750             nan     0.0010    0.0002
#&gt;      9        1.3745             nan     0.0010    0.0002
#&gt;     10        1.3739             nan     0.0010    0.0002
#&gt;     20        1.3684             nan     0.0010    0.0002
#&gt;     40        1.3581             nan     0.0010    0.0002
#&gt;     60        1.3480             nan     0.0010    0.0002
#&gt;     80        1.3380             nan     0.0010    0.0002
#&gt;    100        1.3280             nan     0.0010    0.0002
#&gt;    120        1.3186             nan     0.0010    0.0001
#&gt;    140        1.3091             nan     0.0010    0.0002
#&gt;    160        1.3008             nan     0.0010    0.0002
#&gt;    180        1.2922             nan     0.0010    0.0002
#&gt;    200        1.2829             nan     0.0010    0.0002
#&gt;    220        1.2744             nan     0.0010    0.0001
#&gt;    240        1.2661             nan     0.0010    0.0002
#&gt;    260        1.2579             nan     0.0010    0.0001
#&gt;    280        1.2500             nan     0.0010    0.0001
#&gt;    300        1.2419             nan     0.0010    0.0002
#&gt;    320        1.2345             nan     0.0010    0.0002
#&gt;    340        1.2271             nan     0.0010    0.0001
#&gt;    360        1.2201             nan     0.0010    0.0002
#&gt;    380        1.2129             nan     0.0010    0.0001
#&gt;    400        1.2057             nan     0.0010    0.0001
#&gt;    420        1.1987             nan     0.0010    0.0001
#&gt;    440        1.1918             nan     0.0010    0.0001
#&gt;    460        1.1851             nan     0.0010    0.0001
#&gt;    480        1.1783             nan     0.0010    0.0001
#&gt;    500        1.1716             nan     0.0010    0.0001
#&gt;    520        1.1654             nan     0.0010    0.0001
#&gt;    540        1.1592             nan     0.0010    0.0001
#&gt;    560        1.1532             nan     0.0010    0.0001
#&gt;    580        1.1469             nan     0.0010    0.0001
#&gt;    600        1.1411             nan     0.0010    0.0001
#&gt;    620        1.1356             nan     0.0010    0.0001
#&gt;    640        1.1300             nan     0.0010    0.0000
#&gt;    660        1.1243             nan     0.0010    0.0001
#&gt;    680        1.1188             nan     0.0010    0.0001
#&gt;    700        1.1132             nan     0.0010    0.0001
#&gt;    720        1.1079             nan     0.0010    0.0001
#&gt;    740        1.1026             nan     0.0010    0.0001
#&gt;    760        1.0976             nan     0.0010    0.0001
#&gt;    780        1.0927             nan     0.0010    0.0001
#&gt;    800        1.0877             nan     0.0010    0.0001
#&gt;    820        1.0828             nan     0.0010    0.0001
#&gt;    840        1.0782             nan     0.0010    0.0001
#&gt;    860        1.0737             nan     0.0010    0.0001
#&gt;    880        1.0691             nan     0.0010    0.0000
#&gt;    900        1.0645             nan     0.0010    0.0000
#&gt;    920        1.0599             nan     0.0010    0.0001
#&gt;    940        1.0554             nan     0.0010    0.0001
#&gt;    960        1.0510             nan     0.0010    0.0001
#&gt;    980        1.0467             nan     0.0010    0.0001
#&gt;   1000        1.0426             nan     0.0010    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3786             nan     0.0010    0.0003
#&gt;      2        1.3780             nan     0.0010    0.0003
#&gt;      3        1.3773             nan     0.0010    0.0003
#&gt;      4        1.3765             nan     0.0010    0.0003
#&gt;      5        1.3758             nan     0.0010    0.0003
#&gt;      6        1.3751             nan     0.0010    0.0003
#&gt;      7        1.3744             nan     0.0010    0.0003
#&gt;      8        1.3736             nan     0.0010    0.0003
#&gt;      9        1.3729             nan     0.0010    0.0003
#&gt;     10        1.3721             nan     0.0010    0.0003
#&gt;     20        1.3650             nan     0.0010    0.0003
#&gt;     40        1.3510             nan     0.0010    0.0003
#&gt;     60        1.3381             nan     0.0010    0.0003
#&gt;     80        1.3250             nan     0.0010    0.0003
#&gt;    100        1.3128             nan     0.0010    0.0003
#&gt;    120        1.3002             nan     0.0010    0.0003
#&gt;    140        1.2882             nan     0.0010    0.0002
#&gt;    160        1.2764             nan     0.0010    0.0003
#&gt;    180        1.2649             nan     0.0010    0.0002
#&gt;    200        1.2535             nan     0.0010    0.0002
#&gt;    220        1.2426             nan     0.0010    0.0002
#&gt;    240        1.2321             nan     0.0010    0.0002
#&gt;    260        1.2217             nan     0.0010    0.0002
#&gt;    280        1.2116             nan     0.0010    0.0002
#&gt;    300        1.2013             nan     0.0010    0.0002
#&gt;    320        1.1917             nan     0.0010    0.0001
#&gt;    340        1.1824             nan     0.0010    0.0002
#&gt;    360        1.1735             nan     0.0010    0.0001
#&gt;    380        1.1647             nan     0.0010    0.0002
#&gt;    400        1.1561             nan     0.0010    0.0002
#&gt;    420        1.1478             nan     0.0010    0.0002
#&gt;    440        1.1392             nan     0.0010    0.0002
#&gt;    460        1.1312             nan     0.0010    0.0002
#&gt;    480        1.1230             nan     0.0010    0.0002
#&gt;    500        1.1151             nan     0.0010    0.0002
#&gt;    520        1.1076             nan     0.0010    0.0001
#&gt;    540        1.0996             nan     0.0010    0.0002
#&gt;    560        1.0921             nan     0.0010    0.0001
#&gt;    580        1.0848             nan     0.0010    0.0001
#&gt;    600        1.0775             nan     0.0010    0.0002
#&gt;    620        1.0706             nan     0.0010    0.0001
#&gt;    640        1.0638             nan     0.0010    0.0001
#&gt;    660        1.0570             nan     0.0010    0.0001
#&gt;    680        1.0503             nan     0.0010    0.0002
#&gt;    700        1.0438             nan     0.0010    0.0001
#&gt;    720        1.0375             nan     0.0010    0.0001
#&gt;    740        1.0312             nan     0.0010    0.0001
#&gt;    760        1.0252             nan     0.0010    0.0001
#&gt;    780        1.0195             nan     0.0010    0.0001
#&gt;    800        1.0136             nan     0.0010    0.0001
#&gt;    820        1.0077             nan     0.0010    0.0001
#&gt;    840        1.0021             nan     0.0010    0.0001
#&gt;    860        0.9966             nan     0.0010    0.0001
#&gt;    880        0.9911             nan     0.0010    0.0001
#&gt;    900        0.9858             nan     0.0010    0.0001
#&gt;    920        0.9807             nan     0.0010    0.0001
#&gt;    940        0.9756             nan     0.0010    0.0001
#&gt;    960        0.9704             nan     0.0010    0.0001
#&gt;    980        0.9654             nan     0.0010    0.0001
#&gt;   1000        0.9605             nan     0.0010    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3787             nan     0.0010    0.0003
#&gt;      2        1.3779             nan     0.0010    0.0004
#&gt;      3        1.3771             nan     0.0010    0.0003
#&gt;      4        1.3762             nan     0.0010    0.0003
#&gt;      5        1.3753             nan     0.0010    0.0004
#&gt;      6        1.3745             nan     0.0010    0.0003
#&gt;      7        1.3738             nan     0.0010    0.0002
#&gt;      8        1.3730             nan     0.0010    0.0004
#&gt;      9        1.3721             nan     0.0010    0.0003
#&gt;     10        1.3714             nan     0.0010    0.0004
#&gt;     20        1.3628             nan     0.0010    0.0003
#&gt;     40        1.3474             nan     0.0010    0.0004
#&gt;     60        1.3324             nan     0.0010    0.0003
#&gt;     80        1.3173             nan     0.0010    0.0003
#&gt;    100        1.3029             nan     0.0010    0.0002
#&gt;    120        1.2888             nan     0.0010    0.0003
#&gt;    140        1.2752             nan     0.0010    0.0001
#&gt;    160        1.2619             nan     0.0010    0.0003
#&gt;    180        1.2487             nan     0.0010    0.0003
#&gt;    200        1.2360             nan     0.0010    0.0003
#&gt;    220        1.2236             nan     0.0010    0.0002
#&gt;    240        1.2113             nan     0.0010    0.0001
#&gt;    260        1.1996             nan     0.0010    0.0002
#&gt;    280        1.1881             nan     0.0010    0.0002
#&gt;    300        1.1772             nan     0.0010    0.0003
#&gt;    320        1.1662             nan     0.0010    0.0002
#&gt;    340        1.1556             nan     0.0010    0.0002
#&gt;    360        1.1457             nan     0.0010    0.0001
#&gt;    380        1.1361             nan     0.0010    0.0001
#&gt;    400        1.1266             nan     0.0010    0.0002
#&gt;    420        1.1167             nan     0.0010    0.0002
#&gt;    440        1.1074             nan     0.0010    0.0002
#&gt;    460        1.0978             nan     0.0010    0.0002
#&gt;    480        1.0889             nan     0.0010    0.0001
#&gt;    500        1.0799             nan     0.0010    0.0001
#&gt;    520        1.0710             nan     0.0010    0.0001
#&gt;    540        1.0625             nan     0.0010    0.0001
#&gt;    560        1.0539             nan     0.0010    0.0001
#&gt;    580        1.0458             nan     0.0010    0.0001
#&gt;    600        1.0380             nan     0.0010    0.0001
#&gt;    620        1.0305             nan     0.0010    0.0001
#&gt;    640        1.0229             nan     0.0010    0.0001
#&gt;    660        1.0153             nan     0.0010    0.0001
#&gt;    680        1.0077             nan     0.0010    0.0001
#&gt;    700        1.0005             nan     0.0010    0.0001
#&gt;    720        0.9932             nan     0.0010    0.0001
#&gt;    740        0.9865             nan     0.0010    0.0001
#&gt;    760        0.9795             nan     0.0010    0.0002
#&gt;    780        0.9727             nan     0.0010    0.0000
#&gt;    800        0.9663             nan     0.0010    0.0001
#&gt;    820        0.9599             nan     0.0010    0.0001
#&gt;    840        0.9536             nan     0.0010    0.0001
#&gt;    860        0.9475             nan     0.0010    0.0001
#&gt;    880        0.9412             nan     0.0010    0.0001
#&gt;    900        0.9354             nan     0.0010    0.0001
#&gt;    920        0.9293             nan     0.0010    0.0001
#&gt;    940        0.9235             nan     0.0010    0.0001
#&gt;    960        0.9179             nan     0.0010    0.0000
#&gt;    980        0.9123             nan     0.0010    0.0001
#&gt;   1000        0.9070             nan     0.0010    0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3739             nan     0.0100    0.0024
#&gt;      2        1.3693             nan     0.0100    0.0018
#&gt;      3        1.3644             nan     0.0100    0.0024
#&gt;      4        1.3590             nan     0.0100    0.0025
#&gt;      5        1.3529             nan     0.0100    0.0023
#&gt;      6        1.3475             nan     0.0100    0.0024
#&gt;      7        1.3425             nan     0.0100    0.0023
#&gt;      8        1.3374             nan     0.0100    0.0018
#&gt;      9        1.3318             nan     0.0100    0.0021
#&gt;     10        1.3268             nan     0.0100    0.0022
#&gt;     20        1.2824             nan     0.0100    0.0015
#&gt;     40        1.2042             nan     0.0100    0.0016
#&gt;     60        1.1399             nan     0.0100    0.0011
#&gt;     80        1.0874             nan     0.0100    0.0005
#&gt;    100        1.0424             nan     0.0100    0.0009
#&gt;    120        1.0039             nan     0.0100    0.0005
#&gt;    140        0.9698             nan     0.0100    0.0002
#&gt;    160        0.9401             nan     0.0100    0.0002
#&gt;    180        0.9157             nan     0.0100    0.0001
#&gt;    200        0.8927             nan     0.0100    0.0004
#&gt;    220        0.8722             nan     0.0100    0.0001
#&gt;    240        0.8536             nan     0.0100    0.0001
#&gt;    260        0.8365             nan     0.0100    0.0003
#&gt;    280        0.8220             nan     0.0100    0.0001
#&gt;    300        0.8071             nan     0.0100    0.0002
#&gt;    320        0.7954             nan     0.0100   -0.0001
#&gt;    340        0.7841             nan     0.0100   -0.0001
#&gt;    360        0.7731             nan     0.0100   -0.0000
#&gt;    380        0.7637             nan     0.0100   -0.0001
#&gt;    400        0.7550             nan     0.0100    0.0001
#&gt;    420        0.7462             nan     0.0100    0.0000
#&gt;    440        0.7382             nan     0.0100   -0.0002
#&gt;    460        0.7299             nan     0.0100   -0.0001
#&gt;    480        0.7221             nan     0.0100    0.0001
#&gt;    500        0.7152             nan     0.0100   -0.0002
#&gt;    520        0.7085             nan     0.0100   -0.0001
#&gt;    540        0.7021             nan     0.0100   -0.0000
#&gt;    560        0.6958             nan     0.0100   -0.0002
#&gt;    580        0.6894             nan     0.0100   -0.0000
#&gt;    600        0.6832             nan     0.0100    0.0000
#&gt;    620        0.6776             nan     0.0100   -0.0002
#&gt;    640        0.6721             nan     0.0100   -0.0002
#&gt;    660        0.6668             nan     0.0100   -0.0001
#&gt;    680        0.6612             nan     0.0100   -0.0000
#&gt;    700        0.6559             nan     0.0100   -0.0001
#&gt;    720        0.6512             nan     0.0100   -0.0001
#&gt;    740        0.6468             nan     0.0100   -0.0001
#&gt;    760        0.6418             nan     0.0100   -0.0001
#&gt;    780        0.6375             nan     0.0100   -0.0001
#&gt;    800        0.6334             nan     0.0100   -0.0001
#&gt;    820        0.6298             nan     0.0100   -0.0006
#&gt;    840        0.6256             nan     0.0100   -0.0002
#&gt;    860        0.6222             nan     0.0100   -0.0001
#&gt;    880        0.6183             nan     0.0100   -0.0002
#&gt;    900        0.6139             nan     0.0100   -0.0003
#&gt;    920        0.6097             nan     0.0100   -0.0001
#&gt;    940        0.6057             nan     0.0100   -0.0001
#&gt;    960        0.6022             nan     0.0100   -0.0002
#&gt;    980        0.5990             nan     0.0100   -0.0001
#&gt;   1000        0.5957             nan     0.0100   -0.0003
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3719             nan     0.0100    0.0028
#&gt;      2        1.3651             nan     0.0100    0.0023
#&gt;      3        1.3583             nan     0.0100    0.0032
#&gt;      4        1.3511             nan     0.0100    0.0032
#&gt;      5        1.3436             nan     0.0100    0.0032
#&gt;      6        1.3370             nan     0.0100    0.0028
#&gt;      7        1.3310             nan     0.0100    0.0027
#&gt;      8        1.3252             nan     0.0100    0.0026
#&gt;      9        1.3189             nan     0.0100    0.0029
#&gt;     10        1.3128             nan     0.0100    0.0027
#&gt;     20        1.2567             nan     0.0100    0.0027
#&gt;     40        1.1590             nan     0.0100    0.0018
#&gt;     60        1.0804             nan     0.0100    0.0016
#&gt;     80        1.0153             nan     0.0100    0.0011
#&gt;    100        0.9613             nan     0.0100    0.0007
#&gt;    120        0.9160             nan     0.0100    0.0010
#&gt;    140        0.8758             nan     0.0100    0.0005
#&gt;    160        0.8438             nan     0.0100    0.0002
#&gt;    180        0.8159             nan     0.0100    0.0003
#&gt;    200        0.7912             nan     0.0100    0.0005
#&gt;    220        0.7686             nan     0.0100    0.0002
#&gt;    240        0.7491             nan     0.0100    0.0002
#&gt;    260        0.7302             nan     0.0100    0.0003
#&gt;    280        0.7126             nan     0.0100   -0.0001
#&gt;    300        0.6969             nan     0.0100    0.0002
#&gt;    320        0.6815             nan     0.0100   -0.0000
#&gt;    340        0.6686             nan     0.0100    0.0000
#&gt;    360        0.6557             nan     0.0100    0.0001
#&gt;    380        0.6449             nan     0.0100   -0.0002
#&gt;    400        0.6344             nan     0.0100   -0.0002
#&gt;    420        0.6238             nan     0.0100   -0.0001
#&gt;    440        0.6133             nan     0.0100   -0.0004
#&gt;    460        0.6027             nan     0.0100   -0.0001
#&gt;    480        0.5924             nan     0.0100   -0.0002
#&gt;    500        0.5839             nan     0.0100   -0.0004
#&gt;    520        0.5762             nan     0.0100   -0.0003
#&gt;    540        0.5685             nan     0.0100   -0.0003
#&gt;    560        0.5618             nan     0.0100    0.0000
#&gt;    580        0.5541             nan     0.0100    0.0001
#&gt;    600        0.5466             nan     0.0100   -0.0004
#&gt;    620        0.5383             nan     0.0100   -0.0002
#&gt;    640        0.5319             nan     0.0100   -0.0002
#&gt;    660        0.5258             nan     0.0100   -0.0002
#&gt;    680        0.5197             nan     0.0100   -0.0001
#&gt;    700        0.5139             nan     0.0100   -0.0001
#&gt;    720        0.5081             nan     0.0100   -0.0002
#&gt;    740        0.5015             nan     0.0100   -0.0001
#&gt;    760        0.4959             nan     0.0100   -0.0002
#&gt;    780        0.4904             nan     0.0100   -0.0001
#&gt;    800        0.4848             nan     0.0100   -0.0001
#&gt;    820        0.4799             nan     0.0100   -0.0001
#&gt;    840        0.4742             nan     0.0100   -0.0004
#&gt;    860        0.4689             nan     0.0100   -0.0002
#&gt;    880        0.4633             nan     0.0100   -0.0001
#&gt;    900        0.4590             nan     0.0100   -0.0001
#&gt;    920        0.4545             nan     0.0100   -0.0002
#&gt;    940        0.4486             nan     0.0100   -0.0000
#&gt;    960        0.4442             nan     0.0100   -0.0002
#&gt;    980        0.4393             nan     0.0100   -0.0003
#&gt;   1000        0.4349             nan     0.0100   -0.0002
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3705             nan     0.0100    0.0031
#&gt;      2        1.3633             nan     0.0100    0.0031
#&gt;      3        1.3557             nan     0.0100    0.0036
#&gt;      4        1.3476             nan     0.0100    0.0032
#&gt;      5        1.3401             nan     0.0100    0.0020
#&gt;      6        1.3315             nan     0.0100    0.0039
#&gt;      7        1.3242             nan     0.0100    0.0039
#&gt;      8        1.3173             nan     0.0100    0.0029
#&gt;      9        1.3085             nan     0.0100    0.0031
#&gt;     10        1.3016             nan     0.0100    0.0027
#&gt;     20        1.2338             nan     0.0100    0.0030
#&gt;     40        1.1212             nan     0.0100    0.0022
#&gt;     60        1.0358             nan     0.0100    0.0016
#&gt;     80        0.9656             nan     0.0100    0.0009
#&gt;    100        0.9055             nan     0.0100    0.0009
#&gt;    120        0.8564             nan     0.0100    0.0009
#&gt;    140        0.8122             nan     0.0100    0.0004
#&gt;    160        0.7761             nan     0.0100    0.0002
#&gt;    180        0.7425             nan     0.0100   -0.0000
#&gt;    200        0.7152             nan     0.0100    0.0003
#&gt;    220        0.6914             nan     0.0100    0.0002
#&gt;    240        0.6682             nan     0.0100    0.0002
#&gt;    260        0.6465             nan     0.0100    0.0001
#&gt;    280        0.6282             nan     0.0100   -0.0003
#&gt;    300        0.6112             nan     0.0100   -0.0002
#&gt;    320        0.5945             nan     0.0100    0.0001
#&gt;    340        0.5793             nan     0.0100    0.0001
#&gt;    360        0.5653             nan     0.0100   -0.0002
#&gt;    380        0.5521             nan     0.0100   -0.0001
#&gt;    400        0.5407             nan     0.0100   -0.0005
#&gt;    420        0.5296             nan     0.0100   -0.0002
#&gt;    440        0.5182             nan     0.0100   -0.0000
#&gt;    460        0.5074             nan     0.0100   -0.0002
#&gt;    480        0.4972             nan     0.0100   -0.0001
#&gt;    500        0.4880             nan     0.0100   -0.0002
#&gt;    520        0.4794             nan     0.0100   -0.0002
#&gt;    540        0.4698             nan     0.0100   -0.0001
#&gt;    560        0.4618             nan     0.0100   -0.0003
#&gt;    580        0.4531             nan     0.0100   -0.0000
#&gt;    600        0.4443             nan     0.0100   -0.0001
#&gt;    620        0.4368             nan     0.0100   -0.0003
#&gt;    640        0.4291             nan     0.0100   -0.0002
#&gt;    660        0.4218             nan     0.0100   -0.0003
#&gt;    680        0.4146             nan     0.0100   -0.0001
#&gt;    700        0.4073             nan     0.0100   -0.0003
#&gt;    720        0.4011             nan     0.0100   -0.0002
#&gt;    740        0.3951             nan     0.0100   -0.0001
#&gt;    760        0.3883             nan     0.0100   -0.0003
#&gt;    780        0.3817             nan     0.0100   -0.0001
#&gt;    800        0.3753             nan     0.0100   -0.0003
#&gt;    820        0.3699             nan     0.0100   -0.0001
#&gt;    840        0.3633             nan     0.0100   -0.0002
#&gt;    860        0.3578             nan     0.0100   -0.0002
#&gt;    880        0.3521             nan     0.0100   -0.0000
#&gt;    900        0.3468             nan     0.0100   -0.0001
#&gt;    920        0.3421             nan     0.0100   -0.0001
#&gt;    940        0.3368             nan     0.0100   -0.0002
#&gt;    960        0.3315             nan     0.0100   -0.0001
#&gt;    980        0.3272             nan     0.0100   -0.0001
#&gt;   1000        0.3235             nan     0.0100   -0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3233             nan     0.1000    0.0226
#&gt;      2        1.2783             nan     0.1000    0.0188
#&gt;      3        1.2300             nan     0.1000    0.0159
#&gt;      4        1.1901             nan     0.1000    0.0206
#&gt;      5        1.1605             nan     0.1000    0.0115
#&gt;      6        1.1290             nan     0.1000    0.0117
#&gt;      7        1.1089             nan     0.1000    0.0095
#&gt;      8        1.0826             nan     0.1000    0.0098
#&gt;      9        1.0494             nan     0.1000    0.0105
#&gt;     10        1.0243             nan     0.1000    0.0103
#&gt;     20        0.8811             nan     0.1000    0.0021
#&gt;     40        0.7475             nan     0.1000   -0.0007
#&gt;     60        0.6810             nan     0.1000   -0.0007
#&gt;     80        0.6275             nan     0.1000    0.0001
#&gt;    100        0.5903             nan     0.1000   -0.0009
#&gt;    120        0.5633             nan     0.1000   -0.0014
#&gt;    140        0.5390             nan     0.1000   -0.0042
#&gt;    160        0.5217             nan     0.1000   -0.0009
#&gt;    180        0.5001             nan     0.1000   -0.0005
#&gt;    200        0.4834             nan     0.1000   -0.0026
#&gt;    220        0.4684             nan     0.1000   -0.0017
#&gt;    240        0.4551             nan     0.1000   -0.0024
#&gt;    260        0.4422             nan     0.1000   -0.0032
#&gt;    280        0.4309             nan     0.1000   -0.0014
#&gt;    300        0.4221             nan     0.1000   -0.0007
#&gt;    320        0.4125             nan     0.1000   -0.0017
#&gt;    340        0.4035             nan     0.1000   -0.0019
#&gt;    360        0.3939             nan     0.1000   -0.0019
#&gt;    380        0.3881             nan     0.1000   -0.0043
#&gt;    400        0.3814             nan     0.1000   -0.0028
#&gt;    420        0.3728             nan     0.1000   -0.0015
#&gt;    440        0.3634             nan     0.1000   -0.0009
#&gt;    460        0.3548             nan     0.1000   -0.0008
#&gt;    480        0.3470             nan     0.1000   -0.0020
#&gt;    500        0.3392             nan     0.1000   -0.0013
#&gt;    520        0.3330             nan     0.1000   -0.0023
#&gt;    540        0.3270             nan     0.1000   -0.0026
#&gt;    560        0.3218             nan     0.1000   -0.0028
#&gt;    580        0.3170             nan     0.1000   -0.0008
#&gt;    600        0.3103             nan     0.1000   -0.0005
#&gt;    620        0.3044             nan     0.1000   -0.0011
#&gt;    640        0.2987             nan     0.1000   -0.0017
#&gt;    660        0.2934             nan     0.1000   -0.0012
#&gt;    680        0.2875             nan     0.1000   -0.0006
#&gt;    700        0.2833             nan     0.1000   -0.0017
#&gt;    720        0.2806             nan     0.1000   -0.0066
#&gt;    740        0.2761             nan     0.1000   -0.0007
#&gt;    760        0.2723             nan     0.1000   -0.0007
#&gt;    780        0.2664             nan     0.1000   -0.0006
#&gt;    800        0.2605             nan     0.1000   -0.0008
#&gt;    820        0.2569             nan     0.1000   -0.0007
#&gt;    840        0.2549             nan     0.1000   -0.0009
#&gt;    860        0.2513             nan     0.1000   -0.0010
#&gt;    880        0.2471             nan     0.1000   -0.0008
#&gt;    900        0.2425             nan     0.1000   -0.0004
#&gt;    920        0.2407             nan     0.1000   -0.0012
#&gt;    940        0.2377             nan     0.1000   -0.0012
#&gt;    960        0.2337             nan     0.1000   -0.0015
#&gt;    980        0.2300             nan     0.1000   -0.0022
#&gt;   1000        0.2271             nan     0.1000   -0.0014
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3107             nan     0.1000    0.0331
#&gt;      2        1.2436             nan     0.1000    0.0281
#&gt;      3        1.1947             nan     0.1000    0.0211
#&gt;      4        1.1486             nan     0.1000    0.0143
#&gt;      5        1.1097             nan     0.1000    0.0133
#&gt;      6        1.0753             nan     0.1000    0.0113
#&gt;      7        1.0344             nan     0.1000    0.0173
#&gt;      8        0.9969             nan     0.1000    0.0109
#&gt;      9        0.9688             nan     0.1000    0.0124
#&gt;     10        0.9489             nan     0.1000    0.0047
#&gt;     20        0.7926             nan     0.1000   -0.0008
#&gt;     40        0.6370             nan     0.1000   -0.0013
#&gt;     60        0.5444             nan     0.1000   -0.0020
#&gt;     80        0.4859             nan     0.1000   -0.0022
#&gt;    100        0.4444             nan     0.1000   -0.0025
#&gt;    120        0.3968             nan     0.1000   -0.0026
#&gt;    140        0.3585             nan     0.1000   -0.0020
#&gt;    160        0.3295             nan     0.1000   -0.0006
#&gt;    180        0.3069             nan     0.1000   -0.0020
#&gt;    200        0.2786             nan     0.1000   -0.0004
#&gt;    220        0.2545             nan     0.1000   -0.0011
#&gt;    240        0.2383             nan     0.1000   -0.0008
#&gt;    260        0.2208             nan     0.1000   -0.0010
#&gt;    280        0.2081             nan     0.1000   -0.0025
#&gt;    300        0.1934             nan     0.1000   -0.0007
#&gt;    320        0.1817             nan     0.1000   -0.0011
#&gt;    340        0.1696             nan     0.1000   -0.0016
#&gt;    360        0.1600             nan     0.1000   -0.0006
#&gt;    380        0.1500             nan     0.1000   -0.0013
#&gt;    400        0.1406             nan     0.1000   -0.0009
#&gt;    420        0.1309             nan     0.1000   -0.0009
#&gt;    440        0.1223             nan     0.1000   -0.0000
#&gt;    460        0.1138             nan     0.1000   -0.0005
#&gt;    480        0.1077             nan     0.1000   -0.0010
#&gt;    500        0.1004             nan     0.1000   -0.0005
#&gt;    520        0.0934             nan     0.1000   -0.0008
#&gt;    540        0.0875             nan     0.1000   -0.0005
#&gt;    560        0.0816             nan     0.1000   -0.0007
#&gt;    580        0.0771             nan     0.1000   -0.0005
#&gt;    600        0.0739             nan     0.1000   -0.0004
#&gt;    620        0.0693             nan     0.1000   -0.0004
#&gt;    640        0.0658             nan     0.1000   -0.0003
#&gt;    660        0.0614             nan     0.1000   -0.0005
#&gt;    680        0.0581             nan     0.1000   -0.0007
#&gt;    700        0.0551             nan     0.1000   -0.0002
#&gt;    720        0.0518             nan     0.1000   -0.0001
#&gt;    740        0.0492             nan     0.1000   -0.0007
#&gt;    760        0.0459             nan     0.1000   -0.0001
#&gt;    780        0.0431             nan     0.1000   -0.0003
#&gt;    800        0.0417             nan     0.1000   -0.0002
#&gt;    820        0.0400             nan     0.1000   -0.0005
#&gt;    840        0.0376             nan     0.1000   -0.0001
#&gt;    860        0.0355             nan     0.1000   -0.0003
#&gt;    880        0.0336             nan     0.1000   -0.0003
#&gt;    900        0.0317             nan     0.1000   -0.0002
#&gt;    920        0.0304             nan     0.1000   -0.0003
#&gt;    940        0.0291             nan     0.1000   -0.0001
#&gt;    960        0.0270             nan     0.1000   -0.0001
#&gt;    980        0.0254             nan     0.1000   -0.0002
#&gt;   1000        0.0245             nan     0.1000   -0.0001
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3010             nan     0.1000    0.0351
#&gt;      2        1.2168             nan     0.1000    0.0272
#&gt;      3        1.1563             nan     0.1000    0.0232
#&gt;      4        1.1108             nan     0.1000    0.0188
#&gt;      5        1.0611             nan     0.1000    0.0212
#&gt;      6        1.0260             nan     0.1000    0.0143
#&gt;      7        0.9971             nan     0.1000    0.0049
#&gt;      8        0.9612             nan     0.1000    0.0128
#&gt;      9        0.9322             nan     0.1000    0.0077
#&gt;     10        0.8992             nan     0.1000    0.0089
#&gt;     20        0.7163             nan     0.1000   -0.0000
#&gt;     40        0.5384             nan     0.1000   -0.0007
#&gt;     60        0.4519             nan     0.1000   -0.0017
#&gt;     80        0.3947             nan     0.1000   -0.0026
#&gt;    100        0.3415             nan     0.1000   -0.0028
#&gt;    120        0.2949             nan     0.1000   -0.0013
#&gt;    140        0.2558             nan     0.1000   -0.0028
#&gt;    160        0.2224             nan     0.1000   -0.0012
#&gt;    180        0.1932             nan     0.1000   -0.0018
#&gt;    200        0.1718             nan     0.1000   -0.0008
#&gt;    220        0.1537             nan     0.1000   -0.0016
#&gt;    240        0.1386             nan     0.1000   -0.0014
#&gt;    260        0.1264             nan     0.1000   -0.0007
#&gt;    280        0.1094             nan     0.1000   -0.0001
#&gt;    300        0.0967             nan     0.1000   -0.0004
#&gt;    320        0.0872             nan     0.1000   -0.0007
#&gt;    340        0.0783             nan     0.1000   -0.0008
#&gt;    360        0.0709             nan     0.1000   -0.0005
#&gt;    380        0.0652             nan     0.1000   -0.0009
#&gt;    400        0.0593             nan     0.1000   -0.0003
#&gt;    420        0.0542             nan     0.1000   -0.0006
#&gt;    440        0.0486             nan     0.1000   -0.0007
#&gt;    460        0.0438             nan     0.1000   -0.0003
#&gt;    480        0.0394             nan     0.1000   -0.0002
#&gt;    500        0.0361             nan     0.1000   -0.0004
#&gt;    520        0.0323             nan     0.1000   -0.0003
#&gt;    540        0.0295             nan     0.1000   -0.0001
#&gt;    560        0.0267             nan     0.1000   -0.0003
#&gt;    580        0.0244             nan     0.1000   -0.0001
#&gt;    600        0.0222             nan     0.1000   -0.0001
#&gt;    620        0.0205             nan     0.1000   -0.0001
#&gt;    640        0.0187             nan     0.1000   -0.0000
#&gt;    660        0.0171             nan     0.1000   -0.0002
#&gt;    680        0.0152             nan     0.1000   -0.0001
#&gt;    700        0.0139             nan     0.1000   -0.0001
#&gt;    720        0.0125             nan     0.1000   -0.0001
#&gt;    740        0.0115             nan     0.1000    0.0000
#&gt;    760        0.0105             nan     0.1000   -0.0001
#&gt;    780        0.0096             nan     0.1000   -0.0001
#&gt;    800        0.0089             nan     0.1000   -0.0001
#&gt;    820        0.0081             nan     0.1000   -0.0001
#&gt;    840        0.0075             nan     0.1000   -0.0000
#&gt;    860        0.0068             nan     0.1000   -0.0000
#&gt;    880        0.0062             nan     0.1000   -0.0001
#&gt;    900        0.0056             nan     0.1000   -0.0000
#&gt;    920        0.0051             nan     0.1000   -0.0000
#&gt;    940        0.0046             nan     0.1000   -0.0000
#&gt;    960        0.0042             nan     0.1000   -0.0000
#&gt;    980        0.0038             nan     0.1000   -0.0000
#&gt;   1000        0.0035             nan     0.1000   -0.0000
#&gt; 
#&gt; Iter   TrainDeviance   ValidDeviance   StepSize   Improve
#&gt;      1        1.3299             nan     0.1000    0.0257
#&gt;      2        1.2844             nan     0.1000    0.0208
#&gt;      3        1.2443             nan     0.1000    0.0159
#&gt;      4        1.2034             nan     0.1000    0.0178
#&gt;      5        1.1749             nan     0.1000    0.0127
#&gt;      6        1.1487             nan     0.1000    0.0110
#&gt;      7        1.1213             nan     0.1000    0.0132
#&gt;      8        1.0953             nan     0.1000    0.0103
#&gt;      9        1.0744             nan     0.1000    0.0090
#&gt;     10        1.0565             nan     0.1000    0.0078
#&gt;     20        0.9156             nan     0.1000    0.0034
#&gt;     40        0.7795             nan     0.1000    0.0013
#&gt;     60        0.7094             nan     0.1000   -0.0009
#&gt;     80        0.6646             nan     0.1000   -0.0006
#&gt;    100        0.6353             nan     0.1000   -0.0014
#&gt;    120        0.6104             nan     0.1000   -0.0014
#&gt;    140        0.5877             nan     0.1000   -0.0016
#&gt;    160        0.5640             nan     0.1000   -0.0020
#&gt;    180        0.5497             nan     0.1000   -0.0018
#&gt;    200        0.5358             nan     0.1000   -0.0018
#&gt;    220        0.5244             nan     0.1000   -0.0018
#&gt;    240        0.5111             nan     0.1000   -0.0015
#&gt;    260        0.5016             nan     0.1000   -0.0025
#&gt;    280        0.4874             nan     0.1000   -0.0017
#&gt;    300        0.4796             nan     0.1000   -0.0010
#&gt;    320        0.4726             nan     0.1000   -0.0015
#&gt;    340        0.4629             nan     0.1000   -0.0023
#&gt;    360        0.4581             nan     0.1000   -0.0026
#&gt;    380        0.4464             nan     0.1000   -0.0008
#&gt;    400        0.4428             nan     0.1000   -0.0014
#&gt;    420        0.4325             nan     0.1000   -0.0017
#&gt;    440        0.4254             nan     0.1000   -0.0000
#&gt;    460        0.4188             nan     0.1000    0.0002
#&gt;    480        0.4124             nan     0.1000   -0.0019
#&gt;    500        0.4073             nan     0.1000   -0.0015
#&gt;    520        0.4025             nan     0.1000   -0.0025
#&gt;    540        0.3969             nan     0.1000   -0.0019
#&gt;    560        0.3930             nan     0.1000   -0.0008
#&gt;    580        0.3880             nan     0.1000   -0.0007
#&gt;    600        0.3824             nan     0.1000   -0.0005
#&gt;    606        0.3815             nan     0.1000   -0.0011
```

---
exclude: true

## Boosting in R

.col-left.pad-top[

```r
# Set the seed
set.seed(12345)
# Train the random forest
heart_boost = train(
  heart_disease ~ .,
  data = heart_df,
  method = "gbm",
  trControl = trainControl(
    method = "cv",
    number = 5
  ),
  tuneGrid = expand.grid(
    "n.trees" = seq(25, 200, by = 25),
    "interaction.depth" = 1:3,
    "shrinkage" = c(0.1, 0.01, 0.001),
    "n.minobsinnode" = 5
  )
)
```
]

---
exclude: true
count: false

## Boosting in R

.col-left.pad-top[

```r
# Set the seed
set.seed(12345)
# Train the random forest
heart_boost = train(
  heart_disease ~ .,
  data = heart_df,
* method = "gbm",
  trControl = trainControl(
    method = "cv",
    number = 5
  ),
  tuneGrid = expand.grid(
    "n.trees" = seq(25, 200, by = 25),
    "interaction.depth" = 1:3,
    "shrinkage" = c(0.1, 0.01, 0.001),
    "n.minobsinnode" = 5
  )
)
```
]
.col-right.pad-top[
&lt;br&gt;
- boosted trees via `gbm` package
]

---
exclude: true
count: false

## Boosting in R

.col-left.pad-top[

```r
# Set the seed
set.seed(12345)
# Train the random forest
heart_boost = train(
  heart_disease ~ .,
  data = heart_df,
  method = "gbm",
  trControl = trainControl(
*   method = "cv",
*   number = 5
  ),
  tuneGrid = expand.grid(
    "n.trees" = seq(25, 200, by = 25),
    "interaction.depth" = 1:3,
    "shrinkage" = c(0.1, 0.01, 0.001),
    "n.minobsinnode" = 5
  )
)
```
]
.col-right.pad-top[
&lt;br&gt;
- boosted trees via `gbm` package
- cross validation now (no OOB)
]

---
exclude: true
count: false

## Boosting in R

.col-left.pad-top[

```r
# Set the seed
set.seed(12345)
# Train the random forest
heart_boost = train(
  heart_disease ~ .,
  data = heart_df,
  method = "gbm",
  trControl = trainControl(
    method = "cv",
    number = 5
  ),
  tuneGrid = expand.grid(
*   "n.trees" = seq(25, 200, by = 25),
    "interaction.depth" = 1:3,
    "shrinkage" = c(0.1, 0.01, 0.001),
    "n.minobsinnode" = 5
  )
)
```
]
.col-right.pad-top[
&lt;br&gt;
- boosted trees via `gbm` package
- cross validation now (no OOB)
- CV-search of parameter grid
  - number of trees
]

---
exclude: true
count: false

## Boosting in R

.col-left.pad-top[

```r
# Set the seed
set.seed(12345)
# Train the random forest
heart_boost = train(
  heart_disease ~ .,
  data = heart_df,
  method = "gbm",
  trControl = trainControl(
    method = "cv",
    number = 5
  ),
  tuneGrid = expand.grid(
    "n.trees" = seq(25, 200, by = 25),
*   "interaction.depth" = 1:3,
    "shrinkage" = c(0.1, 0.01, 0.001),
    "n.minobsinnode" = 5
  )
)
```
]
.col-right.pad-top[
&lt;br&gt;
- boosted trees via `gbm` package
- cross validation now (no OOB)
- CV-search of parameter grid
  - number of trees
  - tree depth (complexity)
]

---
exclude: true
count: false

## Boosting in R

.col-left.pad-top[

```r
# Set the seed
set.seed(12345)
# Train the random forest
heart_boost = train(
  heart_disease ~ .,
  data = heart_df,
  method = "gbm",
  trControl = trainControl(
    method = "cv",
    number = 5
  ),
  tuneGrid = expand.grid(
    "n.trees" = seq(25, 200, by = 25),
    "interaction.depth" = 1:3,
*   "shrinkage" = c(0.1, 0.01, 0.001),
    "n.minobsinnode" = 5
  )
)
```
]
.col-right.pad-top[
&lt;br&gt;
- boosted trees via `gbm` package
- cross validation now (no OOB)
- CV-search of parameter grid
  - number of trees
  - tree depth (complexity)
  - shrinkage (learing rate)
]

---
exclude: true
count: false

## Boosting in R

.col-left.pad-top[

```r
# Set the seed
set.seed(12345)
# Train the random forest
heart_boost = train(
  heart_disease ~ .,
  data = heart_df,
  method = "gbm",
  trControl = trainControl(
    method = "cv",
    number = 5
  ),
  tuneGrid = expand.grid(
    "n.trees" = seq(25, 200, by = 25),
    "interaction.depth" = 1:3,
    "shrinkage" = c(0.1, 0.01, 0.001),
*   "n.minobsinnode" = 5
  )
)
```
]
.col-right.pad-top[
&lt;br&gt;
- boosted trees via `gbm` package
- cross validation now (no OOB)
- CV-search of parameter grid
  - number of trees
  - tree depth (complexity)
  - shrinkage (learing rate)
  - minimum leaf size&lt;br&gt;(not searching here)
]

---
layout: false
class: clear

.b[Comparing boosting parameters]â€”notice the rates of learning

&lt;img src="008-slides_files/figure-html/plot-boost-param-1.svg" style="display: block; margin: auto;" /&gt;

---
layout: false
class: clear

.b[Comparing boosting parameters]â€”more trees!

&lt;img src="008-slides_files/figure-html/plot-boost-param-more-1.svg" style="display: block; margin: auto;" /&gt;

---
class: clear

.b[Tree ensembles and the number of trees]

&lt;img src="008-slides_files/figure-html/plot-bag-rf-boost-1.svg" style="display: block; margin: auto;" /&gt;

---
layout: false
class: clear, middle

Of course, there are a lot of other tree-based learning options:

- [CatBoost](https://catboost.ai) ([R](https://catboost.ai/en/docs/concepts/r-installation))

- [LightGBM](https://lightgbm.readthedocs.io/en/latest/) ([R](https://lightgbm.readthedocs.io/en/latest/R/index.html))

- [TabNet](https://arxiv.org/abs/1908.07442) ([R](https://github.com/mlverse/tabnet/))


---
name: sources
layout: false
# Sources

These notes draw upon

- [An Introduction to Statistical Learning](http://faculty.marshall.usc.edu/gareth-james/ISL/) (*ISL*)&lt;br&gt;James, Witten, Hastie, and Tibshirani
---
# Table of contents

.col-left[
.smallest[
#### Admin
- [Today and upcoming](#admin)

#### Decision trees

1. [Fundamentals](#tree-review-fundamentals)
1. [Strengths and weaknesses](#tree-review-tradeoff)

#### Other
- [Sources/references](#sources)

]
]
.col-right[
.smallest[

#### Ensemble methods

1. [Introduction](#intro)
1. [Bagging](#bag-intro)
  - [Introduction](#bag-intro)
  - [Algorithm](#bag-algorithm)
  - [Out-of-bag](#bag-oob)
  - [In R](#bag-r)
  - [Variable importance](#bag-var)
1. [Random forests](#rf-intro)
  - [Introduction](#rf-intro)
  - [In R](#rf-r)
1. [Boosting](#boost-intro)
  - [Introduction](#boost-intro)
  - [Parameters](#boost-param)
  - [Algorithm](#boost-alg)
  - [In R](#boost-r)

]
]


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"highlightSpans": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
